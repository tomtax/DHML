{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b59afbfc",
   "metadata": {
    "papermill": {
     "duration": 0.011443,
     "end_time": "2024-02-29T13:25:41.827492",
     "exception": false,
     "start_time": "2024-02-29T13:25:41.816049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Framework for predictions and portfolio forming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea652e24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T13:25:41.852276Z",
     "iopub.status.busy": "2024-02-29T13:25:41.851732Z",
     "iopub.status.idle": "2024-02-29T13:25:45.608666Z",
     "shell.execute_reply": "2024-02-29T13:25:45.607121Z"
    },
    "papermill": {
     "duration": 3.773263,
     "end_time": "2024-02-29T13:25:45.611811",
     "exception": false,
     "start_time": "2024-02-29T13:25:41.838548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "# import the parquet library\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# import model libraries\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c7cee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T13:25:45.638553Z",
     "iopub.status.busy": "2024-02-29T13:25:45.637863Z",
     "iopub.status.idle": "2024-02-29T13:25:50.444448Z",
     "shell.execute_reply": "2024-02-29T13:25:50.443074Z"
    },
    "papermill": {
     "duration": 4.82394,
     "end_time": "2024-02-29T13:25:50.447256",
     "exception": false,
     "start_time": "2024-02-29T13:25:45.623316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>y</th>\n",
       "      <th>RET</th>\n",
       "      <th>LME</th>\n",
       "      <th>ME</th>\n",
       "      <th>bull_D</th>\n",
       "      <th>bear_D</th>\n",
       "      <th>bull_W</th>\n",
       "      <th>bear_W</th>\n",
       "      <th>bull_M</th>\n",
       "      <th>bear_M</th>\n",
       "      <th>SPREAD_L</th>\n",
       "      <th>LTURNOVER</th>\n",
       "      <th>IVOL</th>\n",
       "      <th>IVOL2</th>\n",
       "      <th>IVOL3</th>\n",
       "      <th>STR</th>\n",
       "      <th>LTR</th>\n",
       "      <th>IMOM</th>\n",
       "      <th>MOM</th>\n",
       "      <th>PCTHIGH</th>\n",
       "      <th>MVOL</th>\n",
       "      <th>MVOL2</th>\n",
       "      <th>MVOL3</th>\n",
       "      <th>LMKT</th>\n",
       "      <th>LMKT2</th>\n",
       "      <th>LMKT3</th>\n",
       "      <th>MMOM</th>\n",
       "      <th>MIMOM</th>\n",
       "      <th>MLTR</th>\n",
       "      <th>release_L</th>\n",
       "      <th>LAT</th>\n",
       "      <th>DPI2A_L</th>\n",
       "      <th>CTO_L</th>\n",
       "      <th>D2A_L</th>\n",
       "      <th>NOA_L</th>\n",
       "      <th>OL_L</th>\n",
       "      <th>PCM_L</th>\n",
       "      <th>FC2Y_L</th>\n",
       "      <th>INVEST_L</th>\n",
       "      <th>RNA_L</th>\n",
       "      <th>S2E_L</th>\n",
       "      <th>PROF_L</th>\n",
       "      <th>PM_L</th>\n",
       "      <th>ATO_L</th>\n",
       "      <th>ROA_L</th>\n",
       "      <th>FCF_L</th>\n",
       "      <th>A2ME_L</th>\n",
       "      <th>B2ME_L</th>\n",
       "      <th>S2P_L</th>\n",
       "      <th>ROE_L</th>\n",
       "      <th>LEV_L</th>\n",
       "      <th>TQ_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>1987-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.384615</td>\n",
       "      <td>1581.53125</td>\n",
       "      <td>973.25000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.297252</td>\n",
       "      <td>-1.089044</td>\n",
       "      <td>-2.079441</td>\n",
       "      <td>0.091549</td>\n",
       "      <td>0.545027</td>\n",
       "      <td>0.771919</td>\n",
       "      <td>0.434190</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>-0.0278</td>\n",
       "      <td>0.186212</td>\n",
       "      <td>0.112764</td>\n",
       "      <td>0.459110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055319</td>\n",
       "      <td>0.037352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236407</td>\n",
       "      <td>-1.495726</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016564</td>\n",
       "      <td>0.279904</td>\n",
       "      <td>0.064593</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.071779</td>\n",
       "      <td>-0.061939</td>\n",
       "      <td>-0.024586</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>748.571277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>1987-04-30</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>973.25000</td>\n",
       "      <td>912.44134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.285384</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>-0.384615</td>\n",
       "      <td>0.014185</td>\n",
       "      <td>-1.459321</td>\n",
       "      <td>-2.390877</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.672597</td>\n",
       "      <td>0.545027</td>\n",
       "      <td>0.771919</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.179935</td>\n",
       "      <td>-0.025601</td>\n",
       "      <td>0.498953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055319</td>\n",
       "      <td>0.037352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236407</td>\n",
       "      <td>-1.495726</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016564</td>\n",
       "      <td>0.279904</td>\n",
       "      <td>0.064593</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.071779</td>\n",
       "      <td>-0.061939</td>\n",
       "      <td>-0.024586</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>460.967849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>1987-05-31</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>912.44134</td>\n",
       "      <td>851.59375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.133330</td>\n",
       "      <td>0.256358</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>-0.089613</td>\n",
       "      <td>-1.633155</td>\n",
       "      <td>-2.772587</td>\n",
       "      <td>0.075378</td>\n",
       "      <td>1.565461</td>\n",
       "      <td>0.672597</td>\n",
       "      <td>0.545027</td>\n",
       "      <td>-0.0167</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.208747</td>\n",
       "      <td>0.032263</td>\n",
       "      <td>0.488026</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.115</td>\n",
       "      <td>-0.037825</td>\n",
       "      <td>0.074232</td>\n",
       "      <td>0.028309</td>\n",
       "      <td>-0.382033</td>\n",
       "      <td>0.293803</td>\n",
       "      <td>-1.101911</td>\n",
       "      <td>0.343949</td>\n",
       "      <td>-38.203310</td>\n",
       "      <td>-0.368640</td>\n",
       "      <td>-1.121429</td>\n",
       "      <td>2.535714</td>\n",
       "      <td>-2.261146</td>\n",
       "      <td>0.163032</td>\n",
       "      <td>-0.108274</td>\n",
       "      <td>-0.146901</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>-0.000251</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>699.225968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>1987-06-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>851.59375</td>\n",
       "      <td>851.59375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071451</td>\n",
       "      <td>0.209350</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.341485</td>\n",
       "      <td>-1.323014</td>\n",
       "      <td>-2.585254</td>\n",
       "      <td>0.070707</td>\n",
       "      <td>0.955605</td>\n",
       "      <td>1.565461</td>\n",
       "      <td>0.672597</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>-0.0167</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.142069</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>0.591159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.115</td>\n",
       "      <td>-0.037825</td>\n",
       "      <td>0.074232</td>\n",
       "      <td>0.028309</td>\n",
       "      <td>-0.382033</td>\n",
       "      <td>0.293803</td>\n",
       "      <td>-1.101911</td>\n",
       "      <td>0.343949</td>\n",
       "      <td>-38.203310</td>\n",
       "      <td>-0.368640</td>\n",
       "      <td>-1.121429</td>\n",
       "      <td>2.535714</td>\n",
       "      <td>-2.261146</td>\n",
       "      <td>0.163032</td>\n",
       "      <td>-0.108274</td>\n",
       "      <td>-0.146901</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>652.670811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005</td>\n",
       "      <td>1987-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>795.11688</td>\n",
       "      <td>795.11688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090936</td>\n",
       "      <td>0.016213</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.021169</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.405465</td>\n",
       "      <td>-1.163152</td>\n",
       "      <td>-0.470004</td>\n",
       "      <td>0.578954</td>\n",
       "      <td>0.545027</td>\n",
       "      <td>0.771919</td>\n",
       "      <td>0.434190</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>-0.0278</td>\n",
       "      <td>0.186212</td>\n",
       "      <td>0.112764</td>\n",
       "      <td>0.459110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.954</td>\n",
       "      <td>-0.001485</td>\n",
       "      <td>0.023762</td>\n",
       "      <td>0.015865</td>\n",
       "      <td>-0.032673</td>\n",
       "      <td>0.044012</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>1.437500</td>\n",
       "      <td>-3.267327</td>\n",
       "      <td>-0.423313</td>\n",
       "      <td>0.025263</td>\n",
       "      <td>-0.036316</td>\n",
       "      <td>-1.437500</td>\n",
       "      <td>0.294479</td>\n",
       "      <td>-0.033168</td>\n",
       "      <td>-0.018424</td>\n",
       "      <td>0.004506</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>406.945179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PERMNO       date  y       RET         LME         ME  bull_D  bear_D  \\\n",
       "0   10000 1987-03-31  0 -0.384615  1581.53125  973.25000     0.0     0.0   \n",
       "1   10000 1987-04-30  0 -0.062500   973.25000  912.44134     0.0     0.0   \n",
       "2   10000 1987-05-31  0 -0.066667   912.44134  851.59375     0.0     0.0   \n",
       "3   10000 1987-06-30  0  0.000000   851.59375  851.59375     0.0     0.0   \n",
       "4   10005 1987-03-31  0  0.000000   795.11688  795.11688     0.0     0.0   \n",
       "\n",
       "   bull_W  bear_W  bull_M  bear_M  SPREAD_L  LTURNOVER      IVOL     IVOL2  \\\n",
       "0     0.0     1.0       0       0  0.076923   0.100694  0.000612  0.000830   \n",
       "1     0.0     0.0       0       1  0.625000   0.285384  0.003465  0.000612   \n",
       "2     0.0     0.0       0       2  0.133330   0.256358  0.001893  0.003465   \n",
       "3     0.0     0.0       0       0  0.071451   0.209350  0.000190  0.001893   \n",
       "4     0.0     0.0       0       0  0.090936   0.016213  0.000532  0.021169   \n",
       "\n",
       "      IVOL3       STR       LTR      IMOM       MOM   PCTHIGH      MVOL  \\\n",
       "0  0.002413  0.000000 -0.297252 -1.089044 -2.079441  0.091549  0.545027   \n",
       "1  0.000830 -0.384615  0.014185 -1.459321 -2.390877  0.062500  0.672597   \n",
       "2  0.000612 -0.062500 -0.089613 -1.633155 -2.772587  0.075378  1.565461   \n",
       "3  0.003465 -0.066667 -0.341485 -1.323014 -2.585254  0.070707  0.955605   \n",
       "4  0.000013  0.100000 -0.405465 -1.163152 -0.470004  0.578954  0.545027   \n",
       "\n",
       "      MVOL2     MVOL3    LMKT   LMKT2   LMKT3      MMOM     MIMOM      MLTR  \\\n",
       "0  0.771919  0.434190  0.0482  0.1289 -0.0278  0.186212  0.112764  0.459110   \n",
       "1  0.545027  0.771919  0.0211  0.0482  0.1289  0.179935 -0.025601  0.498953   \n",
       "2  0.672597  0.545027 -0.0167  0.0211  0.0482  0.208747  0.032263  0.488026   \n",
       "3  1.565461  0.672597  0.0049 -0.0167  0.0211  0.142069 -0.002095  0.591159   \n",
       "4  0.771919  0.434190  0.0482  0.1289 -0.0278  0.186212  0.112764  0.459110   \n",
       "\n",
       "   release_L    LAT   DPI2A_L     CTO_L     D2A_L     NOA_L      OL_L  \\\n",
       "0        0.0  2.115  0.000000  0.055319  0.037352  0.000000  0.236407   \n",
       "1        0.0  2.115  0.000000  0.055319  0.037352  0.000000  0.236407   \n",
       "2        1.0  2.115 -0.037825  0.074232  0.028309 -0.382033  0.293803   \n",
       "3        0.0  2.115 -0.037825  0.074232  0.028309 -0.382033  0.293803   \n",
       "4        0.0  1.954 -0.001485  0.023762  0.015865 -0.032673  0.044012   \n",
       "\n",
       "      PCM_L    FC2Y_L   INVEST_L     RNA_L     S2E_L    PROF_L      PM_L  \\\n",
       "0 -1.495726  1.777778   0.000000  0.016564  0.279904  0.064593  0.230769   \n",
       "1 -1.495726  1.777778   0.000000  0.016564  0.279904  0.064593  0.230769   \n",
       "2 -1.101911  0.343949 -38.203310 -0.368640 -1.121429  2.535714 -2.261146   \n",
       "3 -1.101911  0.343949 -38.203310 -0.368640 -1.121429  2.535714 -2.261146   \n",
       "4  0.645833  1.437500  -3.267327 -0.423313  0.025263 -0.036316 -1.437500   \n",
       "\n",
       "      ATO_L     ROA_L     FCF_L    A2ME_L    B2ME_L     S2P_L     ROE_L  \\\n",
       "0  0.071779 -0.061939 -0.024586  0.001067  0.000211  0.000059 -0.000083   \n",
       "1  0.071779 -0.061939 -0.024586  0.001067  0.000211  0.000059 -0.000135   \n",
       "2  0.163032 -0.108274 -0.146901  0.000660 -0.000071  0.000079 -0.000251   \n",
       "3  0.163032 -0.108274 -0.146901  0.000660 -0.000071  0.000079 -0.000269   \n",
       "4  0.294479 -0.033168 -0.018424  0.004506  0.004381  0.000111 -0.000084   \n",
       "\n",
       "      LEV_L        TQ_L  \n",
       "0  0.000037  748.571277  \n",
       "1  0.000060  460.967849  \n",
       "2  0.000018  699.225968  \n",
       "3  0.000019  652.670811  \n",
       "4  0.000047  406.945179  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load 'basemodel.parquet'\n",
    "#df = pd.read_parquet('basemodel.parquet')\n",
    "df= pd.read_parquet('/kaggle/input/sign-prediction-datasets/clean_financials.parquet')\n",
    "prediction_cols = []\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1adb76b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T13:25:50.473858Z",
     "iopub.status.busy": "2024-02-29T13:25:50.473335Z",
     "iopub.status.idle": "2024-02-29T13:25:50.481127Z",
     "shell.execute_reply": "2024-02-29T13:25:50.479798Z"
    },
    "papermill": {
     "duration": 0.024134,
     "end_time": "2024-02-29T13:25:50.483618",
     "exception": false,
     "start_time": "2024-02-29T13:25:50.459484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select the columns to be used for prediction\n",
    "X_col = ['bull_D', 'bear_D', 'bull_W', 'bear_W', 'bull_M', 'bear_M', 'LMKT', 'IVOL', # initial columns\n",
    "         'STR',\t'LTURNOVER', 'IMOM', 'MOM',\t'LTR', 'PCTHIGH', 'IVOL2', 'IVOL3', 'SPREAD_L',\t# stock specific columns\n",
    "         'MVOL', 'MVOL2', 'MVOL3', 'LMKT2',\t'LMKT3', 'MMOM', 'MIMOM', 'MLTR', # market specific columns\n",
    "         'LAT',\t'DPI2A_L',\t'CTO_L', 'D2A_L', 'NOA_L', 'OL_L',\t'PCM_L', 'FC2Y_L',\t\n",
    "         'INVEST_L', 'RNA_L', 'S2E_L', 'PROF_L', 'PM_L', 'ATO_L', 'ROA_L', \t\n",
    "         'FCF_L', 'A2ME_L',\t'B2ME_L', 'S2P_L', 'ROE_L',\t'LEV_L', 'TQ_L'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf6298d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T13:25:50.509876Z",
     "iopub.status.busy": "2024-02-29T13:25:50.509352Z",
     "iopub.status.idle": "2024-02-29T13:25:53.944395Z",
     "shell.execute_reply": "2024-02-29T13:25:53.943295Z"
    },
    "papermill": {
     "duration": 3.451697,
     "end_time": "2024-02-29T13:25:53.947278",
     "exception": false,
     "start_time": "2024-02-29T13:25:50.495581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scale the data for faster coeficient convergence\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df[X_col] = scaler.fit_transform(df[X_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a9d21c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T13:25:53.973514Z",
     "iopub.status.busy": "2024-02-29T13:25:53.973045Z",
     "iopub.status.idle": "2024-02-29T13:25:55.609224Z",
     "shell.execute_reply": "2024-02-29T13:25:55.608148Z"
    },
    "papermill": {
     "duration": 1.652861,
     "end_time": "2024-02-29T13:25:55.611982",
     "exception": false,
     "start_time": "2024-02-29T13:25:53.959121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'date' to datetime format (if not already done) and sort the DataFrame\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.sort_values(by='date', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create a 'year' column based on the 'date' column\n",
    "df['year'] = df['date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86fa430",
   "metadata": {
    "papermill": {
     "duration": 0.012187,
     "end_time": "2024-02-29T13:25:55.637127",
     "exception": false,
     "start_time": "2024-02-29T13:25:55.624940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Paper Replication - OLS and Logit, Expanding Window - No Hyperparameters\n",
    "- They start with out of sample forecasting in 1932\n",
    "- models will be named model_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0f300f",
   "metadata": {
    "papermill": {
     "duration": 0.013195,
     "end_time": "2024-02-29T13:25:55.662410",
     "exception": false,
     "start_time": "2024-02-29T13:25:55.649215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Linear Regression (Pooled OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a82ec7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T13:25:55.689457Z",
     "iopub.status.busy": "2024-02-29T13:25:55.688347Z",
     "iopub.status.idle": "2024-02-29T13:26:33.072098Z",
     "shell.execute_reply": "2024-02-29T13:26:33.068459Z"
    },
    "papermill": {
     "duration": 37.405187,
     "end_time": "2024-02-29T13:26:33.080098",
     "exception": false,
     "start_time": "2024-02-29T13:25:55.674911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1976 - Time: 0.13 seconds\n",
      "Year 1977 - Time: 0.17 seconds\n",
      "Year 1978 - Time: 0.17 seconds\n",
      "Year 1979 - Time: 0.19 seconds\n",
      "Year 1980 - Time: 0.20 seconds\n",
      "Year 1981 - Time: 0.21 seconds\n",
      "Year 1982 - Time: 0.23 seconds\n",
      "Year 1983 - Time: 0.26 seconds\n",
      "Year 1984 - Time: 0.30 seconds\n",
      "Year 1985 - Time: 0.30 seconds\n",
      "Year 1986 - Time: 0.31 seconds\n",
      "Year 1987 - Time: 0.34 seconds\n",
      "Year 1988 - Time: 0.38 seconds\n",
      "Year 1989 - Time: 0.40 seconds\n",
      "Year 1990 - Time: 0.44 seconds\n",
      "Year 1991 - Time: 0.46 seconds\n",
      "Year 1992 - Time: 0.51 seconds\n",
      "Year 1993 - Time: 0.52 seconds\n",
      "Year 1994 - Time: 0.54 seconds\n",
      "Year 1995 - Time: 0.60 seconds\n",
      "Year 1996 - Time: 0.62 seconds\n",
      "Year 1997 - Time: 0.64 seconds\n",
      "Year 1998 - Time: 0.70 seconds\n",
      "Year 1999 - Time: 0.71 seconds\n",
      "Year 2000 - Time: 0.74 seconds\n",
      "Year 2001 - Time: 0.84 seconds\n",
      "Year 2002 - Time: 0.92 seconds\n",
      "Year 2003 - Time: 0.89 seconds\n",
      "Year 2004 - Time: 0.92 seconds\n",
      "Year 2005 - Time: 0.97 seconds\n",
      "Year 2006 - Time: 0.99 seconds\n",
      "Year 2007 - Time: 1.02 seconds\n",
      "Year 2008 - Time: 1.22 seconds\n",
      "Year 2009 - Time: 1.06 seconds\n",
      "Year 2010 - Time: 1.07 seconds\n",
      "Year 2011 - Time: 1.10 seconds\n",
      "Year 2012 - Time: 2.73 seconds\n",
      "Year 2013 - Time: 2.18 seconds\n",
      "Year 2014 - Time: 1.20 seconds\n",
      "Year 2015 - Time: 1.18 seconds\n",
      "Year 2016 - Time: 1.18 seconds\n",
      "Year 2017 - Time: 1.24 seconds\n",
      "Year 2018 - Time: 1.28 seconds\n",
      "Year 2019 - Time: 1.23 seconds\n",
      "Year 2020 - Time: 1.30 seconds\n",
      "Year 2021 - Time: 1.37 seconds\n",
      "Year 2022 - Time: 1.36 seconds\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "# OLS, default, exp window\n",
    "#################################\n",
    "\n",
    "model_name = 'base_ols_default'\n",
    "\n",
    "\n",
    "# Update the column name for storing Decision Tree regression predictions\n",
    "df[model_name] = np.nan\n",
    "\n",
    "# Ensure the new column is in the prediction_cols list\n",
    "if model_name not in prediction_cols:\n",
    "    prediction_cols.append(model_name)\n",
    "\n",
    "for year in range(df['year'].min() + 6, df['year'].max() + 1):\n",
    "    start_time = time.time()  # Start timing\n",
    "    \n",
    "    # Define the training data up until this year\n",
    "    train_data = df[df['year'] < year]\n",
    "    \n",
    "    X_train = train_data[['bull_D', 'bear_D', 'bull_W', 'bear_W', 'bull_M', 'bear_M', 'LMKT', 'IVOL']]\n",
    "    y_train = train_data['y']\n",
    "    \n",
    "    # Train the Linear Regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict for the next year\n",
    "    next_year_data = df[df['year'] == year]\n",
    "    X_next_year = next_year_data[['bull_D', 'bear_D', 'bull_W', 'bear_W', 'bull_M', 'bear_M', 'LMKT', 'IVOL']]\n",
    "    \n",
    "    if not X_next_year.empty:\n",
    "        next_year_predictions = model.predict(X_next_year)\n",
    "        df.loc[df['year'] == year, model_name] = next_year_predictions\n",
    "    \n",
    "    end_time = time.time()  # End timing\n",
    "    iteration_time = end_time - start_time  # Calculate iteration time\n",
    "    \n",
    "    print(f\"Year {year} - Time: {iteration_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a597cd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T13:26:33.164828Z",
     "iopub.status.busy": "2024-02-29T13:26:33.162383Z",
     "iopub.status.idle": "2024-02-29T13:29:44.552277Z",
     "shell.execute_reply": "2024-02-29T13:29:44.550510Z"
    },
    "papermill": {
     "duration": 191.438691,
     "end_time": "2024-02-29T13:29:44.557385",
     "exception": false,
     "start_time": "2024-02-29T13:26:33.118694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1976 - Time: 0.34 seconds\n",
      "Year 1977 - Time: 0.46 seconds\n",
      "Year 1978 - Time: 0.54 seconds\n",
      "Year 1979 - Time: 0.68 seconds\n",
      "Year 1980 - Time: 0.72 seconds\n",
      "Year 1981 - Time: 0.80 seconds\n",
      "Year 1982 - Time: 0.96 seconds\n",
      "Year 1983 - Time: 0.95 seconds\n",
      "Year 1984 - Time: 1.09 seconds\n",
      "Year 1985 - Time: 1.21 seconds\n",
      "Year 1986 - Time: 1.31 seconds\n",
      "Year 1987 - Time: 1.50 seconds\n",
      "Year 1988 - Time: 1.95 seconds\n",
      "Year 1989 - Time: 1.97 seconds\n",
      "Year 1990 - Time: 1.94 seconds\n",
      "Year 1991 - Time: 2.07 seconds\n",
      "Year 1992 - Time: 2.19 seconds\n",
      "Year 1993 - Time: 2.37 seconds\n",
      "Year 1994 - Time: 2.79 seconds\n",
      "Year 1995 - Time: 2.82 seconds\n",
      "Year 1996 - Time: 3.41 seconds\n",
      "Year 1997 - Time: 3.41 seconds\n",
      "Year 1998 - Time: 3.59 seconds\n",
      "Year 1999 - Time: 4.33 seconds\n",
      "Year 2000 - Time: 4.46 seconds\n",
      "Year 2001 - Time: 4.55 seconds\n",
      "Year 2002 - Time: 4.82 seconds\n",
      "Year 2003 - Time: 5.00 seconds\n",
      "Year 2004 - Time: 5.20 seconds\n",
      "Year 2005 - Time: 5.38 seconds\n",
      "Year 2006 - Time: 5.55 seconds\n",
      "Year 2007 - Time: 5.58 seconds\n",
      "Year 2008 - Time: 5.95 seconds\n",
      "Year 2009 - Time: 6.28 seconds\n",
      "Year 2010 - Time: 6.49 seconds\n",
      "Year 2011 - Time: 6.69 seconds\n",
      "Year 2012 - Time: 6.97 seconds\n",
      "Year 2013 - Time: 7.02 seconds\n",
      "Year 2014 - Time: 7.00 seconds\n",
      "Year 2015 - Time: 7.12 seconds\n",
      "Year 2016 - Time: 7.32 seconds\n",
      "Year 2017 - Time: 7.55 seconds\n",
      "Year 2018 - Time: 7.79 seconds\n",
      "Year 2019 - Time: 7.69 seconds\n",
      "Year 2020 - Time: 7.82 seconds\n",
      "Year 2021 - Time: 7.88 seconds\n",
      "Year 2022 - Time: 7.81 seconds\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "# OLS, default, exp window\n",
    "#################################\n",
    "\n",
    "model_name = 'ols_default'\n",
    "\n",
    "\n",
    "# Update the column name for storing Decision Tree regression predictions\n",
    "df[model_name] = np.nan\n",
    "\n",
    "# Ensure the new column is in the prediction_cols list\n",
    "if model_name not in prediction_cols:\n",
    "    prediction_cols.append(model_name)\n",
    "\n",
    "for year in range(df['year'].min() + 6, df['year'].max() + 1):\n",
    "    start_time = time.time()  # Start timing\n",
    "    \n",
    "    # Define the training data up until this year\n",
    "    train_data = df[df['year'] < year]\n",
    "    \n",
    "    X_train = train_data[X_col]\n",
    "    y_train = train_data['y']\n",
    "    \n",
    "    # Train the Linear Regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict for the next year\n",
    "    next_year_data = df[df['year'] == year]\n",
    "    X_next_year = next_year_data[X_col]\n",
    "    \n",
    "    if not X_next_year.empty:\n",
    "        next_year_predictions = model.predict(X_next_year)\n",
    "        df.loc[df['year'] == year, model_name] = next_year_predictions\n",
    "    \n",
    "    end_time = time.time()  # End timing\n",
    "    iteration_time = end_time - start_time  # Calculate iteration time\n",
    "    \n",
    "    print(f\"Year {year} - Time: {iteration_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b2e0a6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T13:29:44.650291Z",
     "iopub.status.busy": "2024-02-29T13:29:44.649320Z",
     "iopub.status.idle": "2024-02-29T13:29:44.707142Z",
     "shell.execute_reply": "2024-02-29T13:29:44.705984Z"
    },
    "papermill": {
     "duration": 0.108107,
     "end_time": "2024-02-29T13:29:44.709856",
     "exception": false,
     "start_time": "2024-02-29T13:29:44.601749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>y</th>\n",
       "      <th>RET</th>\n",
       "      <th>LME</th>\n",
       "      <th>ME</th>\n",
       "      <th>bull_D</th>\n",
       "      <th>bear_D</th>\n",
       "      <th>bull_W</th>\n",
       "      <th>bear_W</th>\n",
       "      <th>bull_M</th>\n",
       "      <th>bear_M</th>\n",
       "      <th>SPREAD_L</th>\n",
       "      <th>LTURNOVER</th>\n",
       "      <th>IVOL</th>\n",
       "      <th>IVOL2</th>\n",
       "      <th>IVOL3</th>\n",
       "      <th>STR</th>\n",
       "      <th>LTR</th>\n",
       "      <th>IMOM</th>\n",
       "      <th>MOM</th>\n",
       "      <th>PCTHIGH</th>\n",
       "      <th>MVOL</th>\n",
       "      <th>MVOL2</th>\n",
       "      <th>MVOL3</th>\n",
       "      <th>LMKT</th>\n",
       "      <th>LMKT2</th>\n",
       "      <th>LMKT3</th>\n",
       "      <th>MMOM</th>\n",
       "      <th>MIMOM</th>\n",
       "      <th>MLTR</th>\n",
       "      <th>release_L</th>\n",
       "      <th>LAT</th>\n",
       "      <th>DPI2A_L</th>\n",
       "      <th>CTO_L</th>\n",
       "      <th>D2A_L</th>\n",
       "      <th>NOA_L</th>\n",
       "      <th>OL_L</th>\n",
       "      <th>PCM_L</th>\n",
       "      <th>FC2Y_L</th>\n",
       "      <th>INVEST_L</th>\n",
       "      <th>RNA_L</th>\n",
       "      <th>S2E_L</th>\n",
       "      <th>PROF_L</th>\n",
       "      <th>PM_L</th>\n",
       "      <th>ATO_L</th>\n",
       "      <th>ROA_L</th>\n",
       "      <th>FCF_L</th>\n",
       "      <th>A2ME_L</th>\n",
       "      <th>B2ME_L</th>\n",
       "      <th>S2P_L</th>\n",
       "      <th>ROE_L</th>\n",
       "      <th>LEV_L</th>\n",
       "      <th>TQ_L</th>\n",
       "      <th>year</th>\n",
       "      <th>base_ols_default</th>\n",
       "      <th>ols_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1795158</th>\n",
       "      <td>14523</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.211268</td>\n",
       "      <td>4.210201e+05</td>\n",
       "      <td>3.603768e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010376</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.046569</td>\n",
       "      <td>0.752262</td>\n",
       "      <td>0.626562</td>\n",
       "      <td>0.667402</td>\n",
       "      <td>0.596191</td>\n",
       "      <td>0.108507</td>\n",
       "      <td>0.127252</td>\n",
       "      <td>0.072299</td>\n",
       "      <td>0.363567</td>\n",
       "      <td>0.568917</td>\n",
       "      <td>0.336051</td>\n",
       "      <td>0.428937</td>\n",
       "      <td>0.674246</td>\n",
       "      <td>0.832911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.907457</td>\n",
       "      <td>0.105361</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.261469</td>\n",
       "      <td>0.217470</td>\n",
       "      <td>0.304657</td>\n",
       "      <td>0.956337</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>0.784626</td>\n",
       "      <td>0.140765</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.797185</td>\n",
       "      <td>0.009079</td>\n",
       "      <td>0.522669</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.528958</td>\n",
       "      <td>0.456078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795159</th>\n",
       "      <td>84413</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020794</td>\n",
       "      <td>9.367426e+05</td>\n",
       "      <td>9.562860e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.042502</td>\n",
       "      <td>0.708189</td>\n",
       "      <td>0.669056</td>\n",
       "      <td>0.712299</td>\n",
       "      <td>0.767522</td>\n",
       "      <td>0.108507</td>\n",
       "      <td>0.127252</td>\n",
       "      <td>0.072299</td>\n",
       "      <td>0.363567</td>\n",
       "      <td>0.568917</td>\n",
       "      <td>0.336051</td>\n",
       "      <td>0.428937</td>\n",
       "      <td>0.674246</td>\n",
       "      <td>0.832911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.006655</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.907473</td>\n",
       "      <td>0.105362</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.261528</td>\n",
       "      <td>0.217475</td>\n",
       "      <td>0.304657</td>\n",
       "      <td>0.956344</td>\n",
       "      <td>0.008166</td>\n",
       "      <td>0.785350</td>\n",
       "      <td>0.140878</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.797068</td>\n",
       "      <td>0.009113</td>\n",
       "      <td>0.522682</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.819094</td>\n",
       "      <td>0.816904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795160</th>\n",
       "      <td>14526</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066548</td>\n",
       "      <td>8.689975e+05</td>\n",
       "      <td>9.219528e+05</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.037465</td>\n",
       "      <td>0.704435</td>\n",
       "      <td>0.671810</td>\n",
       "      <td>0.725260</td>\n",
       "      <td>0.814332</td>\n",
       "      <td>0.108507</td>\n",
       "      <td>0.127252</td>\n",
       "      <td>0.072299</td>\n",
       "      <td>0.363567</td>\n",
       "      <td>0.568917</td>\n",
       "      <td>0.336051</td>\n",
       "      <td>0.428937</td>\n",
       "      <td>0.674246</td>\n",
       "      <td>0.832911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.006563</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.907461</td>\n",
       "      <td>0.105344</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.261578</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>0.304673</td>\n",
       "      <td>0.956347</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>0.785690</td>\n",
       "      <td>0.141023</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.797248</td>\n",
       "      <td>0.009861</td>\n",
       "      <td>0.522707</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.711270</td>\n",
       "      <td>0.700782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795161</th>\n",
       "      <td>90548</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.087452</td>\n",
       "      <td>1.138132e+05</td>\n",
       "      <td>1.216028e+05</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.034937</td>\n",
       "      <td>0.710461</td>\n",
       "      <td>0.697203</td>\n",
       "      <td>0.745026</td>\n",
       "      <td>0.673998</td>\n",
       "      <td>0.108507</td>\n",
       "      <td>0.127252</td>\n",
       "      <td>0.072299</td>\n",
       "      <td>0.363567</td>\n",
       "      <td>0.568917</td>\n",
       "      <td>0.336051</td>\n",
       "      <td>0.428937</td>\n",
       "      <td>0.674246</td>\n",
       "      <td>0.832911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.907466</td>\n",
       "      <td>0.105348</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.261564</td>\n",
       "      <td>0.217474</td>\n",
       "      <td>0.304668</td>\n",
       "      <td>0.956347</td>\n",
       "      <td>0.008270</td>\n",
       "      <td>0.785608</td>\n",
       "      <td>0.141003</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.797898</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>0.522709</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.849967</td>\n",
       "      <td>0.900600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795162</th>\n",
       "      <td>93436</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.323765</td>\n",
       "      <td>7.010302e+08</td>\n",
       "      <td>9.311106e+08</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.035278</td>\n",
       "      <td>0.866215</td>\n",
       "      <td>0.692366</td>\n",
       "      <td>0.729311</td>\n",
       "      <td>0.587806</td>\n",
       "      <td>0.108507</td>\n",
       "      <td>0.127252</td>\n",
       "      <td>0.072299</td>\n",
       "      <td>0.363567</td>\n",
       "      <td>0.568917</td>\n",
       "      <td>0.336051</td>\n",
       "      <td>0.428937</td>\n",
       "      <td>0.674246</td>\n",
       "      <td>0.832911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.077968</td>\n",
       "      <td>0.006790</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.907462</td>\n",
       "      <td>0.105342</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.261577</td>\n",
       "      <td>0.217473</td>\n",
       "      <td>0.304671</td>\n",
       "      <td>0.956348</td>\n",
       "      <td>0.008230</td>\n",
       "      <td>0.785736</td>\n",
       "      <td>0.141042</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.797041</td>\n",
       "      <td>0.009040</td>\n",
       "      <td>0.522691</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.711275</td>\n",
       "      <td>0.814605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PERMNO       date  y       RET           LME            ME    bull_D  \\\n",
       "1795158   14523 2022-07-31  0 -0.211268  4.210201e+05  3.603768e+05  0.000000   \n",
       "1795159   84413 2022-07-31  1  0.020794  9.367426e+05  9.562860e+05  0.000000   \n",
       "1795160   14526 2022-07-31  1  0.066548  8.689975e+05  9.219528e+05  0.166667   \n",
       "1795161   90548 2022-07-31  1  0.087452  1.138132e+05  1.216028e+05  0.416667   \n",
       "1795162   93436 2022-07-31  1  0.323765  7.010302e+08  9.311106e+08  0.166667   \n",
       "\n",
       "         bear_D    bull_W  bear_W    bull_M  bear_M  SPREAD_L  LTURNOVER  \\\n",
       "1795158     0.0  0.000000     0.0  0.000000     0.0  0.010376   0.000127   \n",
       "1795159     0.0  0.000000     0.0  0.166667     0.0  0.004925   0.000068   \n",
       "1795160     0.0  0.083333     0.0  0.000000     0.0  0.004318   0.000094   \n",
       "1795161     0.0  0.083333     0.0  0.000000     0.0  0.005750   0.000025   \n",
       "1795162     0.0  0.083333     0.0  0.000000     0.0  0.004688   0.000218   \n",
       "\n",
       "             IVOL     IVOL2     IVOL3       STR       LTR      IMOM       MOM  \\\n",
       "1795158  0.000547  0.000081  0.000018  0.046569  0.752262  0.626562  0.667402   \n",
       "1795159  0.000052  0.000111  0.000040  0.042502  0.708189  0.669056  0.712299   \n",
       "1795160  0.000042  0.000013  0.000019  0.037465  0.704435  0.671810  0.725260   \n",
       "1795161  0.000038  0.000066  0.000015  0.034937  0.710461  0.697203  0.745026   \n",
       "1795162  0.000038  0.000041  0.000077  0.035278  0.866215  0.692366  0.729311   \n",
       "\n",
       "          PCTHIGH      MVOL     MVOL2     MVOL3      LMKT     LMKT2     LMKT3  \\\n",
       "1795158  0.596191  0.108507  0.127252  0.072299  0.363567  0.568917  0.336051   \n",
       "1795159  0.767522  0.108507  0.127252  0.072299  0.363567  0.568917  0.336051   \n",
       "1795160  0.814332  0.108507  0.127252  0.072299  0.363567  0.568917  0.336051   \n",
       "1795161  0.673998  0.108507  0.127252  0.072299  0.363567  0.568917  0.336051   \n",
       "1795162  0.587806  0.108507  0.127252  0.072299  0.363567  0.568917  0.336051   \n",
       "\n",
       "             MMOM     MIMOM      MLTR  release_L       LAT   DPI2A_L  \\\n",
       "1795158  0.428937  0.674246  0.832911        1.0  0.000078  0.007624   \n",
       "1795159  0.428937  0.674246  0.832911        1.0  0.000262  0.006655   \n",
       "1795160  0.428937  0.674246  0.832911        0.0  0.001048  0.006563   \n",
       "1795161  0.428937  0.674246  0.832911        1.0  0.000372  0.006682   \n",
       "1795162  0.428937  0.674246  0.832911        1.0  0.077968  0.006790   \n",
       "\n",
       "            CTO_L     D2A_L     NOA_L      OL_L     PCM_L    FC2Y_L  INVEST_L  \\\n",
       "1795158  0.000401  0.000090  0.000694  0.000181  0.907457  0.105361  0.000694   \n",
       "1795159  0.000400  0.000085  0.000376  0.000203  0.907473  0.105362  0.000376   \n",
       "1795160  0.000466  0.000117  0.000394  0.000240  0.907461  0.105344  0.000394   \n",
       "1795161  0.000408  0.000135  0.000382  0.000187  0.907466  0.105348  0.000382   \n",
       "1795162  0.000415  0.000123  0.000400  0.000184  0.907462  0.105342  0.000400   \n",
       "\n",
       "            RNA_L     S2E_L    PROF_L      PM_L     ATO_L     ROA_L     FCF_L  \\\n",
       "1795158  0.261469  0.217470  0.304657  0.956337  0.008175  0.784626  0.140765   \n",
       "1795159  0.261528  0.217475  0.304657  0.956344  0.008166  0.785350  0.140878   \n",
       "1795160  0.261578  0.217481  0.304673  0.956347  0.008336  0.785690  0.141023   \n",
       "1795161  0.261564  0.217474  0.304668  0.956347  0.008270  0.785608  0.141003   \n",
       "1795162  0.261577  0.217473  0.304671  0.956348  0.008230  0.785736  0.141042   \n",
       "\n",
       "           A2ME_L    B2ME_L     S2P_L     ROE_L     LEV_L      TQ_L  year  \\\n",
       "1795158  0.000122  0.797185  0.009079  0.522669  0.000005  0.000137  2022   \n",
       "1795159  0.000094  0.797068  0.009113  0.522682  0.000030  0.000168  2022   \n",
       "1795160  0.000383  0.797248  0.009861  0.522707  0.000150  0.000037  2022   \n",
       "1795161  0.001059  0.797898  0.010453  0.522709  0.000321  0.000014  2022   \n",
       "1795162  0.000032  0.797041  0.009040  0.522691  0.000006  0.000397  2022   \n",
       "\n",
       "         base_ols_default  ols_default  \n",
       "1795158          0.528958     0.456078  \n",
       "1795159          0.819094     0.816904  \n",
       "1795160          0.711270     0.700782  \n",
       "1795161          0.849967     0.900600  \n",
       "1795162          0.711275     0.814605  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a70247",
   "metadata": {
    "papermill": {
     "duration": 0.021026,
     "end_time": "2024-02-29T13:29:44.753525",
     "exception": false,
     "start_time": "2024-02-29T13:29:44.732499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# My Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edcfba4",
   "metadata": {
    "papermill": {
     "duration": 0.022241,
     "end_time": "2024-02-29T13:29:44.797578",
     "exception": false,
     "start_time": "2024-02-29T13:29:44.775337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Machine Learning - Hyperparameter Tuning included in the process\n",
    "- models to be named 'model_clas/reg_exp/roll'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbbbf55",
   "metadata": {
    "papermill": {
     "duration": 0.020548,
     "end_time": "2024-02-29T13:29:44.839396",
     "exception": false,
     "start_time": "2024-02-29T13:29:44.818848",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### First expanding, then rolling\n",
    "start predicting for 1932, expand the window until you reach X years, then roll it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e019d31",
   "metadata": {
    "papermill": {
     "duration": 0.020353,
     "end_time": "2024-02-29T13:29:44.880583",
     "exception": false,
     "start_time": "2024-02-29T13:29:44.860230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### MSE Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6255c786",
   "metadata": {
    "papermill": {
     "duration": 0.020862,
     "end_time": "2024-02-29T13:29:44.922987",
     "exception": false,
     "start_time": "2024-02-29T13:29:44.902125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb6062e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T13:29:44.966897Z",
     "iopub.status.busy": "2024-02-29T13:29:44.966413Z",
     "iopub.status.idle": "2024-02-29T13:29:44.972085Z",
     "shell.execute_reply": "2024-02-29T13:29:44.970753Z"
    },
    "papermill": {
     "duration": 0.030966,
     "end_time": "2024-02-29T13:29:44.974783",
     "exception": false,
     "start_time": "2024-02-29T13:29:44.943817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rolling_window = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7938075a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T13:29:45.022248Z",
     "iopub.status.busy": "2024-02-29T13:29:45.021833Z",
     "iopub.status.idle": "2024-02-29T14:47:09.406491Z",
     "shell.execute_reply": "2024-02-29T14:47:09.403041Z"
    },
    "papermill": {
     "duration": 4644.413493,
     "end_time": "2024-02-29T14:47:09.411455",
     "exception": false,
     "start_time": "2024-02-29T13:29:44.997962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1976 - Best C: 100, Best ACC: 0.0676, Time: 40.40 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1977 - Best C: 100, Best ACC: 0.0567, Time: 55.69 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1978 - Best C: 100, Best ACC: 0.0615, Time: 61.53 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1979 - Best C: 100, Best ACC: 0.0487, Time: 61.97 seconds\n",
      "Year 1980 - Best C: 100, Best ACC: 0.0497, Time: 54.69 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1981 - Best C: 100, Best ACC: 0.051, Time: 62.29 seconds\n",
      "Year 1982 - Best C: 100, Best ACC: 0.0438, Time: 51.80 seconds\n",
      "Year 1983 - Best C: 100, Best ACC: 0.0484, Time: 54.98 seconds\n",
      "Year 1984 - Best C: 100, Best ACC: 0.0511, Time: 55.04 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1985 - Best C: 100, Best ACC: 0.0622, Time: 62.83 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1986 - Best C: 100, Best ACC: 0.0648, Time: 73.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1987 - Best C: 100, Best ACC: 0.063, Time: 100.72 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1988 - Best C: 100, Best ACC: 0.0778, Time: 101.71 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1989 - Best C: 100, Best ACC: 0.087, Time: 118.59 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1990 - Best C: 100, Best ACC: 0.0715, Time: 123.24 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1991 - Best C: 100, Best ACC: 0.0688, Time: 127.22 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1992 - Best C: 100, Best ACC: 0.0711, Time: 130.29 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1993 - Best C: 100, Best ACC: 0.0692, Time: 130.79 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1994 - Best C: 100, Best ACC: 0.0665, Time: 120.29 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1995 - Best C: 100, Best ACC: 0.0651, Time: 123.82 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1996 - Best C: 100, Best ACC: 0.0599, Time: 115.24 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1997 - Best C: 100, Best ACC: 0.0529, Time: 129.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1998 - Best C: 100, Best ACC: 0.0449, Time: 129.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1999 - Best C: 100, Best ACC: 0.0393, Time: 135.49 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2000 - Best C: 100, Best ACC: 0.0399, Time: 140.98 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2001 - Best C: 100, Best ACC: 0.0339, Time: 139.38 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2002 - Best C: 100, Best ACC: 0.0286, Time: 160.17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2003 - Best C: 100, Best ACC: 0.0287, Time: 144.24 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2004 - Best C: 100, Best ACC: 0.0345, Time: 135.30 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2005 - Best C: 100, Best ACC: 0.0323, Time: 135.54 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2006 - Best C: 100, Best ACC: 0.0291, Time: 128.80 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2007 - Best C: 100, Best ACC: 0.0285, Time: 118.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2008 - Best C: 100, Best ACC: 0.0276, Time: 106.37 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2009 - Best C: 100, Best ACC: 0.0323, Time: 99.39 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2010 - Best C: 100, Best ACC: 0.0399, Time: 91.96 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2011 - Best C: 100, Best ACC: 0.0253, Time: 103.64 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2012 - Best C: 100, Best ACC: 0.0279, Time: 99.75 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2013 - Best C: 100, Best ACC: 0.0353, Time: 98.99 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2014 - Best C: 100, Best ACC: 0.031, Time: 96.22 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2015 - Best C: 100, Best ACC: 0.0265, Time: 79.33 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2016 - Best C: 100, Best ACC: 0.0289, Time: 79.93 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2017 - Best C: 100, Best ACC: 0.0274, Time: 77.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2018 - Best C: 100, Best ACC: 0.031, Time: 76.30 seconds\n",
      "Year 2019 - Best C: 100, Best ACC: 0.0312, Time: 70.07 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2020 - Best C: 100, Best ACC: 0.0238, Time: 72.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2021 - Best C: 100, Best ACC: 0.0418, Time: 84.40 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2022 - Best C: 100, Best ACC: 0.0406, Time: 86.43 seconds\n",
      "Total time: 4644.36 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# RIDGE CLASSIFICATION MODEL - MSE\n",
    "############################################\n",
    "\n",
    "model_name = 'ridge_clas_roll5_MSE'  # Name of the new column for storing predictions\n",
    "start_time2 = time.time()  # Start timing\n",
    "\n",
    "\n",
    "# Predefined set of C values for hyperparameter tuning\n",
    "HP1 = [0.01, 0.1, 1, 10, 100] # C\n",
    "\n",
    "# Update the column name for storing Decision Tree regression predictions\n",
    "df[model_name] = np.nan\n",
    "\n",
    "# Ensure the new column is in the prediction_cols list\n",
    "if model_name not in prediction_cols:\n",
    "    prediction_cols.append(model_name)\n",
    "\n",
    "# Define the start year for modeling based on having at least 7 years of data\n",
    "start_modeling_year = df['year'].min() + 6\n",
    "\n",
    "for year in range(start_modeling_year, df['year'].max() + 1):\n",
    "    start_time = time.time()  # Start timing\n",
    "    \n",
    "    # Determine the start year of the training window based on the current year\n",
    "    train_start_year = max(year - rolling_window, df['year'].min())  # Ensure it does not go below the earliest year\n",
    "    \n",
    "    # Select the training data based on the calculated start year\n",
    "    train_data = df[(df['year'] >= train_start_year) & (df['year'] < year)]\n",
    "    \n",
    "    # Split training data into actual training and tuning sets\n",
    "    # Use the last year of the training data for tuning\n",
    "    tuning_data = train_data[train_data['year'] == year - 1]\n",
    "    actual_train_data = train_data[train_data['year'] < year - 1]\n",
    "    \n",
    "    X_train = actual_train_data[X_col]\n",
    "    y_train = actual_train_data['y']\n",
    "    \n",
    "    X_tune = tuning_data[X_col]\n",
    "    y_tune = tuning_data['y']\n",
    "       \n",
    "    best_HP1 = None\n",
    "    best_mse = np.inf # Initialize with infinity\n",
    "    \n",
    "    # Hyperparameter tuning\n",
    "    for hp1 in HP1:\n",
    "        model = LogisticRegression(C=hp1, max_iter=1000, penalty='l2')  # Ridge\n",
    "        model.fit(X_train, y_train)\n",
    "        probabilities = model.predict_proba(X_tune)[:, 1]  # Get probabilities of the positive class\n",
    "        mse = mean_squared_error(y_tune, probabilities)  # Calculate MSE\n",
    "        \n",
    "        if mse < best_mse:  # Lower MSE is better\n",
    "            best_mse = mse\n",
    "            best_HP1 = hp1\n",
    "    \n",
    "    \n",
    "    # Retrain on the entire training window (excluding tuning year) with the best C value\n",
    "    model = LogisticRegression(C=best_HP1, max_iter=1000, penalty='l2')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict for the next year\n",
    "    next_year_data = df[df['year'] == year]\n",
    "    X_next_year = next_year_data[X_col]\n",
    "    \n",
    "    if not X_next_year.empty:\n",
    "        next_year_probabilities = model.predict_proba(X_next_year)[:, 1]  # Probability of the positive class\n",
    "        df.loc[df['year'] == year, model_name] = next_year_probabilities\n",
    "    \n",
    "    end_time = time.time()  # End timing\n",
    "    iteration_time = end_time - start_time  # Calculate iteration time\n",
    "    \n",
    "    print(f\"Year {year} - Best C: {best_HP1}, Best ACC: {round(best_mse,4)}, Time: {iteration_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "end_time2 = time.time()  # End timing\n",
    "print(f\"Total time: {end_time2 - start_time2:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab77c915",
   "metadata": {
    "papermill": {
     "duration": 0.042417,
     "end_time": "2024-02-29T14:47:09.531517",
     "exception": false,
     "start_time": "2024-02-29T14:47:09.489100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b2b26f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T14:47:09.606786Z",
     "iopub.status.busy": "2024-02-29T14:47:09.606175Z",
     "iopub.status.idle": "2024-02-29T15:05:47.795691Z",
     "shell.execute_reply": "2024-02-29T15:05:47.790120Z"
    },
    "papermill": {
     "duration": 1118.266274,
     "end_time": "2024-02-29T15:05:47.833286",
     "exception": false,
     "start_time": "2024-02-29T14:47:09.567012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1976 - Best Max Depth: 5, Best ACC: 0.0374, Time: 7.97 seconds\n",
      "Year 1977 - Best Max Depth: 5, Best ACC: 0.033, Time: 12.02 seconds\n",
      "Year 1978 - Best Max Depth: 5, Best ACC: 0.0347, Time: 13.40 seconds\n",
      "Year 1979 - Best Max Depth: 10, Best ACC: 0.0281, Time: 14.19 seconds\n",
      "Year 1980 - Best Max Depth: 5, Best ACC: 0.0257, Time: 13.52 seconds\n",
      "Year 1981 - Best Max Depth: 5, Best ACC: 0.0215, Time: 13.48 seconds\n",
      "Year 1982 - Best Max Depth: 5, Best ACC: 0.0238, Time: 12.90 seconds\n",
      "Year 1983 - Best Max Depth: 5, Best ACC: 0.0302, Time: 12.71 seconds\n",
      "Year 1984 - Best Max Depth: 5, Best ACC: 0.0327, Time: 12.06 seconds\n",
      "Year 1985 - Best Max Depth: 10, Best ACC: 0.0422, Time: 14.87 seconds\n",
      "Year 1986 - Best Max Depth: 10, Best ACC: 0.043, Time: 18.68 seconds\n",
      "Year 1987 - Best Max Depth: 10, Best ACC: 0.0406, Time: 22.30 seconds\n",
      "Year 1988 - Best Max Depth: 10, Best ACC: 0.0428, Time: 26.21 seconds\n",
      "Year 1989 - Best Max Depth: 10, Best ACC: 0.0499, Time: 28.40 seconds\n",
      "Year 1990 - Best Max Depth: 10, Best ACC: 0.0497, Time: 29.75 seconds\n",
      "Year 1991 - Best Max Depth: 10, Best ACC: 0.0492, Time: 31.44 seconds\n",
      "Year 1992 - Best Max Depth: 10, Best ACC: 0.047, Time: 32.34 seconds\n",
      "Year 1993 - Best Max Depth: 10, Best ACC: 0.0441, Time: 32.10 seconds\n",
      "Year 1994 - Best Max Depth: 10, Best ACC: 0.0407, Time: 31.39 seconds\n",
      "Year 1995 - Best Max Depth: 10, Best ACC: 0.0415, Time: 31.27 seconds\n",
      "Year 1996 - Best Max Depth: 10, Best ACC: 0.0361, Time: 31.74 seconds\n",
      "Year 1997 - Best Max Depth: 10, Best ACC: 0.0319, Time: 33.00 seconds\n",
      "Year 1998 - Best Max Depth: 10, Best ACC: 0.0258, Time: 34.43 seconds\n",
      "Year 1999 - Best Max Depth: 10, Best ACC: 0.0226, Time: 35.15 seconds\n",
      "Year 2000 - Best Max Depth: 10, Best ACC: 0.0215, Time: 37.10 seconds\n",
      "Year 2001 - Best Max Depth: 10, Best ACC: 0.0196, Time: 36.98 seconds\n",
      "Year 2002 - Best Max Depth: 5, Best ACC: 0.0101, Time: 36.03 seconds\n",
      "Year 2003 - Best Max Depth: 5, Best ACC: 0.0087, Time: 34.41 seconds\n",
      "Year 2004 - Best Max Depth: 5, Best ACC: 0.0069, Time: 32.28 seconds\n",
      "Year 2005 - Best Max Depth: 5, Best ACC: 0.0057, Time: 29.78 seconds\n",
      "Year 2006 - Best Max Depth: 10, Best ACC: 0.0048, Time: 29.39 seconds\n",
      "Year 2007 - Best Max Depth: 5, Best ACC: 0.0051, Time: 26.56 seconds\n",
      "Year 2008 - Best Max Depth: 5, Best ACC: 0.005, Time: 25.57 seconds\n",
      "Year 2009 - Best Max Depth: 5, Best ACC: 0.0044, Time: 24.48 seconds\n",
      "Year 2010 - Best Max Depth: 5, Best ACC: 0.0045, Time: 25.59 seconds\n",
      "Year 2011 - Best Max Depth: 5, Best ACC: 0.0046, Time: 25.28 seconds\n",
      "Year 2012 - Best Max Depth: 5, Best ACC: 0.0042, Time: 23.75 seconds\n",
      "Year 2013 - Best Max Depth: 5, Best ACC: 0.0041, Time: 23.19 seconds\n",
      "Year 2014 - Best Max Depth: 5, Best ACC: 0.0035, Time: 19.51 seconds\n",
      "Year 2015 - Best Max Depth: 10, Best ACC: 0.0032, Time: 19.02 seconds\n",
      "Year 2016 - Best Max Depth: 5, Best ACC: 0.0034, Time: 17.58 seconds\n",
      "Year 2017 - Best Max Depth: 5, Best ACC: 0.0031, Time: 18.29 seconds\n",
      "Year 2018 - Best Max Depth: 5, Best ACC: 0.0061, Time: 18.35 seconds\n",
      "Year 2019 - Best Max Depth: 5, Best ACC: 0.0041, Time: 18.38 seconds\n",
      "Year 2020 - Best Max Depth: 5, Best ACC: 0.0027, Time: 16.92 seconds\n",
      "Year 2021 - Best Max Depth: 5, Best ACC: 0.0022, Time: 17.22 seconds\n",
      "Year 2022 - Best Max Depth: 5, Best ACC: 0.0023, Time: 17.20 seconds\n",
      "Total time: 1118.17 seconds\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# DECISION TREE CLASSIFICATION MODEL\n",
    "############################################\n",
    "\n",
    "model_name = 'DT_class_roll5_MSE'\n",
    "start_time2 = time.time()  # Start timing\n",
    "\n",
    "# Predefined set of max_depth values for hyperparameter tuning\n",
    "HP1 = [3, 5, 10, 15, 25, None] # max_depth\n",
    "\n",
    "# Update the column name for storing Decision Tree regression predictions\n",
    "df[model_name] = np.nan\n",
    "\n",
    "# Ensure the new column is in the prediction_cols list\n",
    "if model_name not in prediction_cols:\n",
    "    prediction_cols.append(model_name)\n",
    "\n",
    "start_modeling_year = df['year'].min() + 6\n",
    "\n",
    "for year in range(start_modeling_year, df['year'].max() + 1):\n",
    "    start_time = time.time()  # Timing each iteration\n",
    "    \n",
    "    train_start_year = max(year - rolling_window, df['year'].min())\n",
    "    train_data = df[(df['year'] >= train_start_year) & (df['year'] < year)]\n",
    "    \n",
    "    tuning_data = train_data[train_data['year'] == year - 1]\n",
    "    actual_train_data = train_data[train_data['year'] < year - 1]\n",
    "    \n",
    "    X_train = actual_train_data[X_col]\n",
    "    y_train = actual_train_data['y']\n",
    "    \n",
    "    X_tune = tuning_data[X_col]\n",
    "    y_tune = tuning_data['y']\n",
    "    \n",
    "    best_HP1 = None\n",
    "    best_mse = np.inf\n",
    "    \n",
    "    # Hyperparameter tuning for max_depth\n",
    "    for hp1 in HP1:\n",
    "        model = DecisionTreeClassifier(max_depth=hp1)\n",
    "        model.fit(X_train, y_train)\n",
    "        probabilities = model.predict_proba(X_tune)[:, 1]  # Get probabilities of the positive class\n",
    "        mse = mean_squared_error(y_tune, probabilities)  # Calculate MSE\n",
    "        \n",
    "        if mse < best_mse:  # Lower MSE is better\n",
    "            best_mse = mse\n",
    "            best_HP1 = hp1\n",
    "    \n",
    "    # Retrain on the entire training window with the best max_depth value\n",
    "    model = DecisionTreeClassifier(max_depth=best_HP1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict for the next year\n",
    "    next_year_data = df[df['year'] == year]\n",
    "    X_next_year = next_year_data[X_col]\n",
    "    \n",
    "    if not X_next_year.empty:\n",
    "        next_year_predictions = model.predict_proba(X_next_year)[:, 1]\n",
    "        df.loc[df['year'] == year, model_name] = next_year_predictions\n",
    "    \n",
    "    end_time = time.time()\n",
    "    iteration_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Year {year} - Best Max Depth: {best_HP1}, Best ACC: {round(best_mse,4)}, Time: {iteration_time:.2f} seconds\")\n",
    "\n",
    "end_time2 = time.time()  # End timing\n",
    "print(f\"Total time: {end_time2 - start_time2:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04d1162e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T15:05:47.912868Z",
     "iopub.status.busy": "2024-02-29T15:05:47.911520Z",
     "iopub.status.idle": "2024-02-29T19:14:13.858652Z",
     "shell.execute_reply": "2024-02-29T19:14:13.855559Z"
    },
    "papermill": {
     "duration": 14906.033197,
     "end_time": "2024-02-29T19:14:13.904617",
     "exception": false,
     "start_time": "2024-02-29T15:05:47.871420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1976 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.06, Time: 113.43 seconds\n",
      "Year 1977 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.04, Time: 156.64 seconds\n",
      "Year 1978 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.04, Time: 185.41 seconds\n",
      "Year 1979 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.03, Time: 197.16 seconds\n",
      "Year 1980 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.03, Time: 190.27 seconds\n",
      "Year 1981 - Best n_estimators: 50, Best max_depth: None, Best ACC: 0.03, Time: 171.29 seconds\n",
      "Year 1982 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.03, Time: 184.45 seconds\n",
      "Year 1983 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.04, Time: 175.47 seconds\n",
      "Year 1984 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.04, Time: 174.30 seconds\n",
      "Year 1985 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.05, Time: 206.89 seconds\n",
      "Year 1986 - Best n_estimators: 100, Best max_depth: None, Best ACC: 0.05, Time: 233.10 seconds\n",
      "Year 1987 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.05, Time: 303.73 seconds\n",
      "Year 1988 - Best n_estimators: 50, Best max_depth: None, Best ACC: 0.05, Time: 312.86 seconds\n",
      "Year 1989 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.06, Time: 366.59 seconds\n",
      "Year 1990 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.05, Time: 380.75 seconds\n",
      "Year 1991 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.05, Time: 395.38 seconds\n",
      "Year 1992 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.06, Time: 418.67 seconds\n",
      "Year 1993 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.05, Time: 421.02 seconds\n",
      "Year 1994 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.05, Time: 414.83 seconds\n",
      "Year 1995 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.04, Time: 421.93 seconds\n",
      "Year 1996 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.04, Time: 433.13 seconds\n",
      "Year 1997 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.04, Time: 453.00 seconds\n",
      "Year 1998 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.04, Time: 481.43 seconds\n",
      "Year 1999 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.03, Time: 501.16 seconds\n",
      "Year 2000 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.03, Time: 509.87 seconds\n",
      "Year 2001 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.03, Time: 498.16 seconds\n",
      "Year 2002 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.02, Time: 501.21 seconds\n",
      "Year 2003 - Best n_estimators: 50, Best max_depth: None, Best ACC: 0.02, Time: 428.20 seconds\n",
      "Year 2004 - Best n_estimators: 50, Best max_depth: None, Best ACC: 0.01, Time: 409.76 seconds\n",
      "Year 2005 - Best n_estimators: 50, Best max_depth: None, Best ACC: 0.01, Time: 386.56 seconds\n",
      "Year 2006 - Best n_estimators: 50, Best max_depth: None, Best ACC: 0.01, Time: 354.37 seconds\n",
      "Year 2007 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.01, Time: 377.34 seconds\n",
      "Year 2008 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.01, Time: 345.93 seconds\n",
      "Year 2009 - Best n_estimators: 50, Best max_depth: None, Best ACC: 0.02, Time: 306.72 seconds\n",
      "Year 2010 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.03, Time: 335.77 seconds\n",
      "Year 2011 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.01, Time: 330.04 seconds\n",
      "Year 2012 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.01, Time: 308.73 seconds\n",
      "Year 2013 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.01, Time: 290.75 seconds\n",
      "Year 2014 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.01, Time: 279.58 seconds\n",
      "Year 2015 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.01, Time: 267.09 seconds\n",
      "Year 2016 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.01, Time: 262.20 seconds\n",
      "Year 2017 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.01, Time: 254.93 seconds\n",
      "Year 2018 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.01, Time: 258.07 seconds\n",
      "Year 2019 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.01, Time: 250.88 seconds\n",
      "Year 2020 - Best n_estimators: 50, Best max_depth: None, Best ACC: 0.01, Time: 222.35 seconds\n",
      "Year 2021 - Best n_estimators: 50, Best max_depth: None, Best ACC: 0.01, Time: 215.46 seconds\n",
      "Year 2022 - Best n_estimators: 100, Best max_depth: None, Best ACC: 0.01, Time: 219.06 seconds\n",
      "Total time: 14905.92 seconds\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# RF CLASSIFICATION MODEL\n",
    "############################################\n",
    "\n",
    "model_name = 'RF_class_roll5_MSE'\n",
    "start_time2 = time.time()\n",
    "\n",
    "\n",
    "# Predefined set of values for hyperparameter tuning\n",
    "HP1 = [10, 50, 100, 200]  # Possible values for n_estimators\n",
    "HP2 = [5, 10, 15, None]  # Possible values for max_depth\n",
    "\n",
    "# Update the column name for storing Decision Tree regression predictions\n",
    "df[model_name] = np.nan\n",
    "\n",
    "# Ensure the new column is in the prediction_cols list\n",
    "if model_name not in prediction_cols:\n",
    "    prediction_cols.append(model_name)\n",
    "\n",
    "start_modeling_year = df['year'].min() + 6\n",
    "\n",
    "for year in range(start_modeling_year, df['year'].max() + 1):\n",
    "    start_time = time.time()  # Timing each iteration\n",
    "    \n",
    "    train_start_year = max(year - rolling_window, df['year'].min())\n",
    "    train_data = df[(df['year'] >= train_start_year) & (df['year'] < year)]\n",
    "    \n",
    "    tuning_data = train_data[train_data['year'] == year - 1]\n",
    "    actual_train_data = train_data[train_data['year'] < year - 1]\n",
    "    \n",
    "    X_train = actual_train_data[X_col]\n",
    "    y_train = actual_train_data['y']\n",
    "    \n",
    "    X_tune = tuning_data[X_col]\n",
    "    y_tune = tuning_data['y']\n",
    "    \n",
    "    best_HP1 = None\n",
    "    best_HP2 = None\n",
    "    best_mse = np.inf\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    for hp1 in HP1:\n",
    "        for hp2 in HP2:\n",
    "            model = RandomForestClassifier(n_estimators=hp1, max_depth=hp2, random_state=42, n_jobs=-1)\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict_proba(X_tune)[:, 1]  # Get probabilities of the positive class\n",
    "            mse = mean_squared_error(y_tune, predictions)  # Calculate MSE\n",
    "            \n",
    "            # Lower MSE is better, so we invert the logic used for accuracy\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_HP1 = hp1\n",
    "                best_HP2 = hp2\n",
    "    \n",
    "    # Retrain on the entire training window with the best max_depth value\n",
    "    model = model = RandomForestClassifier(n_estimators=best_HP1, max_depth=best_HP2, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict for the next year\n",
    "    next_year_data = df[df['year'] == year]\n",
    "    X_next_year = next_year_data[X_col]\n",
    "    \n",
    "    if not X_next_year.empty:\n",
    "        next_year_predictions = model.predict_proba(X_next_year)[:, 1]\n",
    "        df.loc[df['year'] == year, model_name] = next_year_predictions\n",
    "    \n",
    "    end_time = time.time()\n",
    "    iteration_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Year {year} - Best n_estimators: {best_HP1}, Best max_depth: {best_HP2 if best_HP2 is not None else 'None'}, Best ACC: {round(best_mse, 2)}, Time: {iteration_time:.2f} seconds\")\n",
    "\n",
    "end_time2 = time.time()\n",
    "print(f\"Total time: {end_time2 - start_time2:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c9b792",
   "metadata": {
    "papermill": {
     "duration": 0.042948,
     "end_time": "2024-02-29T19:14:13.991295",
     "exception": false,
     "start_time": "2024-02-29T19:14:13.948347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Forming Portfolios, Value-weighted portfolio returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94aac5f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T19:14:14.084152Z",
     "iopub.status.busy": "2024-02-29T19:14:14.083575Z",
     "iopub.status.idle": "2024-02-29T19:14:14.155440Z",
     "shell.execute_reply": "2024-02-29T19:14:14.154055Z"
    },
    "papermill": {
     "duration": 0.12498,
     "end_time": "2024-02-29T19:14:14.159802",
     "exception": false,
     "start_time": "2024-02-29T19:14:14.034822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>y</th>\n",
       "      <th>RET</th>\n",
       "      <th>LME</th>\n",
       "      <th>ME</th>\n",
       "      <th>bull_D</th>\n",
       "      <th>bear_D</th>\n",
       "      <th>bull_W</th>\n",
       "      <th>bear_W</th>\n",
       "      <th>bull_M</th>\n",
       "      <th>bear_M</th>\n",
       "      <th>SPREAD_L</th>\n",
       "      <th>LTURNOVER</th>\n",
       "      <th>IVOL</th>\n",
       "      <th>IVOL2</th>\n",
       "      <th>IVOL3</th>\n",
       "      <th>STR</th>\n",
       "      <th>LTR</th>\n",
       "      <th>IMOM</th>\n",
       "      <th>MOM</th>\n",
       "      <th>PCTHIGH</th>\n",
       "      <th>MVOL</th>\n",
       "      <th>MVOL2</th>\n",
       "      <th>MVOL3</th>\n",
       "      <th>LMKT</th>\n",
       "      <th>LMKT2</th>\n",
       "      <th>LMKT3</th>\n",
       "      <th>MMOM</th>\n",
       "      <th>MIMOM</th>\n",
       "      <th>MLTR</th>\n",
       "      <th>release_L</th>\n",
       "      <th>LAT</th>\n",
       "      <th>DPI2A_L</th>\n",
       "      <th>CTO_L</th>\n",
       "      <th>D2A_L</th>\n",
       "      <th>NOA_L</th>\n",
       "      <th>OL_L</th>\n",
       "      <th>PCM_L</th>\n",
       "      <th>FC2Y_L</th>\n",
       "      <th>INVEST_L</th>\n",
       "      <th>RNA_L</th>\n",
       "      <th>S2E_L</th>\n",
       "      <th>PROF_L</th>\n",
       "      <th>PM_L</th>\n",
       "      <th>ATO_L</th>\n",
       "      <th>ROA_L</th>\n",
       "      <th>FCF_L</th>\n",
       "      <th>A2ME_L</th>\n",
       "      <th>B2ME_L</th>\n",
       "      <th>S2P_L</th>\n",
       "      <th>ROE_L</th>\n",
       "      <th>LEV_L</th>\n",
       "      <th>TQ_L</th>\n",
       "      <th>year</th>\n",
       "      <th>base_ols_default</th>\n",
       "      <th>ols_default</th>\n",
       "      <th>ridge_clas_roll5_MSE</th>\n",
       "      <th>DT_class_roll5_MSE</th>\n",
       "      <th>RF_class_roll5_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31464</td>\n",
       "      <td>1970-04-30</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.102941</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>37149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.039638</td>\n",
       "      <td>0.731272</td>\n",
       "      <td>0.612170</td>\n",
       "      <td>0.670081</td>\n",
       "      <td>0.413984</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>0.010420</td>\n",
       "      <td>0.564331</td>\n",
       "      <td>0.723312</td>\n",
       "      <td>0.385732</td>\n",
       "      <td>0.408401</td>\n",
       "      <td>0.496787</td>\n",
       "      <td>0.647683</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.00062</td>\n",
       "      <td>0.907359</td>\n",
       "      <td>0.105362</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.261588</td>\n",
       "      <td>0.217478</td>\n",
       "      <td>0.304686</td>\n",
       "      <td>0.956350</td>\n",
       "      <td>0.008189</td>\n",
       "      <td>0.785605</td>\n",
       "      <td>0.141009</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.797682</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.522705</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31464</td>\n",
       "      <td>1970-05-31</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.065574</td>\n",
       "      <td>37149.0</td>\n",
       "      <td>34713.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.035635</td>\n",
       "      <td>0.722584</td>\n",
       "      <td>0.625955</td>\n",
       "      <td>0.672735</td>\n",
       "      <td>0.400651</td>\n",
       "      <td>0.017869</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>0.309299</td>\n",
       "      <td>0.564331</td>\n",
       "      <td>0.723312</td>\n",
       "      <td>0.385646</td>\n",
       "      <td>0.535558</td>\n",
       "      <td>0.630483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.00062</td>\n",
       "      <td>0.907359</td>\n",
       "      <td>0.105362</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.261588</td>\n",
       "      <td>0.217478</td>\n",
       "      <td>0.304686</td>\n",
       "      <td>0.956350</td>\n",
       "      <td>0.008189</td>\n",
       "      <td>0.785605</td>\n",
       "      <td>0.141009</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.797682</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.522707</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31464</td>\n",
       "      <td>1970-06-30</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.143860</td>\n",
       "      <td>34713.0</td>\n",
       "      <td>29232.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.006530</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.037131</td>\n",
       "      <td>0.721443</td>\n",
       "      <td>0.622612</td>\n",
       "      <td>0.670797</td>\n",
       "      <td>0.455396</td>\n",
       "      <td>0.127382</td>\n",
       "      <td>0.017869</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.414013</td>\n",
       "      <td>0.309299</td>\n",
       "      <td>0.564331</td>\n",
       "      <td>0.279599</td>\n",
       "      <td>0.494936</td>\n",
       "      <td>0.666119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.00062</td>\n",
       "      <td>0.907359</td>\n",
       "      <td>0.105362</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.261588</td>\n",
       "      <td>0.217478</td>\n",
       "      <td>0.304686</td>\n",
       "      <td>0.956350</td>\n",
       "      <td>0.008189</td>\n",
       "      <td>0.785605</td>\n",
       "      <td>0.141009</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.797682</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.522708</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31464</td>\n",
       "      <td>1970-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>29232.0</td>\n",
       "      <td>25578.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.033998</td>\n",
       "      <td>0.698329</td>\n",
       "      <td>0.624735</td>\n",
       "      <td>0.678001</td>\n",
       "      <td>0.447986</td>\n",
       "      <td>0.035887</td>\n",
       "      <td>0.127382</td>\n",
       "      <td>0.017869</td>\n",
       "      <td>0.444076</td>\n",
       "      <td>0.414013</td>\n",
       "      <td>0.309299</td>\n",
       "      <td>0.282368</td>\n",
       "      <td>0.548597</td>\n",
       "      <td>0.589858</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.00062</td>\n",
       "      <td>0.907347</td>\n",
       "      <td>0.105364</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.261588</td>\n",
       "      <td>0.217477</td>\n",
       "      <td>0.304686</td>\n",
       "      <td>0.956351</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.785544</td>\n",
       "      <td>0.140986</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.797682</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>0.522684</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31464</td>\n",
       "      <td>1970-08-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>25578.0</td>\n",
       "      <td>26796.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003877</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.034753</td>\n",
       "      <td>0.687449</td>\n",
       "      <td>0.638067</td>\n",
       "      <td>0.679698</td>\n",
       "      <td>0.391849</td>\n",
       "      <td>0.023573</td>\n",
       "      <td>0.035887</td>\n",
       "      <td>0.127382</td>\n",
       "      <td>0.766624</td>\n",
       "      <td>0.444076</td>\n",
       "      <td>0.414013</td>\n",
       "      <td>0.294738</td>\n",
       "      <td>0.536452</td>\n",
       "      <td>0.498298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.00062</td>\n",
       "      <td>0.907347</td>\n",
       "      <td>0.105364</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.261588</td>\n",
       "      <td>0.217477</td>\n",
       "      <td>0.304686</td>\n",
       "      <td>0.956351</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.785544</td>\n",
       "      <td>0.140986</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.797682</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>0.522684</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PERMNO       date  y       RET      LME       ME  bull_D    bear_D  bull_W  \\\n",
       "0   31464 1970-04-30  0 -0.102941  41412.0  37149.0     0.0  0.000000     0.0   \n",
       "1   31464 1970-05-31  0 -0.065574  37149.0  34713.0     0.0  0.000000     0.0   \n",
       "2   31464 1970-06-30  0 -0.143860  34713.0  29232.0     0.0  0.000000     0.0   \n",
       "3   31464 1970-07-31  0 -0.125000  29232.0  25578.0     0.0  0.083333     0.0   \n",
       "4   31464 1970-08-31  1  0.047619  25578.0  26796.0     0.0  0.000000     0.0   \n",
       "\n",
       "     bear_W  bull_M    bear_M  SPREAD_L  LTURNOVER      IVOL     IVOL2  \\\n",
       "0  0.166667     0.0  0.416667  0.003421   0.000006  0.000046  0.000034   \n",
       "1  0.000000     0.0  0.500000  0.004576   0.000006  0.000013  0.000046   \n",
       "2  0.250000     0.0  0.583333  0.006530   0.000008  0.000062  0.000013   \n",
       "3  0.000000     0.0  0.666667  0.004847   0.000004  0.000020  0.000062   \n",
       "4  0.000000     0.0  0.000000  0.003877   0.000005  0.000047  0.000020   \n",
       "\n",
       "      IVOL3       STR       LTR      IMOM       MOM   PCTHIGH      MVOL  \\\n",
       "0  0.000047  0.039638  0.731272  0.612170  0.670081  0.413984  0.012852   \n",
       "1  0.000034  0.035635  0.722584  0.625955  0.672735  0.400651  0.017869   \n",
       "2  0.000046  0.037131  0.721443  0.622612  0.670797  0.455396  0.127382   \n",
       "3  0.000013  0.033998  0.698329  0.624735  0.678001  0.447986  0.035887   \n",
       "4  0.000062  0.034753  0.687449  0.638067  0.679698  0.391849  0.023573   \n",
       "\n",
       "      MVOL2     MVOL3      LMKT     LMKT2     LMKT3      MMOM     MIMOM  \\\n",
       "0  0.012583  0.010420  0.564331  0.723312  0.385732  0.408401  0.496787   \n",
       "1  0.012852  0.012583  0.309299  0.564331  0.723312  0.385646  0.535558   \n",
       "2  0.017869  0.012852  0.414013  0.309299  0.564331  0.279599  0.494936   \n",
       "3  0.127382  0.017869  0.444076  0.414013  0.309299  0.282368  0.548597   \n",
       "4  0.035887  0.127382  0.766624  0.444076  0.414013  0.294738  0.536452   \n",
       "\n",
       "       MLTR  release_L       LAT   DPI2A_L     CTO_L     D2A_L     NOA_L  \\\n",
       "0  0.647683        1.0  0.000119  0.006682  0.000433  0.000149  0.000386   \n",
       "1  0.630483        0.0  0.000119  0.006682  0.000433  0.000149  0.000386   \n",
       "2  0.666119        0.0  0.000119  0.006682  0.000433  0.000149  0.000386   \n",
       "3  0.589858        1.0  0.000119  0.006682  0.000424  0.000149  0.000386   \n",
       "4  0.498298        0.0  0.000119  0.006682  0.000424  0.000149  0.000386   \n",
       "\n",
       "      OL_L     PCM_L    FC2Y_L  INVEST_L     RNA_L     S2E_L    PROF_L  \\\n",
       "0  0.00062  0.907359  0.105362  0.000386  0.261588  0.217478  0.304686   \n",
       "1  0.00062  0.907359  0.105362  0.000386  0.261588  0.217478  0.304686   \n",
       "2  0.00062  0.907359  0.105362  0.000386  0.261588  0.217478  0.304686   \n",
       "3  0.00062  0.907347  0.105364  0.000386  0.261588  0.217477  0.304686   \n",
       "4  0.00062  0.907347  0.105364  0.000386  0.261588  0.217477  0.304686   \n",
       "\n",
       "       PM_L     ATO_L     ROA_L     FCF_L    A2ME_L    B2ME_L     S2P_L  \\\n",
       "0  0.956350  0.008189  0.785605  0.141009  0.001061  0.797682  0.010881   \n",
       "1  0.956350  0.008189  0.785605  0.141009  0.001061  0.797682  0.010881   \n",
       "2  0.956350  0.008189  0.785605  0.141009  0.001061  0.797682  0.010881   \n",
       "3  0.956351  0.008181  0.785544  0.140986  0.001061  0.797682  0.010711   \n",
       "4  0.956351  0.008181  0.785544  0.140986  0.001061  0.797682  0.010711   \n",
       "\n",
       "      ROE_L     LEV_L      TQ_L  year  base_ols_default  ols_default  \\\n",
       "0  0.522705  0.000224  0.000016  1970               NaN          NaN   \n",
       "1  0.522707  0.000250  0.000014  1970               NaN          NaN   \n",
       "2  0.522708  0.000267  0.000013  1970               NaN          NaN   \n",
       "3  0.522684  0.000316  0.000011  1970               NaN          NaN   \n",
       "4  0.522684  0.000361  0.000010  1970               NaN          NaN   \n",
       "\n",
       "   ridge_clas_roll5_MSE  DT_class_roll5_MSE  RF_class_roll5_MSE  \n",
       "0                   NaN                 NaN                 NaN  \n",
       "1                   NaN                 NaN                 NaN  \n",
       "2                   NaN                 NaN                 NaN  \n",
       "3                   NaN                 NaN                 NaN  \n",
       "4                   NaN                 NaN                 NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf40a4c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T19:14:14.249832Z",
     "iopub.status.busy": "2024-02-29T19:14:14.249362Z",
     "iopub.status.idle": "2024-02-29T19:14:14.256595Z",
     "shell.execute_reply": "2024-02-29T19:14:14.255619Z"
    },
    "papermill": {
     "duration": 0.054576,
     "end_time": "2024-02-29T19:14:14.258976",
     "exception": false,
     "start_time": "2024-02-29T19:14:14.204400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_ols_default',\n",
       " 'ols_default',\n",
       " 'ridge_clas_roll5_MSE',\n",
       " 'DT_class_roll5_MSE',\n",
       " 'RF_class_roll5_MSE']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_cols\n",
    "# prediction_cols = ['logit_default','OLS_default','logit_roll6','DT_reg_roll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55e137ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T19:14:14.349321Z",
     "iopub.status.busy": "2024-02-29T19:14:14.348924Z",
     "iopub.status.idle": "2024-02-29T19:14:14.964413Z",
     "shell.execute_reply": "2024-02-29T19:14:14.963125Z"
    },
    "papermill": {
     "duration": 0.663445,
     "end_time": "2024-02-29T19:14:14.966820",
     "exception": false,
     "start_time": "2024-02-29T19:14:14.303375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>RET</th>\n",
       "      <th>ME</th>\n",
       "      <th>y</th>\n",
       "      <th>base_ols_default</th>\n",
       "      <th>ols_default</th>\n",
       "      <th>ridge_clas_roll5_MSE</th>\n",
       "      <th>DT_class_roll5_MSE</th>\n",
       "      <th>RF_class_roll5_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80751</th>\n",
       "      <td>1976-01-31</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>99391.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429566</td>\n",
       "      <td>0.541998</td>\n",
       "      <td>0.874848</td>\n",
       "      <td>0.846724</td>\n",
       "      <td>0.615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80752</th>\n",
       "      <td>1976-01-31</td>\n",
       "      <td>0.266187</td>\n",
       "      <td>87802.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.651250</td>\n",
       "      <td>0.657648</td>\n",
       "      <td>0.966976</td>\n",
       "      <td>0.954098</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80753</th>\n",
       "      <td>1976-01-31</td>\n",
       "      <td>0.124031</td>\n",
       "      <td>113172.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608244</td>\n",
       "      <td>0.652779</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80754</th>\n",
       "      <td>1976-01-31</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>12801.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1.688311</td>\n",
       "      <td>1.560148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80755</th>\n",
       "      <td>1976-01-31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8228.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.429613</td>\n",
       "      <td>0.383483</td>\n",
       "      <td>0.182690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date       RET         ME  y  base_ols_default  ols_default  \\\n",
       "80751 1976-01-31  0.147541   99391.25  1          0.429566     0.541998   \n",
       "80752 1976-01-31  0.266187   87802.00  1          0.651250     0.657648   \n",
       "80753 1976-01-31  0.124031  113172.50  1          0.608244     0.652779   \n",
       "80754 1976-01-31  0.319444   12801.25  1          1.688311     1.560148   \n",
       "80755 1976-01-31  0.000000    8228.50  0          0.429613     0.383483   \n",
       "\n",
       "       ridge_clas_roll5_MSE  DT_class_roll5_MSE  RF_class_roll5_MSE  \n",
       "80751              0.874848            0.846724               0.615  \n",
       "80752              0.966976            0.954098               0.825  \n",
       "80753              0.999998            1.000000               0.945  \n",
       "80754              1.000000            1.000000               0.915  \n",
       "80755              0.182690            0.000000               0.140  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio = df[['date', 'RET', 'ME', 'y'] + prediction_cols].copy()\n",
    "portfolio['date'] = pd.to_datetime(portfolio['date'])\n",
    "\n",
    "# drop rows with missing values\n",
    "portfolio.dropna(inplace=True)\n",
    "\n",
    "portfolio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85f899ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T19:14:15.057462Z",
     "iopub.status.busy": "2024-02-29T19:14:15.056383Z",
     "iopub.status.idle": "2024-02-29T19:14:15.073678Z",
     "shell.execute_reply": "2024-02-29T19:14:15.072506Z"
    },
    "papermill": {
     "duration": 0.065436,
     "end_time": "2024-02-29T19:14:15.076328",
     "exception": false,
     "start_time": "2024-02-29T19:14:15.010892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>RET</th>\n",
       "      <th>ME</th>\n",
       "      <th>y</th>\n",
       "      <th>base_ols_default</th>\n",
       "      <th>ols_default</th>\n",
       "      <th>ridge_clas_roll5_MSE</th>\n",
       "      <th>DT_class_roll5_MSE</th>\n",
       "      <th>RF_class_roll5_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1795158</th>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>-0.211268</td>\n",
       "      <td>3.603768e+05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528958</td>\n",
       "      <td>0.456078</td>\n",
       "      <td>0.042556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795159</th>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>0.020794</td>\n",
       "      <td>9.562860e+05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.819094</td>\n",
       "      <td>0.816904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795160</th>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>0.066548</td>\n",
       "      <td>9.219528e+05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.711270</td>\n",
       "      <td>0.700782</td>\n",
       "      <td>0.968239</td>\n",
       "      <td>0.993929</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795161</th>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>0.087452</td>\n",
       "      <td>1.216028e+05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.849967</td>\n",
       "      <td>0.900600</td>\n",
       "      <td>0.997182</td>\n",
       "      <td>0.993929</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795162</th>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>0.323765</td>\n",
       "      <td>9.311106e+08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.711275</td>\n",
       "      <td>0.814605</td>\n",
       "      <td>0.995536</td>\n",
       "      <td>0.993929</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date       RET            ME  y  base_ols_default  ols_default  \\\n",
       "1795158 2022-07-31 -0.211268  3.603768e+05  0          0.528958     0.456078   \n",
       "1795159 2022-07-31  0.020794  9.562860e+05  1          0.819094     0.816904   \n",
       "1795160 2022-07-31  0.066548  9.219528e+05  1          0.711270     0.700782   \n",
       "1795161 2022-07-31  0.087452  1.216028e+05  1          0.849967     0.900600   \n",
       "1795162 2022-07-31  0.323765  9.311106e+08  1          0.711275     0.814605   \n",
       "\n",
       "         ridge_clas_roll5_MSE  DT_class_roll5_MSE  RF_class_roll5_MSE  \n",
       "1795158              0.042556            0.000000                0.23  \n",
       "1795159              1.000000            1.000000                0.92  \n",
       "1795160              0.968239            0.993929                0.93  \n",
       "1795161              0.997182            0.993929                0.92  \n",
       "1795162              0.995536            0.993929                0.89  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39310538",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T19:14:15.169503Z",
     "iopub.status.busy": "2024-02-29T19:14:15.169104Z",
     "iopub.status.idle": "2024-02-29T19:14:24.256994Z",
     "shell.execute_reply": "2024-02-29T19:14:24.255764Z"
    },
    "papermill": {
     "duration": 9.137829,
     "end_time": "2024-02-29T19:14:24.259470",
     "exception": false,
     "start_time": "2024-02-29T19:14:15.121641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2999037948.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  vwreturns_temp = portfolio.groupby('date').apply(lambda x: np.sum(x['RET'] * x['ME'] * x[position_col]) / np.sum(x['ME'])).reset_index(name=vwret_col)\n",
      "/tmp/ipykernel_18/2999037948.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  vwreturns_temp = portfolio.groupby('date').apply(lambda x: np.sum(x['RET'] * x['ME'] * x[position_col]) / np.sum(x['ME'])).reset_index(name=vwret_col)\n",
      "/tmp/ipykernel_18/2999037948.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  vwreturns_temp = portfolio.groupby('date').apply(lambda x: np.sum(x['RET'] * x['ME'] * x[position_col]) / np.sum(x['ME'])).reset_index(name=vwret_col)\n",
      "/tmp/ipykernel_18/2999037948.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  vwreturns_temp = portfolio.groupby('date').apply(lambda x: np.sum(x['RET'] * x['ME'] * x[position_col]) / np.sum(x['ME'])).reset_index(name=vwret_col)\n",
      "/tmp/ipykernel_18/2999037948.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  vwreturns_temp = portfolio.groupby('date').apply(lambda x: np.sum(x['RET'] * x['ME'] * x[position_col]) / np.sum(x['ME'])).reset_index(name=vwret_col)\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store value-weighted returns for each model\n",
    "vwreturns = pd.DataFrame(portfolio['date'].unique(), columns=['date'])  # Ensures all dates are included\n",
    "\n",
    "for pred_col in prediction_cols:\n",
    "    # Calculate deciles for this prediction\n",
    "    decile_col = f'decile_{pred_col}'\n",
    "    portfolio[decile_col] = portfolio.groupby(['date'])[pred_col].transform(lambda x: pd.qcut(x, 10, labels=False, duplicates='drop'))\n",
    "    \n",
    "    # Determine position based on deciles\n",
    "    position_col = f'position_{pred_col}'\n",
    "    portfolio[position_col] = np.where(portfolio[decile_col] == 9, 1, np.where(portfolio[decile_col] == 0, -1, 0))\n",
    "    \n",
    "    # Calculate the value-weighted return for this prediction\n",
    "    vwret_col = f'vwreturn_{pred_col}'\n",
    "    vwreturns_temp = portfolio.groupby('date').apply(lambda x: np.sum(x['RET'] * x['ME'] * x[position_col]) / np.sum(x['ME'])).reset_index(name=vwret_col)\n",
    "    \n",
    "    # Merge the temporary value-weighted returns with the main vwreturns DataFrame\n",
    "    vwreturns = vwreturns.merge(vwreturns_temp, on='date', how='left')\n",
    "\n",
    "# Ensure the 'date' column is the first column and is sorted\n",
    "vwreturns = vwreturns.sort_values('date').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cf7079b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T19:14:24.352021Z",
     "iopub.status.busy": "2024-02-29T19:14:24.351611Z",
     "iopub.status.idle": "2024-02-29T19:14:24.365202Z",
     "shell.execute_reply": "2024-02-29T19:14:24.364166Z"
    },
    "papermill": {
     "duration": 0.062515,
     "end_time": "2024-02-29T19:14:24.367481",
     "exception": false,
     "start_time": "2024-02-29T19:14:24.304966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>vwreturn_base_ols_default</th>\n",
       "      <th>vwreturn_ols_default</th>\n",
       "      <th>vwreturn_ridge_clas_roll5_MSE</th>\n",
       "      <th>vwreturn_DT_class_roll5_MSE</th>\n",
       "      <th>vwreturn_RF_class_roll5_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1976-01-31</td>\n",
       "      <td>0.039535</td>\n",
       "      <td>0.030443</td>\n",
       "      <td>0.022083</td>\n",
       "      <td>-0.001281</td>\n",
       "      <td>0.023344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1976-02-29</td>\n",
       "      <td>0.022362</td>\n",
       "      <td>0.015261</td>\n",
       "      <td>0.013882</td>\n",
       "      <td>-0.009918</td>\n",
       "      <td>0.019715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1976-03-31</td>\n",
       "      <td>0.011892</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>0.013456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976-04-30</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.026945</td>\n",
       "      <td>0.010274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1976-05-31</td>\n",
       "      <td>0.019215</td>\n",
       "      <td>0.020038</td>\n",
       "      <td>0.016704</td>\n",
       "      <td>0.025408</td>\n",
       "      <td>0.016797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  vwreturn_base_ols_default  vwreturn_ols_default  \\\n",
       "0 1976-01-31                   0.039535              0.030443   \n",
       "1 1976-02-29                   0.022362              0.015261   \n",
       "2 1976-03-31                   0.011892              0.010497   \n",
       "3 1976-04-30                   0.007972              0.010684   \n",
       "4 1976-05-31                   0.019215              0.020038   \n",
       "\n",
       "   vwreturn_ridge_clas_roll5_MSE  vwreturn_DT_class_roll5_MSE  \\\n",
       "0                       0.022083                    -0.001281   \n",
       "1                       0.013882                    -0.009918   \n",
       "2                       0.009977                     0.005947   \n",
       "3                       0.007117                     0.026945   \n",
       "4                       0.016704                     0.025408   \n",
       "\n",
       "   vwreturn_RF_class_roll5_MSE  \n",
       "0                     0.023344  \n",
       "1                     0.019715  \n",
       "2                     0.013456  \n",
       "3                     0.010274  \n",
       "4                     0.016797  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vwreturns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca6349",
   "metadata": {
    "papermill": {
     "duration": 0.04636,
     "end_time": "2024-02-29T19:14:24.460130",
     "exception": false,
     "start_time": "2024-02-29T19:14:24.413770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Compare to market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa04e308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T19:14:24.553507Z",
     "iopub.status.busy": "2024-02-29T19:14:24.553104Z",
     "iopub.status.idle": "2024-02-29T19:14:24.602482Z",
     "shell.execute_reply": "2024-02-29T19:14:24.601358Z"
    },
    "papermill": {
     "duration": 0.099303,
     "end_time": "2024-02-29T19:14:24.605442",
     "exception": false,
     "start_time": "2024-02-29T19:14:24.506139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#market = pd.read_csv('FF3_clean.csv')\n",
    "market = pd.read_csv('/kaggle/input/sign-prediction-datasets/FF3_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9554e8a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T19:14:24.698298Z",
     "iopub.status.busy": "2024-02-29T19:14:24.697899Z",
     "iopub.status.idle": "2024-02-29T19:14:24.713124Z",
     "shell.execute_reply": "2024-02-29T19:14:24.711884Z"
    },
    "papermill": {
     "duration": 0.064146,
     "end_time": "2024-02-29T19:14:24.715495",
     "exception": false,
     "start_time": "2024-02-29T19:14:24.651349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1926-07-31</td>\n",
       "      <td>2.96</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>-2.43</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1926-08-31</td>\n",
       "      <td>2.64</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1926-09-30</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1926-10-31</td>\n",
       "      <td>-3.24</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1926-11-30</td>\n",
       "      <td>2.53</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  Mkt-RF   SMB   HML    RF\n",
       "0  1926-07-31    2.96 -2.56 -2.43  0.22\n",
       "1  1926-08-31    2.64 -1.17  3.82  0.25\n",
       "2  1926-09-30    0.36 -1.40  0.13  0.23\n",
       "3  1926-10-31   -3.24 -0.09  0.70  0.32\n",
       "4  1926-11-30    2.53 -0.10 -0.51  0.31"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9aa71d8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T19:14:24.810813Z",
     "iopub.status.busy": "2024-02-29T19:14:24.809971Z",
     "iopub.status.idle": "2024-02-29T19:14:24.835740Z",
     "shell.execute_reply": "2024-02-29T19:14:24.834424Z"
    },
    "papermill": {
     "duration": 0.077264,
     "end_time": "2024-02-29T19:14:24.838687",
     "exception": false,
     "start_time": "2024-02-29T19:14:24.761423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a new 'Mkt' which is a sum of Mkt-RF and RF\n",
    "market['Mkt'] = market['Mkt-RF'] + market['RF']\n",
    "\n",
    "# divide all columns by 100 except 'date'\n",
    "market.iloc[:, 1:] = market.iloc[:, 1:] / 100\n",
    "\n",
    "#set the 'date' column to datetime format\n",
    "market['date'] = pd.to_datetime(market['date'])\n",
    "\n",
    "# merge the market data (only date and Mkt columns) with the vwreturns DataFrame\n",
    "vwreturns = vwreturns.merge(market[['date', 'Mkt']], on='date', how='left')\n",
    "\n",
    "# transform all columns (except 'date') to a log: log(x+1) and save the result as lvwreturns\n",
    "lvwreturns = vwreturns.copy()\n",
    "lvwreturns.iloc[:, 1:] = np.log(vwreturns.iloc[:, 1:] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4e25fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T19:14:24.933087Z",
     "iopub.status.busy": "2024-02-29T19:14:24.932619Z",
     "iopub.status.idle": "2024-02-29T19:14:24.947266Z",
     "shell.execute_reply": "2024-02-29T19:14:24.946414Z"
    },
    "papermill": {
     "duration": 0.064086,
     "end_time": "2024-02-29T19:14:24.949527",
     "exception": false,
     "start_time": "2024-02-29T19:14:24.885441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>vwreturn_base_ols_default</th>\n",
       "      <th>vwreturn_ols_default</th>\n",
       "      <th>vwreturn_ridge_clas_roll5_MSE</th>\n",
       "      <th>vwreturn_DT_class_roll5_MSE</th>\n",
       "      <th>vwreturn_RF_class_roll5_MSE</th>\n",
       "      <th>Mkt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1976-01-31</td>\n",
       "      <td>0.039535</td>\n",
       "      <td>0.030443</td>\n",
       "      <td>0.022083</td>\n",
       "      <td>-0.001281</td>\n",
       "      <td>0.023344</td>\n",
       "      <td>0.1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1976-02-29</td>\n",
       "      <td>0.022362</td>\n",
       "      <td>0.015261</td>\n",
       "      <td>0.013882</td>\n",
       "      <td>-0.009918</td>\n",
       "      <td>0.019715</td>\n",
       "      <td>0.0066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1976-03-31</td>\n",
       "      <td>0.011892</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>0.013456</td>\n",
       "      <td>0.0272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976-04-30</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.026945</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>-0.0107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1976-05-31</td>\n",
       "      <td>0.019215</td>\n",
       "      <td>0.020038</td>\n",
       "      <td>0.016704</td>\n",
       "      <td>0.025408</td>\n",
       "      <td>0.016797</td>\n",
       "      <td>-0.0097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  vwreturn_base_ols_default  vwreturn_ols_default  \\\n",
       "0 1976-01-31                   0.039535              0.030443   \n",
       "1 1976-02-29                   0.022362              0.015261   \n",
       "2 1976-03-31                   0.011892              0.010497   \n",
       "3 1976-04-30                   0.007972              0.010684   \n",
       "4 1976-05-31                   0.019215              0.020038   \n",
       "\n",
       "   vwreturn_ridge_clas_roll5_MSE  vwreturn_DT_class_roll5_MSE  \\\n",
       "0                       0.022083                    -0.001281   \n",
       "1                       0.013882                    -0.009918   \n",
       "2                       0.009977                     0.005947   \n",
       "3                       0.007117                     0.026945   \n",
       "4                       0.016704                     0.025408   \n",
       "\n",
       "   vwreturn_RF_class_roll5_MSE     Mkt  \n",
       "0                     0.023344  0.1263  \n",
       "1                     0.019715  0.0066  \n",
       "2                     0.013456  0.0272  \n",
       "3                     0.010274 -0.0107  \n",
       "4                     0.016797 -0.0097  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vwreturns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab71712e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T19:14:25.045119Z",
     "iopub.status.busy": "2024-02-29T19:14:25.044688Z",
     "iopub.status.idle": "2024-02-29T19:14:25.059148Z",
     "shell.execute_reply": "2024-02-29T19:14:25.058222Z"
    },
    "papermill": {
     "duration": 0.064914,
     "end_time": "2024-02-29T19:14:25.061317",
     "exception": false,
     "start_time": "2024-02-29T19:14:24.996403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>vwreturn_base_ols_default</th>\n",
       "      <th>vwreturn_ols_default</th>\n",
       "      <th>vwreturn_ridge_clas_roll5_MSE</th>\n",
       "      <th>vwreturn_DT_class_roll5_MSE</th>\n",
       "      <th>vwreturn_RF_class_roll5_MSE</th>\n",
       "      <th>Mkt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1976-01-31</td>\n",
       "      <td>0.038773</td>\n",
       "      <td>0.029989</td>\n",
       "      <td>0.021843</td>\n",
       "      <td>-0.001282</td>\n",
       "      <td>0.023075</td>\n",
       "      <td>0.118938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1976-02-29</td>\n",
       "      <td>0.022116</td>\n",
       "      <td>0.015146</td>\n",
       "      <td>0.013786</td>\n",
       "      <td>-0.009967</td>\n",
       "      <td>0.019523</td>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1976-03-31</td>\n",
       "      <td>0.011821</td>\n",
       "      <td>0.010442</td>\n",
       "      <td>0.009928</td>\n",
       "      <td>0.005930</td>\n",
       "      <td>0.013366</td>\n",
       "      <td>0.026837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976-04-30</td>\n",
       "      <td>0.007940</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.026588</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>-0.010758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1976-05-31</td>\n",
       "      <td>0.019032</td>\n",
       "      <td>0.019840</td>\n",
       "      <td>0.016566</td>\n",
       "      <td>0.025091</td>\n",
       "      <td>0.016657</td>\n",
       "      <td>-0.009747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  vwreturn_base_ols_default  vwreturn_ols_default  \\\n",
       "0 1976-01-31                   0.038773              0.029989   \n",
       "1 1976-02-29                   0.022116              0.015146   \n",
       "2 1976-03-31                   0.011821              0.010442   \n",
       "3 1976-04-30                   0.007940              0.010628   \n",
       "4 1976-05-31                   0.019032              0.019840   \n",
       "\n",
       "   vwreturn_ridge_clas_roll5_MSE  vwreturn_DT_class_roll5_MSE  \\\n",
       "0                       0.021843                    -0.001282   \n",
       "1                       0.013786                    -0.009967   \n",
       "2                       0.009928                     0.005930   \n",
       "3                       0.007092                     0.026588   \n",
       "4                       0.016566                     0.025091   \n",
       "\n",
       "   vwreturn_RF_class_roll5_MSE       Mkt  \n",
       "0                     0.023075  0.118938  \n",
       "1                     0.019523  0.006578  \n",
       "2                     0.013366  0.026837  \n",
       "3                     0.010222 -0.010758  \n",
       "4                     0.016657 -0.009747  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvwreturns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "238743e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T19:14:25.155271Z",
     "iopub.status.busy": "2024-02-29T19:14:25.154549Z",
     "iopub.status.idle": "2024-02-29T19:14:25.189003Z",
     "shell.execute_reply": "2024-02-29T19:14:25.187713Z"
    },
    "papermill": {
     "duration": 0.084721,
     "end_time": "2024-02-29T19:14:25.191816",
     "exception": false,
     "start_time": "2024-02-29T19:14:25.107095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>vwreturn_base_ols_default</th>\n",
       "      <th>vwreturn_ols_default</th>\n",
       "      <th>vwreturn_ridge_clas_roll5_MSE</th>\n",
       "      <th>vwreturn_DT_class_roll5_MSE</th>\n",
       "      <th>vwreturn_RF_class_roll5_MSE</th>\n",
       "      <th>Mkt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>559</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1999-05-01 04:22:45.295169920</td>\n",
       "      <td>0.016911</td>\n",
       "      <td>0.016571</td>\n",
       "      <td>0.008193</td>\n",
       "      <td>0.022117</td>\n",
       "      <td>0.014239</td>\n",
       "      <td>0.009303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1976-01-31 00:00:00</td>\n",
       "      <td>-0.028077</td>\n",
       "      <td>-0.020252</td>\n",
       "      <td>-0.024542</td>\n",
       "      <td>-0.054603</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>-0.256700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1987-09-15 00:00:00</td>\n",
       "      <td>0.011065</td>\n",
       "      <td>0.010928</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>-0.015672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1999-04-30 00:00:00</td>\n",
       "      <td>0.015014</td>\n",
       "      <td>0.014409</td>\n",
       "      <td>0.006101</td>\n",
       "      <td>0.015474</td>\n",
       "      <td>0.012861</td>\n",
       "      <td>0.013804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2010-12-15 12:00:00</td>\n",
       "      <td>0.020360</td>\n",
       "      <td>0.019833</td>\n",
       "      <td>0.012080</td>\n",
       "      <td>0.029988</td>\n",
       "      <td>0.017341</td>\n",
       "      <td>0.038162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2022-07-31 00:00:00</td>\n",
       "      <td>0.077910</td>\n",
       "      <td>0.077408</td>\n",
       "      <td>0.039721</td>\n",
       "      <td>0.205754</td>\n",
       "      <td>0.066362</td>\n",
       "      <td>0.127953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009251</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.007458</td>\n",
       "      <td>0.023861</td>\n",
       "      <td>0.007490</td>\n",
       "      <td>0.045169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                date  vwreturn_base_ols_default  \\\n",
       "count                            559                 559.000000   \n",
       "mean   1999-05-01 04:22:45.295169920                   0.016911   \n",
       "min              1976-01-31 00:00:00                  -0.028077   \n",
       "25%              1987-09-15 00:00:00                   0.011065   \n",
       "50%              1999-04-30 00:00:00                   0.015014   \n",
       "75%              2010-12-15 12:00:00                   0.020360   \n",
       "max              2022-07-31 00:00:00                   0.077910   \n",
       "std                              NaN                   0.009251   \n",
       "\n",
       "       vwreturn_ols_default  vwreturn_ridge_clas_roll5_MSE  \\\n",
       "count            559.000000                     559.000000   \n",
       "mean               0.016571                       0.008193   \n",
       "min               -0.020252                      -0.024542   \n",
       "25%                0.010928                       0.002257   \n",
       "50%                0.014409                       0.006101   \n",
       "75%                0.019833                       0.012080   \n",
       "max                0.077408                       0.039721   \n",
       "std                0.008660                       0.007458   \n",
       "\n",
       "       vwreturn_DT_class_roll5_MSE  vwreturn_RF_class_roll5_MSE         Mkt  \n",
       "count                   559.000000                   559.000000  559.000000  \n",
       "mean                      0.022117                     0.014239    0.009303  \n",
       "min                      -0.054603                     0.001003   -0.256700  \n",
       "25%                       0.008078                     0.009434   -0.015672  \n",
       "50%                       0.015474                     0.012861    0.013804  \n",
       "75%                       0.029988                     0.017341    0.038162  \n",
       "max                       0.205754                     0.066362    0.127953  \n",
       "std                       0.023861                     0.007490    0.045169  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvwreturns.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e5b1379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T19:14:25.287390Z",
     "iopub.status.busy": "2024-02-29T19:14:25.286556Z",
     "iopub.status.idle": "2024-02-29T19:14:27.095912Z",
     "shell.execute_reply": "2024-02-29T19:14:27.094748Z"
    },
    "papermill": {
     "duration": 1.859927,
     "end_time": "2024-02-29T19:14:27.098818",
     "exception": false,
     "start_time": "2024-02-29T19:14:25.238891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the lvwreturns and portfolio DataFrame to a parquet file into 'outputs' folder\n",
    "\n",
    "# for reproducibility and visualization purposes\n",
    "lvwreturns.to_parquet('fin_lvwreturns_class1.parquet')\n",
    "portfolio.to_parquet('fin_portfolio_class1.parquet')\n",
    "\n",
    "# save vwreturns DataFrame to a .dta file into 'outputs' folder\n",
    "#vwreturns.to_stata('outputs/vwreturns.dta') # for backtasting in R - we need normal returns, not log returns\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4464890,
     "sourceId": 7720907,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20930.171489,
   "end_time": "2024-02-29T19:14:28.459245",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-29T13:25:38.287756",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
