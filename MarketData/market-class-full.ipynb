{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d878d4f",
   "metadata": {
    "papermill": {
     "duration": 0.01188,
     "end_time": "2024-02-29T12:02:54.104978",
     "exception": false,
     "start_time": "2024-02-29T12:02:54.093098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Framework for predictions and portfolio forming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf72baec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T12:02:54.129051Z",
     "iopub.status.busy": "2024-02-29T12:02:54.128403Z",
     "iopub.status.idle": "2024-02-29T12:02:57.402248Z",
     "shell.execute_reply": "2024-02-29T12:02:57.400988Z"
    },
    "papermill": {
     "duration": 3.289314,
     "end_time": "2024-02-29T12:02:57.405101",
     "exception": false,
     "start_time": "2024-02-29T12:02:54.115787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "# import the parquet library\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# import model libraries\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d794144c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T12:02:57.429571Z",
     "iopub.status.busy": "2024-02-29T12:02:57.428697Z",
     "iopub.status.idle": "2024-02-29T12:03:00.293524Z",
     "shell.execute_reply": "2024-02-29T12:03:00.292358Z"
    },
    "papermill": {
     "duration": 2.879578,
     "end_time": "2024-02-29T12:03:00.295921",
     "exception": false,
     "start_time": "2024-02-29T12:02:57.416343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>RET</th>\n",
       "      <th>ME</th>\n",
       "      <th>bull_D</th>\n",
       "      <th>bear_D</th>\n",
       "      <th>bull_W</th>\n",
       "      <th>bear_W</th>\n",
       "      <th>bull_M</th>\n",
       "      <th>bear_M</th>\n",
       "      <th>LMKT</th>\n",
       "      <th>IVOL</th>\n",
       "      <th>y</th>\n",
       "      <th>STR</th>\n",
       "      <th>LTURNOVER</th>\n",
       "      <th>IMOM</th>\n",
       "      <th>MOM</th>\n",
       "      <th>LTR</th>\n",
       "      <th>PCTHIGH</th>\n",
       "      <th>IVOL2</th>\n",
       "      <th>IVOL3</th>\n",
       "      <th>MVOL</th>\n",
       "      <th>MVOL2</th>\n",
       "      <th>MVOL3</th>\n",
       "      <th>LMKT2</th>\n",
       "      <th>LMKT3</th>\n",
       "      <th>MMOM</th>\n",
       "      <th>MIMOM</th>\n",
       "      <th>MLTR</th>\n",
       "      <th>LSPREAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>1987-03-31</td>\n",
       "      <td>-0.384615</td>\n",
       "      <td>973.25000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>-1.089044</td>\n",
       "      <td>-2.079441</td>\n",
       "      <td>-0.297252</td>\n",
       "      <td>0.091549</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.545027</td>\n",
       "      <td>0.771919</td>\n",
       "      <td>0.434190</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>-0.0278</td>\n",
       "      <td>0.186212</td>\n",
       "      <td>0.112764</td>\n",
       "      <td>0.459110</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>1987-04-30</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>912.44134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.384615</td>\n",
       "      <td>0.285384</td>\n",
       "      <td>-1.459321</td>\n",
       "      <td>-2.390877</td>\n",
       "      <td>0.014185</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.672597</td>\n",
       "      <td>0.545027</td>\n",
       "      <td>0.771919</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.179935</td>\n",
       "      <td>-0.025601</td>\n",
       "      <td>0.498953</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>1987-05-31</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>851.59375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.0167</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.256358</td>\n",
       "      <td>-1.633155</td>\n",
       "      <td>-2.772587</td>\n",
       "      <td>-0.089613</td>\n",
       "      <td>0.075378</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>1.565461</td>\n",
       "      <td>0.672597</td>\n",
       "      <td>0.545027</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.208747</td>\n",
       "      <td>0.032263</td>\n",
       "      <td>0.488026</td>\n",
       "      <td>0.133330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001</td>\n",
       "      <td>1987-03-31</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>6317.62500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.074074</td>\n",
       "      <td>0.368315</td>\n",
       "      <td>0.071156</td>\n",
       "      <td>0.140122</td>\n",
       "      <td>0.020203</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.545027</td>\n",
       "      <td>0.771919</td>\n",
       "      <td>0.434190</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>-0.0278</td>\n",
       "      <td>0.186212</td>\n",
       "      <td>0.112764</td>\n",
       "      <td>0.459110</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001</td>\n",
       "      <td>1987-04-30</td>\n",
       "      <td>-0.039216</td>\n",
       "      <td>6069.87500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.217962</td>\n",
       "      <td>0.043187</td>\n",
       "      <td>0.038273</td>\n",
       "      <td>0.045090</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.672597</td>\n",
       "      <td>0.545027</td>\n",
       "      <td>0.771919</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.179935</td>\n",
       "      <td>-0.025601</td>\n",
       "      <td>0.498953</td>\n",
       "      <td>0.078431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PERMNO       date       RET          ME  bull_D  bear_D  bull_W  bear_W  \\\n",
       "0   10000 1987-03-31 -0.384615   973.25000     0.0     0.0     0.0     1.0   \n",
       "1   10000 1987-04-30 -0.062500   912.44134     0.0     0.0     0.0     0.0   \n",
       "2   10000 1987-05-31 -0.066667   851.59375     0.0     0.0     0.0     0.0   \n",
       "3   10001 1987-03-31  0.036800  6317.62500     0.0     0.0     0.0     1.0   \n",
       "4   10001 1987-04-30 -0.039216  6069.87500     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   bull_M  bear_M    LMKT      IVOL  y       STR  LTURNOVER      IMOM  \\\n",
       "0       0       0  0.0482  0.000612  0  0.000000   0.100694 -1.089044   \n",
       "1       0       1  0.0211  0.003465  0 -0.384615   0.285384 -1.459321   \n",
       "2       0       2 -0.0167  0.001893  0 -0.062500   0.256358 -1.633155   \n",
       "3       0       0  0.0482  0.001627  1 -0.074074   0.368315  0.071156   \n",
       "4       0       0  0.0211  0.001597  0  0.036800   0.217962  0.043187   \n",
       "\n",
       "        MOM       LTR   PCTHIGH     IVOL2     IVOL3      MVOL     MVOL2  \\\n",
       "0 -2.079441 -0.297252  0.091549  0.000830  0.002413  0.545027  0.771919   \n",
       "1 -2.390877  0.014185  0.062500  0.000612  0.000830  0.672597  0.545027   \n",
       "2 -2.772587 -0.089613  0.075378  0.003465  0.000612  1.565461  0.672597   \n",
       "3  0.140122  0.020203  0.892857  0.001556  0.001527  0.545027  0.771919   \n",
       "4  0.038273  0.045090  0.910714  0.001627  0.001556  0.672597  0.545027   \n",
       "\n",
       "      MVOL3   LMKT2   LMKT3      MMOM     MIMOM      MLTR   LSPREAD  \n",
       "0  0.434190  0.1289 -0.0278  0.186212  0.112764  0.459110  0.076923  \n",
       "1  0.771919  0.0482  0.1289  0.179935 -0.025601  0.498953  0.625000  \n",
       "2  0.545027  0.0211  0.0482  0.208747  0.032263  0.488026  0.133330  \n",
       "3  0.434190  0.1289 -0.0278  0.186212  0.112764  0.459110  0.120000  \n",
       "4  0.771919  0.0482  0.1289  0.179935 -0.025601  0.498953  0.078431  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load 'basemodel.parquet'\n",
    "#df = pd.read_parquet('basemodel.parquet')\n",
    "df = pd.read_parquet('/kaggle/input/sign-prediction-datasets/basicmarket.parquet')\n",
    "prediction_cols = []\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01aaf84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T12:03:00.320132Z",
     "iopub.status.busy": "2024-02-29T12:03:00.319708Z",
     "iopub.status.idle": "2024-02-29T12:03:00.325700Z",
     "shell.execute_reply": "2024-02-29T12:03:00.324637Z"
    },
    "papermill": {
     "duration": 0.021086,
     "end_time": "2024-02-29T12:03:00.328124",
     "exception": false,
     "start_time": "2024-02-29T12:03:00.307038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select the columns to be used for prediction\n",
    "X_col = ['bull_D', 'bear_D', 'bull_W', 'bear_W', 'bull_M', 'bear_M', 'LMKT', 'IVOL', # initial columns\n",
    "         'STR',\t'LTURNOVER', 'IMOM', 'MOM',\t'LTR', 'PCTHIGH', 'IVOL2', 'IVOL3', 'LSPREAD',\t# stock specific columns\n",
    "         'MVOL', 'MVOL2', 'MVOL3', 'LMKT2',\t'LMKT3', 'MMOM', 'MIMOM', 'MLTR'] # market specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f3b0253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T12:03:00.352659Z",
     "iopub.status.busy": "2024-02-29T12:03:00.352104Z",
     "iopub.status.idle": "2024-02-29T12:03:01.980859Z",
     "shell.execute_reply": "2024-02-29T12:03:01.979660Z"
    },
    "papermill": {
     "duration": 1.644213,
     "end_time": "2024-02-29T12:03:01.983599",
     "exception": false,
     "start_time": "2024-02-29T12:03:00.339386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scale the data for faster coeficient convergence\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df[X_col] = scaler.fit_transform(df[X_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e741caf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T12:03:02.008904Z",
     "iopub.status.busy": "2024-02-29T12:03:02.007646Z",
     "iopub.status.idle": "2024-02-29T12:03:03.447012Z",
     "shell.execute_reply": "2024-02-29T12:03:03.445886Z"
    },
    "papermill": {
     "duration": 1.454667,
     "end_time": "2024-02-29T12:03:03.449760",
     "exception": false,
     "start_time": "2024-02-29T12:03:01.995093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'date' to datetime format (if not already done) and sort the DataFrame\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.sort_values(by='date', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create a 'year' column based on the 'date' column\n",
    "df['year'] = df['date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c94279",
   "metadata": {
    "papermill": {
     "duration": 0.011948,
     "end_time": "2024-02-29T12:03:03.472986",
     "exception": false,
     "start_time": "2024-02-29T12:03:03.461038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Paper Replication - OLS and Logit, Expanding Window - No Hyperparameters\n",
    "- They start with out of sample forecasting in 1932\n",
    "- models will be named model_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801b8a5b",
   "metadata": {
    "papermill": {
     "duration": 0.010983,
     "end_time": "2024-02-29T12:03:03.495211",
     "exception": false,
     "start_time": "2024-02-29T12:03:03.484228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Linear Regression (Pooled OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a18907c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T12:03:03.520032Z",
     "iopub.status.busy": "2024-02-29T12:03:03.519362Z",
     "iopub.status.idle": "2024-02-29T12:04:07.897330Z",
     "shell.execute_reply": "2024-02-29T12:04:07.896142Z"
    },
    "papermill": {
     "duration": 64.394555,
     "end_time": "2024-02-29T12:04:07.901126",
     "exception": false,
     "start_time": "2024-02-29T12:03:03.506571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1933 - Time: 0.08 seconds\n",
      "Year 1934 - Time: 0.13 seconds\n",
      "Year 1935 - Time: 0.10 seconds\n",
      "Year 1936 - Time: 0.12 seconds\n",
      "Year 1937 - Time: 0.12 seconds\n",
      "Year 1938 - Time: 0.13 seconds\n",
      "Year 1939 - Time: 0.12 seconds\n",
      "Year 1940 - Time: 0.10 seconds\n",
      "Year 1941 - Time: 0.13 seconds\n",
      "Year 1942 - Time: 0.16 seconds\n",
      "Year 1943 - Time: 0.17 seconds\n",
      "Year 1944 - Time: 0.15 seconds\n",
      "Year 1945 - Time: 0.18 seconds\n",
      "Year 1946 - Time: 0.17 seconds\n",
      "Year 1947 - Time: 0.16 seconds\n",
      "Year 1948 - Time: 0.20 seconds\n",
      "Year 1949 - Time: 0.20 seconds\n",
      "Year 1950 - Time: 0.21 seconds\n",
      "Year 1951 - Time: 0.22 seconds\n",
      "Year 1952 - Time: 0.21 seconds\n",
      "Year 1953 - Time: 0.20 seconds\n",
      "Year 1954 - Time: 0.24 seconds\n",
      "Year 1955 - Time: 0.24 seconds\n",
      "Year 1956 - Time: 0.23 seconds\n",
      "Year 1957 - Time: 0.25 seconds\n",
      "Year 1958 - Time: 0.25 seconds\n",
      "Year 1959 - Time: 0.25 seconds\n",
      "Year 1960 - Time: 0.26 seconds\n",
      "Year 1961 - Time: 0.27 seconds\n",
      "Year 1962 - Time: 0.27 seconds\n",
      "Year 1963 - Time: 0.30 seconds\n",
      "Year 1964 - Time: 0.29 seconds\n",
      "Year 1965 - Time: 0.29 seconds\n",
      "Year 1966 - Time: 0.30 seconds\n",
      "Year 1967 - Time: 0.31 seconds\n",
      "Year 1968 - Time: 0.35 seconds\n",
      "Year 1969 - Time: 0.36 seconds\n",
      "Year 1970 - Time: 0.35 seconds\n",
      "Year 1971 - Time: 0.38 seconds\n",
      "Year 1972 - Time: 0.40 seconds\n",
      "Year 1973 - Time: 0.39 seconds\n",
      "Year 1974 - Time: 0.41 seconds\n",
      "Year 1975 - Time: 0.39 seconds\n",
      "Year 1976 - Time: 0.43 seconds\n",
      "Year 1977 - Time: 0.46 seconds\n",
      "Year 1978 - Time: 0.46 seconds\n",
      "Year 1979 - Time: 0.49 seconds\n",
      "Year 1980 - Time: 0.52 seconds\n",
      "Year 1981 - Time: 0.55 seconds\n",
      "Year 1982 - Time: 0.54 seconds\n",
      "Year 1983 - Time: 0.53 seconds\n",
      "Year 1984 - Time: 0.58 seconds\n",
      "Year 1985 - Time: 0.63 seconds\n",
      "Year 1986 - Time: 0.68 seconds\n",
      "Year 1987 - Time: 0.76 seconds\n",
      "Year 1988 - Time: 0.78 seconds\n",
      "Year 1989 - Time: 0.81 seconds\n",
      "Year 1990 - Time: 0.86 seconds\n",
      "Year 1991 - Time: 0.86 seconds\n",
      "Year 1992 - Time: 0.92 seconds\n",
      "Year 1993 - Time: 0.96 seconds\n",
      "Year 1994 - Time: 0.98 seconds\n",
      "Year 1995 - Time: 1.03 seconds\n",
      "Year 1996 - Time: 1.11 seconds\n",
      "Year 1997 - Time: 1.09 seconds\n",
      "Year 1998 - Time: 1.14 seconds\n",
      "Year 1999 - Time: 1.20 seconds\n",
      "Year 2000 - Time: 1.23 seconds\n",
      "Year 2001 - Time: 1.27 seconds\n",
      "Year 2002 - Time: 1.36 seconds\n",
      "Year 2003 - Time: 1.33 seconds\n",
      "Year 2004 - Time: 1.45 seconds\n",
      "Year 2005 - Time: 1.40 seconds\n",
      "Year 2006 - Time: 1.50 seconds\n",
      "Year 2007 - Time: 1.43 seconds\n",
      "Year 2008 - Time: 1.52 seconds\n",
      "Year 2009 - Time: 1.48 seconds\n",
      "Year 2010 - Time: 1.71 seconds\n",
      "Year 2011 - Time: 1.59 seconds\n",
      "Year 2012 - Time: 1.58 seconds\n",
      "Year 2013 - Time: 1.57 seconds\n",
      "Year 2014 - Time: 1.60 seconds\n",
      "Year 2015 - Time: 1.63 seconds\n",
      "Year 2016 - Time: 1.69 seconds\n",
      "Year 2017 - Time: 1.70 seconds\n",
      "Year 2018 - Time: 1.82 seconds\n",
      "Year 2019 - Time: 1.73 seconds\n",
      "Year 2020 - Time: 1.77 seconds\n",
      "Year 2021 - Time: 1.76 seconds\n",
      "Year 2022 - Time: 1.81 seconds\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "# OLS, default, exp window\n",
    "#################################\n",
    "\n",
    "model_name = 'base_ols_default'\n",
    "\n",
    "\n",
    "# Update the column name for storing Decision Tree regression predictions\n",
    "df[model_name] = np.nan\n",
    "\n",
    "# Ensure the new column is in the prediction_cols list\n",
    "if model_name not in prediction_cols:\n",
    "    prediction_cols.append(model_name)\n",
    "\n",
    "for year in range(df['year'].min() + 6, df['year'].max() + 1):\n",
    "    start_time = time.time()  # Start timing\n",
    "    \n",
    "    # Define the training data up until this year\n",
    "    train_data = df[df['year'] < year]\n",
    "    \n",
    "    X_train = train_data[['bull_D', 'bear_D', 'bull_W', 'bear_W', 'bull_M', 'bear_M', 'LMKT', 'IVOL']]\n",
    "    y_train = train_data['y']\n",
    "    \n",
    "    # Train the Linear Regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict for the next year\n",
    "    next_year_data = df[df['year'] == year]\n",
    "    X_next_year = next_year_data[['bull_D', 'bear_D', 'bull_W', 'bear_W', 'bull_M', 'bear_M', 'LMKT', 'IVOL']]\n",
    "    \n",
    "    if not X_next_year.empty:\n",
    "        next_year_predictions = model.predict(X_next_year)\n",
    "        df.loc[df['year'] == year, model_name] = next_year_predictions\n",
    "    \n",
    "    end_time = time.time()  # End timing\n",
    "    iteration_time = end_time - start_time  # Calculate iteration time\n",
    "    \n",
    "    print(f\"Year {year} - Time: {iteration_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3064b4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T12:04:07.984264Z",
     "iopub.status.busy": "2024-02-29T12:04:07.983544Z",
     "iopub.status.idle": "2024-02-29T12:07:23.765476Z",
     "shell.execute_reply": "2024-02-29T12:07:23.763835Z"
    },
    "papermill": {
     "duration": 195.829565,
     "end_time": "2024-02-29T12:07:23.770861",
     "exception": false,
     "start_time": "2024-02-29T12:04:07.941296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1933 - Time: 0.13 seconds\n",
      "Year 1934 - Time: 0.23 seconds\n",
      "Year 1935 - Time: 0.16 seconds\n",
      "Year 1936 - Time: 0.20 seconds\n",
      "Year 1937 - Time: 0.20 seconds\n",
      "Year 1938 - Time: 0.22 seconds\n",
      "Year 1939 - Time: 0.22 seconds\n",
      "Year 1940 - Time: 0.23 seconds\n",
      "Year 1941 - Time: 0.25 seconds\n",
      "Year 1942 - Time: 0.25 seconds\n",
      "Year 1943 - Time: 0.28 seconds\n",
      "Year 1944 - Time: 0.29 seconds\n",
      "Year 1945 - Time: 0.30 seconds\n",
      "Year 1946 - Time: 0.32 seconds\n",
      "Year 1947 - Time: 0.33 seconds\n",
      "Year 1948 - Time: 0.35 seconds\n",
      "Year 1949 - Time: 0.35 seconds\n",
      "Year 1950 - Time: 0.38 seconds\n",
      "Year 1951 - Time: 0.38 seconds\n",
      "Year 1952 - Time: 0.41 seconds\n",
      "Year 1953 - Time: 0.42 seconds\n",
      "Year 1954 - Time: 0.46 seconds\n",
      "Year 1955 - Time: 0.47 seconds\n",
      "Year 1956 - Time: 0.50 seconds\n",
      "Year 1957 - Time: 0.48 seconds\n",
      "Year 1958 - Time: 0.49 seconds\n",
      "Year 1959 - Time: 0.52 seconds\n",
      "Year 1960 - Time: 0.54 seconds\n",
      "Year 1961 - Time: 0.55 seconds\n",
      "Year 1962 - Time: 0.59 seconds\n",
      "Year 1963 - Time: 0.73 seconds\n",
      "Year 1964 - Time: 0.72 seconds\n",
      "Year 1965 - Time: 0.69 seconds\n",
      "Year 1966 - Time: 0.70 seconds\n",
      "Year 1967 - Time: 0.73 seconds\n",
      "Year 1968 - Time: 0.76 seconds\n",
      "Year 1969 - Time: 0.84 seconds\n",
      "Year 1970 - Time: 0.86 seconds\n",
      "Year 1971 - Time: 0.90 seconds\n",
      "Year 1972 - Time: 0.98 seconds\n",
      "Year 1973 - Time: 1.03 seconds\n",
      "Year 1974 - Time: 1.09 seconds\n",
      "Year 1975 - Time: 1.09 seconds\n",
      "Year 1976 - Time: 1.37 seconds\n",
      "Year 1977 - Time: 1.40 seconds\n",
      "Year 1978 - Time: 1.46 seconds\n",
      "Year 1979 - Time: 1.52 seconds\n",
      "Year 1980 - Time: 1.56 seconds\n",
      "Year 1981 - Time: 1.63 seconds\n",
      "Year 1982 - Time: 1.66 seconds\n",
      "Year 1983 - Time: 1.73 seconds\n",
      "Year 1984 - Time: 1.84 seconds\n",
      "Year 1985 - Time: 1.95 seconds\n",
      "Year 1986 - Time: 2.07 seconds\n",
      "Year 1987 - Time: 2.22 seconds\n",
      "Year 1988 - Time: 2.34 seconds\n",
      "Year 1989 - Time: 2.42 seconds\n",
      "Year 1990 - Time: 2.56 seconds\n",
      "Year 1991 - Time: 2.73 seconds\n",
      "Year 1992 - Time: 2.82 seconds\n",
      "Year 1993 - Time: 2.95 seconds\n",
      "Year 1994 - Time: 3.11 seconds\n",
      "Year 1995 - Time: 3.25 seconds\n",
      "Year 1996 - Time: 3.34 seconds\n",
      "Year 1997 - Time: 3.48 seconds\n",
      "Year 1998 - Time: 4.15 seconds\n",
      "Year 1999 - Time: 3.77 seconds\n",
      "Year 2000 - Time: 3.94 seconds\n",
      "Year 2001 - Time: 4.09 seconds\n",
      "Year 2002 - Time: 4.26 seconds\n",
      "Year 2003 - Time: 4.23 seconds\n",
      "Year 2004 - Time: 4.41 seconds\n",
      "Year 2005 - Time: 4.56 seconds\n",
      "Year 2006 - Time: 4.68 seconds\n",
      "Year 2007 - Time: 4.73 seconds\n",
      "Year 2008 - Time: 4.83 seconds\n",
      "Year 2009 - Time: 4.89 seconds\n",
      "Year 2010 - Time: 5.03 seconds\n",
      "Year 2011 - Time: 5.17 seconds\n",
      "Year 2012 - Time: 5.69 seconds\n",
      "Year 2013 - Time: 5.21 seconds\n",
      "Year 2014 - Time: 5.30 seconds\n",
      "Year 2015 - Time: 5.44 seconds\n",
      "Year 2016 - Time: 5.56 seconds\n",
      "Year 2017 - Time: 5.53 seconds\n",
      "Year 2018 - Time: 5.68 seconds\n",
      "Year 2019 - Time: 5.77 seconds\n",
      "Year 2020 - Time: 5.83 seconds\n",
      "Year 2021 - Time: 5.88 seconds\n",
      "Year 2022 - Time: 6.01 seconds\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "# OLS, default, exp window\n",
    "#################################\n",
    "\n",
    "model_name = 'ols_default'\n",
    "\n",
    "\n",
    "# Update the column name for storing Decision Tree regression predictions\n",
    "df[model_name] = np.nan\n",
    "\n",
    "# Ensure the new column is in the prediction_cols list\n",
    "if model_name not in prediction_cols:\n",
    "    prediction_cols.append(model_name)\n",
    "\n",
    "for year in range(df['year'].min() + 6, df['year'].max() + 1):\n",
    "    start_time = time.time()  # Start timing\n",
    "    \n",
    "    # Define the training data up until this year\n",
    "    train_data = df[df['year'] < year]\n",
    "    \n",
    "    X_train = train_data[X_col]\n",
    "    y_train = train_data['y']\n",
    "    \n",
    "    # Train the Linear Regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict for the next year\n",
    "    next_year_data = df[df['year'] == year]\n",
    "    X_next_year = next_year_data[X_col]\n",
    "    \n",
    "    if not X_next_year.empty:\n",
    "        next_year_predictions = model.predict(X_next_year)\n",
    "        df.loc[df['year'] == year, model_name] = next_year_predictions\n",
    "    \n",
    "    end_time = time.time()  # End timing\n",
    "    iteration_time = end_time - start_time  # Calculate iteration time\n",
    "    \n",
    "    print(f\"Year {year} - Time: {iteration_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b2701a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T12:07:23.877729Z",
     "iopub.status.busy": "2024-02-29T12:07:23.877340Z",
     "iopub.status.idle": "2024-02-29T12:07:23.912317Z",
     "shell.execute_reply": "2024-02-29T12:07:23.911255Z"
    },
    "papermill": {
     "duration": 0.086898,
     "end_time": "2024-02-29T12:07:23.915539",
     "exception": false,
     "start_time": "2024-02-29T12:07:23.828641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>RET</th>\n",
       "      <th>ME</th>\n",
       "      <th>bull_D</th>\n",
       "      <th>bear_D</th>\n",
       "      <th>bull_W</th>\n",
       "      <th>bear_W</th>\n",
       "      <th>bull_M</th>\n",
       "      <th>bear_M</th>\n",
       "      <th>LMKT</th>\n",
       "      <th>IVOL</th>\n",
       "      <th>y</th>\n",
       "      <th>STR</th>\n",
       "      <th>LTURNOVER</th>\n",
       "      <th>IMOM</th>\n",
       "      <th>MOM</th>\n",
       "      <th>LTR</th>\n",
       "      <th>PCTHIGH</th>\n",
       "      <th>IVOL2</th>\n",
       "      <th>IVOL3</th>\n",
       "      <th>MVOL</th>\n",
       "      <th>MVOL2</th>\n",
       "      <th>MVOL3</th>\n",
       "      <th>LMKT2</th>\n",
       "      <th>LMKT3</th>\n",
       "      <th>MMOM</th>\n",
       "      <th>MIMOM</th>\n",
       "      <th>MLTR</th>\n",
       "      <th>LSPREAD</th>\n",
       "      <th>year</th>\n",
       "      <th>base_ols_default</th>\n",
       "      <th>ols_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3076047</th>\n",
       "      <td>20412</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>-0.203046</td>\n",
       "      <td>4.174787e+04</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.304629</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030776</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.575618</td>\n",
       "      <td>0.631158</td>\n",
       "      <td>0.707753</td>\n",
       "      <td>0.068333</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.109743</td>\n",
       "      <td>0.128462</td>\n",
       "      <td>0.073585</td>\n",
       "      <td>0.423071</td>\n",
       "      <td>0.288758</td>\n",
       "      <td>0.520342</td>\n",
       "      <td>0.538953</td>\n",
       "      <td>0.814156</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>2022</td>\n",
       "      <td>-0.784252</td>\n",
       "      <td>-0.838064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076048</th>\n",
       "      <td>16874</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>1.110135e+06</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304629</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038978</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.607527</td>\n",
       "      <td>0.717377</td>\n",
       "      <td>0.713835</td>\n",
       "      <td>0.811097</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.109743</td>\n",
       "      <td>0.128462</td>\n",
       "      <td>0.073585</td>\n",
       "      <td>0.423071</td>\n",
       "      <td>0.288758</td>\n",
       "      <td>0.520342</td>\n",
       "      <td>0.538953</td>\n",
       "      <td>0.814156</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.859305</td>\n",
       "      <td>0.836580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076049</th>\n",
       "      <td>20395</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>0.074970</td>\n",
       "      <td>3.728386e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304629</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040109</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.604234</td>\n",
       "      <td>0.735304</td>\n",
       "      <td>0.708705</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.109743</td>\n",
       "      <td>0.128462</td>\n",
       "      <td>0.073585</td>\n",
       "      <td>0.423071</td>\n",
       "      <td>0.288758</td>\n",
       "      <td>0.520342</td>\n",
       "      <td>0.538953</td>\n",
       "      <td>0.814156</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.907330</td>\n",
       "      <td>0.869929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076050</th>\n",
       "      <td>16857</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>-0.029348</td>\n",
       "      <td>1.304941e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.304629</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038915</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.524726</td>\n",
       "      <td>0.645115</td>\n",
       "      <td>0.780172</td>\n",
       "      <td>0.408233</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.109743</td>\n",
       "      <td>0.128462</td>\n",
       "      <td>0.073585</td>\n",
       "      <td>0.423071</td>\n",
       "      <td>0.288758</td>\n",
       "      <td>0.520342</td>\n",
       "      <td>0.538953</td>\n",
       "      <td>0.814156</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.088415</td>\n",
       "      <td>0.048938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076051</th>\n",
       "      <td>93436</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>0.323765</td>\n",
       "      <td>9.311106e+08</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304629</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035278</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.639349</td>\n",
       "      <td>0.729311</td>\n",
       "      <td>0.866215</td>\n",
       "      <td>0.587806</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.109743</td>\n",
       "      <td>0.128462</td>\n",
       "      <td>0.073585</td>\n",
       "      <td>0.423071</td>\n",
       "      <td>0.288758</td>\n",
       "      <td>0.520342</td>\n",
       "      <td>0.538953</td>\n",
       "      <td>0.814156</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.723794</td>\n",
       "      <td>0.825924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PERMNO       date       RET            ME    bull_D  bear_D  \\\n",
       "3076047   20412 2022-07-31 -0.203046  4.174787e+04  0.166667     0.0   \n",
       "3076048   16874 2022-07-31  0.135593  1.110135e+06  0.250000     0.0   \n",
       "3076049   20395 2022-07-31  0.074970  3.728386e+06  0.000000     0.0   \n",
       "3076050   16857 2022-07-31 -0.029348  1.304941e+05  0.000000     0.0   \n",
       "3076051   93436 2022-07-31  0.323765  9.311106e+08  0.166667     0.0   \n",
       "\n",
       "           bull_W  bear_W    bull_M    bear_M      LMKT      IVOL  y  \\\n",
       "3076047  0.083333     0.0  0.000000  0.833333  0.304629  0.000074  0   \n",
       "3076048  0.166667     0.0  0.000000  0.000000  0.304629  0.000006  1   \n",
       "3076049  0.083333     0.0  0.166667  0.000000  0.304629  0.000005  1   \n",
       "3076050  0.000000     0.0  0.000000  0.250000  0.304629  0.000071  0   \n",
       "3076051  0.083333     0.0  0.000000  0.000000  0.304629  0.000030  1   \n",
       "\n",
       "              STR  LTURNOVER      IMOM       MOM       LTR   PCTHIGH  \\\n",
       "3076047  0.030776   0.000056  0.575618  0.631158  0.707753  0.068333   \n",
       "3076048  0.038978   0.000015  0.607527  0.717377  0.713835  0.811097   \n",
       "3076049  0.040109   0.000054  0.604234  0.735304  0.708705  1.000000   \n",
       "3076050  0.038915   0.000081  0.524726  0.645115  0.780172  0.408233   \n",
       "3076051  0.035278   0.000218  0.639349  0.729311  0.866215  0.587806   \n",
       "\n",
       "            IVOL2     IVOL3      MVOL     MVOL2     MVOL3     LMKT2     LMKT3  \\\n",
       "3076047  0.000222  0.000118  0.109743  0.128462  0.073585  0.423071  0.288758   \n",
       "3076048  0.000034  0.000010  0.109743  0.128462  0.073585  0.423071  0.288758   \n",
       "3076049  0.000003  0.000004  0.109743  0.128462  0.073585  0.423071  0.288758   \n",
       "3076050  0.000130  0.000202  0.109743  0.128462  0.073585  0.423071  0.288758   \n",
       "3076051  0.000033  0.000061  0.109743  0.128462  0.073585  0.423071  0.288758   \n",
       "\n",
       "             MMOM     MIMOM      MLTR   LSPREAD  year  base_ols_default  \\\n",
       "3076047  0.520342  0.538953  0.814156  0.009789  2022         -0.784252   \n",
       "3076048  0.520342  0.538953  0.814156  0.002150  2022          0.859305   \n",
       "3076049  0.520342  0.538953  0.814156  0.001340  2022          0.907330   \n",
       "3076050  0.520342  0.538953  0.814156  0.004310  2022          0.088415   \n",
       "3076051  0.520342  0.538953  0.814156  0.004467  2022          0.723794   \n",
       "\n",
       "         ols_default  \n",
       "3076047    -0.838064  \n",
       "3076048     0.836580  \n",
       "3076049     0.869929  \n",
       "3076050     0.048938  \n",
       "3076051     0.825924  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef0d437",
   "metadata": {
    "papermill": {
     "duration": 0.026914,
     "end_time": "2024-02-29T12:07:23.969457",
     "exception": false,
     "start_time": "2024-02-29T12:07:23.942543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# My Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82c37a0",
   "metadata": {
    "papermill": {
     "duration": 0.026805,
     "end_time": "2024-02-29T12:07:24.023982",
     "exception": false,
     "start_time": "2024-02-29T12:07:23.997177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Machine Learning - Hyperparameter Tuning included in the process\n",
    "- models to be named 'model_clas/reg_exp/roll'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf383d60",
   "metadata": {
    "papermill": {
     "duration": 0.027071,
     "end_time": "2024-02-29T12:07:24.078168",
     "exception": false,
     "start_time": "2024-02-29T12:07:24.051097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### First expanding, then rolling\n",
    "start predicting for 1932, expand the window until you reach X years, then roll it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85445b80",
   "metadata": {
    "papermill": {
     "duration": 0.026791,
     "end_time": "2024-02-29T12:07:24.132169",
     "exception": false,
     "start_time": "2024-02-29T12:07:24.105378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### MSE Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5796a8b3",
   "metadata": {
    "papermill": {
     "duration": 0.02717,
     "end_time": "2024-02-29T12:07:24.186561",
     "exception": false,
     "start_time": "2024-02-29T12:07:24.159391",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c33d70e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T12:07:24.242790Z",
     "iopub.status.busy": "2024-02-29T12:07:24.242400Z",
     "iopub.status.idle": "2024-02-29T12:07:24.247324Z",
     "shell.execute_reply": "2024-02-29T12:07:24.246270Z"
    },
    "papermill": {
     "duration": 0.036052,
     "end_time": "2024-02-29T12:07:24.249717",
     "exception": false,
     "start_time": "2024-02-29T12:07:24.213665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rolling_window = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5d2a8a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T12:07:24.306779Z",
     "iopub.status.busy": "2024-02-29T12:07:24.306393Z",
     "iopub.status.idle": "2024-02-29T13:17:59.782483Z",
     "shell.execute_reply": "2024-02-29T13:17:59.779954Z"
    },
    "papermill": {
     "duration": 4235.511421,
     "end_time": "2024-02-29T13:17:59.788474",
     "exception": false,
     "start_time": "2024-02-29T12:07:24.277053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1933 - Best C: 100, Best ACC: 0.9982, Time: 7.30 seconds\n",
      "Year 1934 - Best C: 1, Best ACC: 0.9994, Time: 5.42 seconds\n",
      "Year 1935 - Best C: 1, Best ACC: 1.0, Time: 6.18 seconds\n",
      "Year 1936 - Best C: 10, Best ACC: 1.0, Time: 7.39 seconds\n",
      "Year 1937 - Best C: 10, Best ACC: 1.0, Time: 6.64 seconds\n",
      "Year 1938 - Best C: 100, Best ACC: 1.0, Time: 8.84 seconds\n",
      "Year 1939 - Best C: 1, Best ACC: 1.0, Time: 6.05 seconds\n",
      "Year 1940 - Best C: 10, Best ACC: 0.9994, Time: 6.65 seconds\n",
      "Year 1941 - Best C: 10, Best ACC: 1.0, Time: 8.95 seconds\n",
      "Year 1942 - Best C: 1, Best ACC: 1.0, Time: 8.53 seconds\n",
      "Year 1943 - Best C: 10, Best ACC: 1.0, Time: 8.13 seconds\n",
      "Year 1944 - Best C: 1, Best ACC: 1.0, Time: 8.22 seconds\n",
      "Year 1945 - Best C: 10, Best ACC: 1.0, Time: 8.16 seconds\n",
      "Year 1946 - Best C: 100, Best ACC: 0.9995, Time: 10.47 seconds\n",
      "Year 1947 - Best C: 100, Best ACC: 1.0, Time: 10.60 seconds\n",
      "Year 1948 - Best C: 10, Best ACC: 1.0, Time: 10.17 seconds\n",
      "Year 1949 - Best C: 10, Best ACC: 1.0, Time: 11.23 seconds\n",
      "Year 1950 - Best C: 10, Best ACC: 1.0, Time: 7.99 seconds\n",
      "Year 1951 - Best C: 10, Best ACC: 1.0, Time: 8.48 seconds\n",
      "Year 1952 - Best C: 10, Best ACC: 1.0, Time: 9.50 seconds\n",
      "Year 1953 - Best C: 10, Best ACC: 1.0, Time: 11.59 seconds\n",
      "Year 1954 - Best C: 1, Best ACC: 1.0, Time: 10.04 seconds\n",
      "Year 1955 - Best C: 100, Best ACC: 0.9996, Time: 14.19 seconds\n",
      "Year 1956 - Best C: 10, Best ACC: 1.0, Time: 12.63 seconds\n",
      "Year 1957 - Best C: 1, Best ACC: 1.0, Time: 9.33 seconds\n",
      "Year 1958 - Best C: 1, Best ACC: 1.0, Time: 10.53 seconds\n",
      "Year 1959 - Best C: 100, Best ACC: 1.0, Time: 17.80 seconds\n",
      "Year 1960 - Best C: 10, Best ACC: 1.0, Time: 11.72 seconds\n",
      "Year 1961 - Best C: 10, Best ACC: 0.9996, Time: 12.87 seconds\n",
      "Year 1962 - Best C: 100, Best ACC: 1.0, Time: 14.04 seconds\n",
      "Year 1963 - Best C: 10, Best ACC: 1.0, Time: 13.28 seconds\n",
      "Year 1964 - Best C: 10, Best ACC: 0.9997, Time: 11.81 seconds\n",
      "Year 1965 - Best C: 10, Best ACC: 0.9998, Time: 16.58 seconds\n",
      "Year 1966 - Best C: 10, Best ACC: 1.0, Time: 18.62 seconds\n",
      "Year 1967 - Best C: 1, Best ACC: 1.0, Time: 14.04 seconds\n",
      "Year 1968 - Best C: 10, Best ACC: 1.0, Time: 21.34 seconds\n",
      "Year 1969 - Best C: 10, Best ACC: 1.0, Time: 27.68 seconds\n",
      "Year 1970 - Best C: 10, Best ACC: 1.0, Time: 23.61 seconds\n",
      "Year 1971 - Best C: 1, Best ACC: 1.0, Time: 27.56 seconds\n",
      "Year 1972 - Best C: 1, Best ACC: 1.0, Time: 20.86 seconds\n",
      "Year 1973 - Best C: 1, Best ACC: 1.0, Time: 27.46 seconds\n",
      "Year 1974 - Best C: 100, Best ACC: 0.9996, Time: 40.34 seconds\n",
      "Year 1975 - Best C: 100, Best ACC: 0.9997, Time: 42.44 seconds\n",
      "Year 1976 - Best C: 1, Best ACC: 0.9997, Time: 39.06 seconds\n",
      "Year 1977 - Best C: 100, Best ACC: 0.9998, Time: 51.94 seconds\n",
      "Year 1978 - Best C: 1, Best ACC: 1.0, Time: 40.63 seconds\n",
      "Year 1979 - Best C: 1, Best ACC: 1.0, Time: 36.26 seconds\n",
      "Year 1980 - Best C: 100, Best ACC: 1.0, Time: 39.17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1981 - Best C: 10, Best ACC: 1.0, Time: 36.62 seconds\n",
      "Year 1982 - Best C: 10, Best ACC: 1.0, Time: 31.63 seconds\n",
      "Year 1983 - Best C: 1, Best ACC: 1.0, Time: 30.43 seconds\n",
      "Year 1984 - Best C: 1, Best ACC: 0.9998, Time: 30.04 seconds\n",
      "Year 1985 - Best C: 1, Best ACC: 1.0, Time: 44.14 seconds\n",
      "Year 1986 - Best C: 1, Best ACC: 0.9998, Time: 49.59 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1987 - Best C: 1, Best ACC: 0.9998, Time: 62.38 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1988 - Best C: 100, Best ACC: 0.9999, Time: 110.33 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1989 - Best C: 1, Best ACC: 0.9998, Time: 92.57 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1990 - Best C: 1, Best ACC: 0.9999, Time: 95.42 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1991 - Best C: 10, Best ACC: 0.9998, Time: 114.23 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1992 - Best C: 1, Best ACC: 0.999, Time: 107.06 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1993 - Best C: 1, Best ACC: 0.9996, Time: 96.75 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1994 - Best C: 1, Best ACC: 0.9998, Time: 92.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1995 - Best C: 100, Best ACC: 0.9999, Time: 117.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1996 - Best C: 100, Best ACC: 0.9999, Time: 130.10 seconds\n",
      "Year 1997 - Best C: 1, Best ACC: 0.9999, Time: 104.03 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1998 - Best C: 1, Best ACC: 0.9997, Time: 90.10 seconds\n",
      "Year 1999 - Best C: 1, Best ACC: 1.0, Time: 97.78 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2000 - Best C: 0.1, Best ACC: 0.9999, Time: 96.49 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2001 - Best C: 1, Best ACC: 1.0, Time: 119.12 seconds\n",
      "Year 2002 - Best C: 100, Best ACC: 0.9996, Time: 143.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2003 - Best C: 1, Best ACC: 0.9999, Time: 120.82 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2004 - Best C: 100, Best ACC: 0.9998, Time: 132.21 seconds\n",
      "Year 2005 - Best C: 1, Best ACC: 1.0, Time: 96.05 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2006 - Best C: 1, Best ACC: 1.0, Time: 87.73 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2007 - Best C: 1, Best ACC: 1.0, Time: 73.15 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2008 - Best C: 1, Best ACC: 1.0, Time: 83.36 seconds\n",
      "Year 2009 - Best C: 100, Best ACC: 0.9998, Time: 81.81 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2010 - Best C: 0.1, Best ACC: 0.9998, Time: 61.03 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2011 - Best C: 100, Best ACC: 0.9998, Time: 90.37 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2012 - Best C: 0.1, Best ACC: 1.0, Time: 55.29 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2013 - Best C: 100, Best ACC: 0.9999, Time: 83.60 seconds\n",
      "Year 2014 - Best C: 100, Best ACC: 0.9999, Time: 79.56 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2015 - Best C: 1, Best ACC: 1.0, Time: 55.35 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2016 - Best C: 1, Best ACC: 1.0, Time: 53.55 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2017 - Best C: 100, Best ACC: 0.9996, Time: 77.40 seconds\n",
      "Year 2018 - Best C: 1, Best ACC: 0.9999, Time: 51.57 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2019 - Best C: 100, Best ACC: 0.9997, Time: 77.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2020 - Best C: 100, Best ACC: 0.9998, Time: 70.30 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2021 - Best C: 0.1, Best ACC: 0.9991, Time: 53.71 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2022 - Best C: 0.1, Best ACC: 1.0, Time: 58.21 seconds\n",
      "Total time: 4235.45 seconds\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# RIDGE CLASSIFICATION MODEL - MSE\n",
    "############################################\n",
    "\n",
    "model_name = 'ridge_clas_roll5'  # Name of the new column for storing predictions\n",
    "start_time2 = time.time()  # Start timing\n",
    "\n",
    "\n",
    "# Predefined set of C values for hyperparameter tuning\n",
    "HP1 = [0.01, 0.1, 1, 10, 100] # C\n",
    "\n",
    "# Update the column name for storing Decision Tree regression predictions\n",
    "df[model_name] = np.nan\n",
    "\n",
    "# Ensure the new column is in the prediction_cols list\n",
    "if model_name not in prediction_cols:\n",
    "    prediction_cols.append(model_name)\n",
    "\n",
    "# Define the start year for modeling based on having at least 7 years of data\n",
    "start_modeling_year = df['year'].min() + 6\n",
    "\n",
    "for year in range(start_modeling_year, df['year'].max() + 1):\n",
    "    start_time = time.time()  # Start timing\n",
    "    \n",
    "    # Determine the start year of the training window based on the current year\n",
    "    train_start_year = max(year - rolling_window, df['year'].min())  # Ensure it does not go below the earliest year\n",
    "    \n",
    "    # Select the training data based on the calculated start year\n",
    "    train_data = df[(df['year'] >= train_start_year) & (df['year'] < year)]\n",
    "    \n",
    "    # Split training data into actual training and tuning sets\n",
    "    # Use the last year of the training data for tuning\n",
    "    tuning_data = train_data[train_data['year'] == year - 1]\n",
    "    actual_train_data = train_data[train_data['year'] < year - 1]\n",
    "    \n",
    "    X_train = actual_train_data[X_col]\n",
    "    y_train = actual_train_data['y']\n",
    "    \n",
    "    X_tune = tuning_data[X_col]\n",
    "    y_tune = tuning_data['y']\n",
    "       \n",
    "    best_HP1 = None\n",
    "    best_accuracy = -1  # Initialize with infinity\n",
    "    \n",
    "    # Hyperparameter tuning\n",
    "    for hp1 in HP1:\n",
    "        model = LogisticRegression(C=hp1, max_iter=1000, penalty='l2')  # Ridge\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict_proba(X_tune)[:, 1]  # Get probabilities of the positive class\n",
    "\n",
    "        # Identify top and bottom deciles\n",
    "        decile_thresholds = np.percentile(predictions, [10, 90])\n",
    "        top_bottom_decile_mask = (predictions <= decile_thresholds[0]) | (predictions >= decile_thresholds[1])\n",
    "        \n",
    "        # Filter tuning dataset based on deciles\n",
    "        filtered_y_tune = y_tune[top_bottom_decile_mask]\n",
    "        filtered_predictions = predictions[top_bottom_decile_mask]\n",
    "        \n",
    "        # Assuming binary classification, convert continuous predictions to binary\n",
    "        # This conversion logic might need adjustment based on your specific use case\n",
    "        binary_predictions = (filtered_predictions >= 0.5).astype(int)\n",
    "        \n",
    "        # Calculate accuracy for filtered predictions\n",
    "        decile_accuracy = accuracy_score(filtered_y_tune, binary_predictions)\n",
    "        \n",
    "        if decile_accuracy > best_accuracy:\n",
    "            best_accuracy = decile_accuracy\n",
    "            best_HP1 = hp1\n",
    "    \n",
    "    \n",
    "    # Retrain on the entire training window (excluding tuning year) with the best C value\n",
    "    model = LogisticRegression(C=best_HP1, max_iter=1000, penalty='l2')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict for the next year\n",
    "    next_year_data = df[df['year'] == year]\n",
    "    X_next_year = next_year_data[X_col]\n",
    "    \n",
    "    if not X_next_year.empty:\n",
    "        next_year_probabilities = model.predict_proba(X_next_year)[:, 1]  # Probability of the positive class\n",
    "        df.loc[df['year'] == year, model_name] = next_year_probabilities\n",
    "    \n",
    "    end_time = time.time()  # End timing\n",
    "    iteration_time = end_time - start_time  # Calculate iteration time\n",
    "    \n",
    "    print(f\"Year {year} - Best C: {best_HP1}, Best ACC: {round(best_accuracy,4)}, Time: {iteration_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "end_time2 = time.time()  # End timing\n",
    "print(f\"Total time: {end_time2 - start_time2:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc87436",
   "metadata": {
    "papermill": {
     "duration": 0.043863,
     "end_time": "2024-02-29T13:17:59.920727",
     "exception": false,
     "start_time": "2024-02-29T13:17:59.876864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d36ed241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T13:18:00.004916Z",
     "iopub.status.busy": "2024-02-29T13:18:00.004484Z",
     "iopub.status.idle": "2024-02-29T13:30:26.823637Z",
     "shell.execute_reply": "2024-02-29T13:30:26.822458Z"
    },
    "papermill": {
     "duration": 746.86595,
     "end_time": "2024-02-29T13:30:26.826298",
     "exception": false,
     "start_time": "2024-02-29T13:17:59.960348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1933 - Best Max Depth: 3, Best ACC: 1.0, Time: 1.58 seconds\n",
      "Year 1934 - Best Max Depth: 3, Best ACC: 1.0, Time: 1.63 seconds\n",
      "Year 1935 - Best Max Depth: 3, Best ACC: 1.0, Time: 1.69 seconds\n",
      "Year 1936 - Best Max Depth: 3, Best ACC: 1.0, Time: 1.79 seconds\n",
      "Year 1937 - Best Max Depth: 3, Best ACC: 1.0, Time: 1.70 seconds\n",
      "Year 1938 - Best Max Depth: 3, Best ACC: 1.0, Time: 1.64 seconds\n",
      "Year 1939 - Best Max Depth: 3, Best ACC: 1.0, Time: 1.71 seconds\n",
      "Year 1940 - Best Max Depth: 3, Best ACC: 1.0, Time: 1.75 seconds\n",
      "Year 1941 - Best Max Depth: 3, Best ACC: 1.0, Time: 1.91 seconds\n",
      "Year 1942 - Best Max Depth: 3, Best ACC: 1.0, Time: 1.96 seconds\n",
      "Year 1943 - Best Max Depth: 3, Best ACC: 1.0, Time: 1.99 seconds\n",
      "Year 1944 - Best Max Depth: 3, Best ACC: 1.0, Time: 2.01 seconds\n",
      "Year 1945 - Best Max Depth: 3, Best ACC: 1.0, Time: 1.91 seconds\n",
      "Year 1946 - Best Max Depth: 3, Best ACC: 1.0, Time: 1.96 seconds\n",
      "Year 1947 - Best Max Depth: 3, Best ACC: 1.0, Time: 1.87 seconds\n",
      "Year 1948 - Best Max Depth: 3, Best ACC: 1.0, Time: 1.96 seconds\n",
      "Year 1949 - Best Max Depth: 3, Best ACC: 1.0, Time: 1.98 seconds\n",
      "Year 1950 - Best Max Depth: 3, Best ACC: 1.0, Time: 2.15 seconds\n",
      "Year 1951 - Best Max Depth: 3, Best ACC: 1.0, Time: 2.28 seconds\n",
      "Year 1952 - Best Max Depth: 3, Best ACC: 1.0, Time: 2.33 seconds\n",
      "Year 1953 - Best Max Depth: 3, Best ACC: 1.0, Time: 2.41 seconds\n",
      "Year 1954 - Best Max Depth: 3, Best ACC: 1.0, Time: 2.48 seconds\n",
      "Year 1955 - Best Max Depth: 3, Best ACC: 1.0, Time: 2.61 seconds\n",
      "Year 1956 - Best Max Depth: 3, Best ACC: 1.0, Time: 2.57 seconds\n",
      "Year 1957 - Best Max Depth: 3, Best ACC: 1.0, Time: 2.63 seconds\n",
      "Year 1958 - Best Max Depth: 3, Best ACC: 1.0, Time: 2.58 seconds\n",
      "Year 1959 - Best Max Depth: 3, Best ACC: 1.0, Time: 2.62 seconds\n",
      "Year 1960 - Best Max Depth: 3, Best ACC: 1.0, Time: 2.68 seconds\n",
      "Year 1961 - Best Max Depth: 3, Best ACC: 1.0, Time: 2.46 seconds\n",
      "Year 1962 - Best Max Depth: 3, Best ACC: 1.0, Time: 2.55 seconds\n",
      "Year 1963 - Best Max Depth: 3, Best ACC: 1.0, Time: 2.50 seconds\n",
      "Year 1964 - Best Max Depth: 3, Best ACC: 1.0, Time: 2.64 seconds\n",
      "Year 1965 - Best Max Depth: 3, Best ACC: 1.0, Time: 3.06 seconds\n",
      "Year 1966 - Best Max Depth: 3, Best ACC: 1.0, Time: 3.62 seconds\n",
      "Year 1967 - Best Max Depth: 3, Best ACC: 1.0, Time: 4.42 seconds\n",
      "Year 1968 - Best Max Depth: 3, Best ACC: 1.0, Time: 5.17 seconds\n",
      "Year 1969 - Best Max Depth: 3, Best ACC: 1.0, Time: 5.56 seconds\n",
      "Year 1970 - Best Max Depth: 3, Best ACC: 1.0, Time: 5.36 seconds\n",
      "Year 1971 - Best Max Depth: 3, Best ACC: 1.0, Time: 5.48 seconds\n",
      "Year 1972 - Best Max Depth: 3, Best ACC: 1.0, Time: 5.49 seconds\n",
      "Year 1973 - Best Max Depth: 3, Best ACC: 1.0, Time: 5.76 seconds\n",
      "Year 1974 - Best Max Depth: 3, Best ACC: 1.0, Time: 6.09 seconds\n",
      "Year 1975 - Best Max Depth: 3, Best ACC: 1.0, Time: 6.25 seconds\n",
      "Year 1976 - Best Max Depth: 3, Best ACC: 1.0, Time: 6.65 seconds\n",
      "Year 1977 - Best Max Depth: 3, Best ACC: 1.0, Time: 6.76 seconds\n",
      "Year 1978 - Best Max Depth: 3, Best ACC: 1.0, Time: 7.10 seconds\n",
      "Year 1979 - Best Max Depth: 3, Best ACC: 1.0, Time: 7.01 seconds\n",
      "Year 1980 - Best Max Depth: 3, Best ACC: 1.0, Time: 6.74 seconds\n",
      "Year 1981 - Best Max Depth: 3, Best ACC: 1.0, Time: 6.62 seconds\n",
      "Year 1982 - Best Max Depth: 3, Best ACC: 1.0, Time: 6.33 seconds\n",
      "Year 1983 - Best Max Depth: 3, Best ACC: 1.0, Time: 6.35 seconds\n",
      "Year 1984 - Best Max Depth: 3, Best ACC: 1.0, Time: 6.27 seconds\n",
      "Year 1985 - Best Max Depth: 3, Best ACC: 1.0, Time: 8.01 seconds\n",
      "Year 1986 - Best Max Depth: 3, Best ACC: 1.0, Time: 10.59 seconds\n",
      "Year 1987 - Best Max Depth: 3, Best ACC: 1.0, Time: 13.12 seconds\n",
      "Year 1988 - Best Max Depth: 3, Best ACC: 1.0, Time: 15.51 seconds\n",
      "Year 1989 - Best Max Depth: 3, Best ACC: 1.0, Time: 16.48 seconds\n",
      "Year 1990 - Best Max Depth: 3, Best ACC: 1.0, Time: 16.93 seconds\n",
      "Year 1991 - Best Max Depth: 3, Best ACC: 1.0, Time: 17.30 seconds\n",
      "Year 1992 - Best Max Depth: 3, Best ACC: 1.0, Time: 17.98 seconds\n",
      "Year 1993 - Best Max Depth: 3, Best ACC: 1.0, Time: 18.17 seconds\n",
      "Year 1994 - Best Max Depth: 3, Best ACC: 1.0, Time: 17.47 seconds\n",
      "Year 1995 - Best Max Depth: 3, Best ACC: 1.0, Time: 17.27 seconds\n",
      "Year 1996 - Best Max Depth: 3, Best ACC: 1.0, Time: 17.76 seconds\n",
      "Year 1997 - Best Max Depth: 3, Best ACC: 1.0, Time: 18.11 seconds\n",
      "Year 1998 - Best Max Depth: 3, Best ACC: 1.0, Time: 18.91 seconds\n",
      "Year 1999 - Best Max Depth: 3, Best ACC: 1.0, Time: 19.49 seconds\n",
      "Year 2000 - Best Max Depth: 3, Best ACC: 1.0, Time: 19.98 seconds\n",
      "Year 2001 - Best Max Depth: 3, Best ACC: 1.0, Time: 20.31 seconds\n",
      "Year 2002 - Best Max Depth: 3, Best ACC: 1.0, Time: 20.58 seconds\n",
      "Year 2003 - Best Max Depth: 3, Best ACC: 1.0, Time: 19.72 seconds\n",
      "Year 2004 - Best Max Depth: 3, Best ACC: 1.0, Time: 18.26 seconds\n",
      "Year 2005 - Best Max Depth: 3, Best ACC: 1.0, Time: 16.61 seconds\n",
      "Year 2006 - Best Max Depth: 3, Best ACC: 1.0, Time: 15.79 seconds\n",
      "Year 2007 - Best Max Depth: 3, Best ACC: 1.0, Time: 14.65 seconds\n",
      "Year 2008 - Best Max Depth: 3, Best ACC: 1.0, Time: 13.84 seconds\n",
      "Year 2009 - Best Max Depth: 3, Best ACC: 1.0, Time: 13.87 seconds\n",
      "Year 2010 - Best Max Depth: 3, Best ACC: 1.0, Time: 13.82 seconds\n",
      "Year 2011 - Best Max Depth: 3, Best ACC: 1.0, Time: 13.50 seconds\n",
      "Year 2012 - Best Max Depth: 3, Best ACC: 1.0, Time: 12.73 seconds\n",
      "Year 2013 - Best Max Depth: 3, Best ACC: 1.0, Time: 12.07 seconds\n",
      "Year 2014 - Best Max Depth: 3, Best ACC: 1.0, Time: 11.42 seconds\n",
      "Year 2015 - Best Max Depth: 3, Best ACC: 1.0, Time: 10.41 seconds\n",
      "Year 2016 - Best Max Depth: 3, Best ACC: 1.0, Time: 10.85 seconds\n",
      "Year 2017 - Best Max Depth: 3, Best ACC: 1.0, Time: 10.29 seconds\n",
      "Year 2018 - Best Max Depth: 3, Best ACC: 1.0, Time: 10.15 seconds\n",
      "Year 2019 - Best Max Depth: 3, Best ACC: 1.0, Time: 10.31 seconds\n",
      "Year 2020 - Best Max Depth: 3, Best ACC: 1.0, Time: 10.04 seconds\n",
      "Year 2021 - Best Max Depth: 3, Best ACC: 1.0, Time: 9.95 seconds\n",
      "Year 2022 - Best Max Depth: 3, Best ACC: 1.0, Time: 9.89 seconds\n",
      "Total time: 746.80 seconds\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# DECISION TREE CLASSIFICATION MODEL\n",
    "############################################\n",
    "\n",
    "model_name = 'DT_class_roll5'\n",
    "start_time2 = time.time()  # Start timing\n",
    "\n",
    "# Predefined set of max_depth values for hyperparameter tuning\n",
    "HP1 = [3, 5, 10, 15, 25, None] # max_depth\n",
    "\n",
    "# Update the column name for storing Decision Tree regression predictions\n",
    "df[model_name] = np.nan\n",
    "\n",
    "# Ensure the new column is in the prediction_cols list\n",
    "if model_name not in prediction_cols:\n",
    "    prediction_cols.append(model_name)\n",
    "\n",
    "start_modeling_year = df['year'].min() + 6\n",
    "\n",
    "for year in range(start_modeling_year, df['year'].max() + 1):\n",
    "    start_time = time.time()  # Timing each iteration\n",
    "    \n",
    "    train_start_year = max(year - rolling_window, df['year'].min())\n",
    "    train_data = df[(df['year'] >= train_start_year) & (df['year'] < year)]\n",
    "    \n",
    "    tuning_data = train_data[train_data['year'] == year - 1]\n",
    "    actual_train_data = train_data[train_data['year'] < year - 1]\n",
    "    \n",
    "    X_train = actual_train_data[X_col]\n",
    "    y_train = actual_train_data['y']\n",
    "    \n",
    "    X_tune = tuning_data[X_col]\n",
    "    y_tune = tuning_data['y']\n",
    "    \n",
    "    best_HP1 = None\n",
    "    best_accuracy = -1\n",
    "    \n",
    "    # Hyperparameter tuning for max_depth\n",
    "    for hp1 in HP1:\n",
    "        model = DecisionTreeClassifier(max_depth=hp1)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict_proba(X_tune)[:, 1]  # Get probabilities of the positive class\n",
    "\n",
    "        # Identify top and bottom deciles\n",
    "        decile_thresholds = np.percentile(predictions, [10, 90])\n",
    "        top_bottom_decile_mask = (predictions <= decile_thresholds[0]) | (predictions >= decile_thresholds[1])\n",
    "        \n",
    "        # Filter tuning dataset based on deciles\n",
    "        filtered_y_tune = y_tune[top_bottom_decile_mask]\n",
    "        filtered_predictions = predictions[top_bottom_decile_mask]\n",
    "        \n",
    "        # Assuming binary classification, convert continuous predictions to binary\n",
    "        # This conversion logic might need adjustment based on your specific use case\n",
    "        binary_predictions = (filtered_predictions >= 0.5).astype(int)\n",
    "        \n",
    "        # Calculate accuracy for filtered predictions\n",
    "        decile_accuracy = accuracy_score(filtered_y_tune, binary_predictions)\n",
    "        \n",
    "        if decile_accuracy > best_accuracy:\n",
    "            best_accuracy = decile_accuracy\n",
    "            best_HP1 = hp1\n",
    "    \n",
    "    # Retrain on the entire training window with the best max_depth value\n",
    "    model = DecisionTreeClassifier(max_depth=best_HP1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict for the next year\n",
    "    next_year_data = df[df['year'] == year]\n",
    "    X_next_year = next_year_data[X_col]\n",
    "    \n",
    "    if not X_next_year.empty:\n",
    "        next_year_predictions = model.predict_proba(X_next_year)[:, 1]\n",
    "        df.loc[df['year'] == year, model_name] = next_year_predictions\n",
    "    \n",
    "    end_time = time.time()\n",
    "    iteration_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Year {year} - Best Max Depth: {best_HP1}, Best ACC: {round(best_accuracy,4)}, Time: {iteration_time:.2f} seconds\")\n",
    "\n",
    "end_time2 = time.time()  # End timing\n",
    "print(f\"Total time: {end_time2 - start_time2:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e63f7730",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T13:30:26.945850Z",
     "iopub.status.busy": "2024-02-29T13:30:26.945466Z",
     "iopub.status.idle": "2024-02-29T17:40:56.373760Z",
     "shell.execute_reply": "2024-02-29T17:40:56.371978Z"
    },
    "papermill": {
     "duration": 15029.546203,
     "end_time": "2024-02-29T17:40:56.430239",
     "exception": false,
     "start_time": "2024-02-29T13:30:26.884036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1933 - Best n_estimators: 100, Best max_depth: None, Best ACC: 0.95, Time: 30.64 seconds\n",
      "Year 1934 - Best n_estimators: 200, Best max_depth: 15, Best ACC: 0.96, Time: 35.27 seconds\n",
      "Year 1935 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.96, Time: 36.49 seconds\n",
      "Year 1936 - Best n_estimators: 100, Best max_depth: 15, Best ACC: 0.96, Time: 34.67 seconds\n",
      "Year 1937 - Best n_estimators: 100, Best max_depth: 15, Best ACC: 0.98, Time: 33.90 seconds\n",
      "Year 1938 - Best n_estimators: 100, Best max_depth: None, Best ACC: 0.98, Time: 33.92 seconds\n",
      "Year 1939 - Best n_estimators: 200, Best max_depth: 10, Best ACC: 0.97, Time: 35.05 seconds\n",
      "Year 1940 - Best n_estimators: 200, Best max_depth: 10, Best ACC: 0.96, Time: 36.51 seconds\n",
      "Year 1941 - Best n_estimators: 100, Best max_depth: 10, Best ACC: 0.95, Time: 36.12 seconds\n",
      "Year 1942 - Best n_estimators: 200, Best max_depth: 10, Best ACC: 0.95, Time: 39.44 seconds\n",
      "Year 1943 - Best n_estimators: 50, Best max_depth: None, Best ACC: 0.95, Time: 37.74 seconds\n",
      "Year 1944 - Best n_estimators: 100, Best max_depth: 10, Best ACC: 0.97, Time: 38.24 seconds\n",
      "Year 1945 - Best n_estimators: 200, Best max_depth: 15, Best ACC: 0.96, Time: 40.16 seconds\n",
      "Year 1946 - Best n_estimators: 200, Best max_depth: 10, Best ACC: 0.99, Time: 39.60 seconds\n",
      "Year 1947 - Best n_estimators: 200, Best max_depth: 10, Best ACC: 0.98, Time: 40.33 seconds\n",
      "Year 1948 - Best n_estimators: 50, Best max_depth: None, Best ACC: 0.96, Time: 35.94 seconds\n",
      "Year 1949 - Best n_estimators: 100, Best max_depth: None, Best ACC: 0.97, Time: 38.73 seconds\n",
      "Year 1950 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.96, Time: 43.51 seconds\n",
      "Year 1951 - Best n_estimators: 200, Best max_depth: 10, Best ACC: 0.97, Time: 45.43 seconds\n",
      "Year 1952 - Best n_estimators: 200, Best max_depth: 15, Best ACC: 0.97, Time: 47.75 seconds\n",
      "Year 1953 - Best n_estimators: 100, Best max_depth: 15, Best ACC: 0.96, Time: 46.38 seconds\n",
      "Year 1954 - Best n_estimators: 100, Best max_depth: None, Best ACC: 0.96, Time: 47.71 seconds\n",
      "Year 1955 - Best n_estimators: 100, Best max_depth: None, Best ACC: 0.98, Time: 49.76 seconds\n",
      "Year 1956 - Best n_estimators: 200, Best max_depth: 15, Best ACC: 0.97, Time: 52.62 seconds\n",
      "Year 1957 - Best n_estimators: 200, Best max_depth: 15, Best ACC: 0.97, Time: 53.70 seconds\n",
      "Year 1958 - Best n_estimators: 100, Best max_depth: None, Best ACC: 0.97, Time: 50.54 seconds\n",
      "Year 1959 - Best n_estimators: 100, Best max_depth: 10, Best ACC: 0.98, Time: 49.39 seconds\n",
      "Year 1960 - Best n_estimators: 200, Best max_depth: 15, Best ACC: 0.97, Time: 54.61 seconds\n",
      "Year 1961 - Best n_estimators: 200, Best max_depth: 15, Best ACC: 0.97, Time: 50.92 seconds\n",
      "Year 1962 - Best n_estimators: 10, Best max_depth: 10, Best ACC: 0.98, Time: 45.13 seconds\n",
      "Year 1963 - Best n_estimators: 100, Best max_depth: None, Best ACC: 0.98, Time: 48.32 seconds\n",
      "Year 1964 - Best n_estimators: 200, Best max_depth: 10, Best ACC: 0.96, Time: 53.23 seconds\n",
      "Year 1965 - Best n_estimators: 200, Best max_depth: 10, Best ACC: 0.95, Time: 60.73 seconds\n",
      "Year 1966 - Best n_estimators: 50, Best max_depth: 10, Best ACC: 0.96, Time: 66.50 seconds\n",
      "Year 1967 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.96, Time: 92.06 seconds\n",
      "Year 1968 - Best n_estimators: 50, Best max_depth: 15, Best ACC: 0.98, Time: 93.03 seconds\n",
      "Year 1969 - Best n_estimators: 200, Best max_depth: 10, Best ACC: 0.98, Time: 106.84 seconds\n",
      "Year 1970 - Best n_estimators: 200, Best max_depth: 10, Best ACC: 0.98, Time: 107.61 seconds\n",
      "Year 1971 - Best n_estimators: 100, Best max_depth: 15, Best ACC: 0.97, Time: 104.50 seconds\n",
      "Year 1972 - Best n_estimators: 200, Best max_depth: 15, Best ACC: 0.97, Time: 112.29 seconds\n",
      "Year 1973 - Best n_estimators: 50, Best max_depth: None, Best ACC: 0.97, Time: 101.95 seconds\n",
      "Year 1974 - Best n_estimators: 200, Best max_depth: 10, Best ACC: 0.97, Time: 119.80 seconds\n",
      "Year 1975 - Best n_estimators: 200, Best max_depth: 15, Best ACC: 0.95, Time: 130.66 seconds\n",
      "Year 1976 - Best n_estimators: 100, Best max_depth: 15, Best ACC: 0.96, Time: 131.18 seconds\n",
      "Year 1977 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.96, Time: 143.16 seconds\n",
      "Year 1978 - Best n_estimators: 100, Best max_depth: 10, Best ACC: 0.96, Time: 130.75 seconds\n",
      "Year 1979 - Best n_estimators: 100, Best max_depth: None, Best ACC: 0.97, Time: 134.56 seconds\n",
      "Year 1980 - Best n_estimators: 100, Best max_depth: 15, Best ACC: 0.97, Time: 127.64 seconds\n",
      "Year 1981 - Best n_estimators: 200, Best max_depth: 10, Best ACC: 0.97, Time: 131.48 seconds\n",
      "Year 1982 - Best n_estimators: 50, Best max_depth: None, Best ACC: 0.97, Time: 117.27 seconds\n",
      "Year 1983 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.96, Time: 126.79 seconds\n",
      "Year 1984 - Best n_estimators: 50, Best max_depth: 15, Best ACC: 0.96, Time: 113.35 seconds\n",
      "Year 1985 - Best n_estimators: 50, Best max_depth: 10, Best ACC: 0.94, Time: 148.72 seconds\n",
      "Year 1986 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.95, Time: 219.08 seconds\n",
      "Year 1987 - Best n_estimators: 100, Best max_depth: 15, Best ACC: 0.95, Time: 250.96 seconds\n",
      "Year 1988 - Best n_estimators: 100, Best max_depth: 15, Best ACC: 0.95, Time: 302.98 seconds\n",
      "Year 1989 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.93, Time: 342.58 seconds\n",
      "Year 1990 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.93, Time: 363.41 seconds\n",
      "Year 1991 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.94, Time: 365.57 seconds\n",
      "Year 1992 - Best n_estimators: 200, Best max_depth: 15, Best ACC: 0.94, Time: 368.30 seconds\n",
      "Year 1993 - Best n_estimators: 100, Best max_depth: None, Best ACC: 0.94, Time: 351.12 seconds\n",
      "Year 1994 - Best n_estimators: 200, Best max_depth: 10, Best ACC: 0.95, Time: 356.66 seconds\n",
      "Year 1995 - Best n_estimators: 200, Best max_depth: 15, Best ACC: 0.95, Time: 354.58 seconds\n",
      "Year 1996 - Best n_estimators: 100, Best max_depth: None, Best ACC: 0.95, Time: 354.04 seconds\n",
      "Year 1997 - Best n_estimators: 50, Best max_depth: 15, Best ACC: 0.96, Time: 351.20 seconds\n",
      "Year 1998 - Best n_estimators: 200, Best max_depth: None, Best ACC: 0.97, Time: 429.09 seconds\n",
      "Year 1999 - Best n_estimators: 100, Best max_depth: 15, Best ACC: 0.97, Time: 410.04 seconds\n",
      "Year 2000 - Best n_estimators: 200, Best max_depth: 15, Best ACC: 0.98, Time: 454.52 seconds\n",
      "Year 2001 - Best n_estimators: 200, Best max_depth: 15, Best ACC: 0.98, Time: 455.24 seconds\n",
      "Year 2002 - Best n_estimators: 200, Best max_depth: 10, Best ACC: 0.99, Time: 438.31 seconds\n",
      "Year 2003 - Best n_estimators: 200, Best max_depth: 10, Best ACC: 0.99, Time: 425.52 seconds\n",
      "Year 2004 - Best n_estimators: 200, Best max_depth: 10, Best ACC: 0.99, Time: 399.37 seconds\n",
      "Year 2005 - Best n_estimators: 100, Best max_depth: 15, Best ACC: 0.99, Time: 342.38 seconds\n",
      "Year 2006 - Best n_estimators: 50, Best max_depth: None, Best ACC: 0.99, Time: 303.42 seconds\n",
      "Year 2007 - Best n_estimators: 100, Best max_depth: 15, Best ACC: 0.99, Time: 292.04 seconds\n",
      "Year 2008 - Best n_estimators: 100, Best max_depth: 15, Best ACC: 0.99, Time: 270.87 seconds\n",
      "Year 2009 - Best n_estimators: 100, Best max_depth: 10, Best ACC: 0.99, Time: 266.47 seconds\n",
      "Year 2010 - Best n_estimators: 100, Best max_depth: 15, Best ACC: 0.99, Time: 266.96 seconds\n",
      "Year 2011 - Best n_estimators: 50, Best max_depth: 10, Best ACC: 0.99, Time: 246.85 seconds\n",
      "Year 2012 - Best n_estimators: 100, Best max_depth: 15, Best ACC: 1.0, Time: 243.03 seconds\n",
      "Year 2013 - Best n_estimators: 100, Best max_depth: 10, Best ACC: 0.99, Time: 226.14 seconds\n",
      "Year 2014 - Best n_estimators: 100, Best max_depth: 15, Best ACC: 1.0, Time: 215.81 seconds\n",
      "Year 2015 - Best n_estimators: 200, Best max_depth: 15, Best ACC: 1.0, Time: 220.86 seconds\n",
      "Year 2016 - Best n_estimators: 10, Best max_depth: 10, Best ACC: 1.0, Time: 191.82 seconds\n",
      "Year 2017 - Best n_estimators: 50, Best max_depth: None, Best ACC: 1.0, Time: 193.10 seconds\n",
      "Year 2018 - Best n_estimators: 100, Best max_depth: None, Best ACC: 0.99, Time: 198.01 seconds\n",
      "Year 2019 - Best n_estimators: 50, Best max_depth: None, Best ACC: 0.99, Time: 196.41 seconds\n",
      "Year 2020 - Best n_estimators: 200, Best max_depth: None, Best ACC: 1.0, Time: 220.02 seconds\n",
      "Year 2021 - Best n_estimators: 50, Best max_depth: 10, Best ACC: 1.0, Time: 187.49 seconds\n",
      "Year 2022 - Best n_estimators: 100, Best max_depth: 15, Best ACC: 1.0, Time: 192.53 seconds\n",
      "Total time: 15029.40 seconds\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# RF CLASSIFICATION MODEL - ACCURACY\n",
    "############################################\n",
    "\n",
    "model_name = 'RF_class_roll5'\n",
    "start_time2 = time.time()\n",
    "\n",
    "\n",
    "# Predefined set of values for hyperparameter tuning\n",
    "HP1 = [10, 50, 100, 200]  # Possible values for n_estimators\n",
    "HP2 = [5, 10, 15, None]  # Possible values for max_depth\n",
    "\n",
    "# Update the column name for storing Decision Tree regression predictions\n",
    "df[model_name] = np.nan\n",
    "\n",
    "# Ensure the new column is in the prediction_cols list\n",
    "if model_name not in prediction_cols:\n",
    "    prediction_cols.append(model_name)\n",
    "\n",
    "start_modeling_year = df['year'].min() + 6\n",
    "\n",
    "for year in range(start_modeling_year, df['year'].max() + 1):\n",
    "    start_time = time.time()  # Timing each iteration\n",
    "    \n",
    "    train_start_year = max(year - rolling_window, df['year'].min())\n",
    "    train_data = df[(df['year'] >= train_start_year) & (df['year'] < year)]\n",
    "    \n",
    "    tuning_data = train_data[train_data['year'] == year - 1]\n",
    "    actual_train_data = train_data[train_data['year'] < year - 1]\n",
    "    \n",
    "    X_train = actual_train_data[X_col]\n",
    "    y_train = actual_train_data['y']\n",
    "    \n",
    "    X_tune = tuning_data[X_col]\n",
    "    y_tune = tuning_data['y']\n",
    "    \n",
    "    best_HP1 = None\n",
    "    best_HP2 = None\n",
    "    best_accuracy = -1\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    for hp1 in HP1:\n",
    "        for hp2 in HP2:\n",
    "            model = RandomForestClassifier(n_estimators=hp1, max_depth=hp2, random_state=42, n_jobs=-1)\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict(X_tune)  # Predict continuous values\n",
    "            \n",
    "            # Identify top and bottom deciles\n",
    "            decile_thresholds = np.percentile(predictions, [10, 90])\n",
    "            top_bottom_decile_mask = (predictions <= decile_thresholds[0]) | (predictions >= decile_thresholds[1])\n",
    "\n",
    "            # Filter tuning dataset based on deciles\n",
    "            filtered_y_tune = y_tune[top_bottom_decile_mask]\n",
    "            filtered_predictions = predictions[top_bottom_decile_mask]\n",
    "\n",
    "            # Assuming binary classification, convert continuous predictions to binary\n",
    "            # This conversion logic might need adjustment based on your specific use case\n",
    "            binary_predictions = (filtered_predictions >= 0.5).astype(int)\n",
    "\n",
    "            # Calculate accuracy for filtered predictions\n",
    "            decile_accuracy = accuracy_score(filtered_y_tune, binary_predictions)\n",
    "\n",
    "            if decile_accuracy > best_accuracy:\n",
    "                best_accuracy = decile_accuracy\n",
    "                best_HP1 = hp1\n",
    "                best_HP2 = hp2\n",
    "    \n",
    "    # Retrain on the entire training window with the best max_depth value\n",
    "    model = model = RandomForestClassifier(n_estimators=best_HP1, max_depth=best_HP2, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict for the next year\n",
    "    next_year_data = df[df['year'] == year]\n",
    "    X_next_year = next_year_data[X_col]\n",
    "    \n",
    "    if not X_next_year.empty:\n",
    "        next_year_predictions = model.predict_proba(X_next_year)[:, 1]\n",
    "        df.loc[df['year'] == year, model_name] = next_year_predictions\n",
    "    \n",
    "    end_time = time.time()\n",
    "    iteration_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Year {year} - Best n_estimators: {best_HP1}, Best max_depth: {best_HP2 if best_HP2 is not None else 'None'}, Best ACC: {round(best_accuracy, 2)}, Time: {iteration_time:.2f} seconds\")\n",
    "\n",
    "end_time2 = time.time()\n",
    "print(f\"Total time: {end_time2 - start_time2:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a42d958",
   "metadata": {
    "papermill": {
     "duration": 0.057427,
     "end_time": "2024-02-29T17:40:56.545105",
     "exception": false,
     "start_time": "2024-02-29T17:40:56.487678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Forming Portfolios, Value-weighted portfolio returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "741a2c75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T17:40:56.661108Z",
     "iopub.status.busy": "2024-02-29T17:40:56.660677Z",
     "iopub.status.idle": "2024-02-29T17:40:56.697660Z",
     "shell.execute_reply": "2024-02-29T17:40:56.696862Z"
    },
    "papermill": {
     "duration": 0.097816,
     "end_time": "2024-02-29T17:40:56.699873",
     "exception": false,
     "start_time": "2024-02-29T17:40:56.602057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>RET</th>\n",
       "      <th>ME</th>\n",
       "      <th>bull_D</th>\n",
       "      <th>bear_D</th>\n",
       "      <th>bull_W</th>\n",
       "      <th>bear_W</th>\n",
       "      <th>bull_M</th>\n",
       "      <th>bear_M</th>\n",
       "      <th>LMKT</th>\n",
       "      <th>IVOL</th>\n",
       "      <th>y</th>\n",
       "      <th>STR</th>\n",
       "      <th>LTURNOVER</th>\n",
       "      <th>IMOM</th>\n",
       "      <th>MOM</th>\n",
       "      <th>LTR</th>\n",
       "      <th>PCTHIGH</th>\n",
       "      <th>IVOL2</th>\n",
       "      <th>IVOL3</th>\n",
       "      <th>MVOL</th>\n",
       "      <th>MVOL2</th>\n",
       "      <th>MVOL3</th>\n",
       "      <th>LMKT2</th>\n",
       "      <th>LMKT3</th>\n",
       "      <th>MMOM</th>\n",
       "      <th>MIMOM</th>\n",
       "      <th>MLTR</th>\n",
       "      <th>LSPREAD</th>\n",
       "      <th>year</th>\n",
       "      <th>base_ols_default</th>\n",
       "      <th>ols_default</th>\n",
       "      <th>ridge_clas_roll5</th>\n",
       "      <th>DT_class_roll5</th>\n",
       "      <th>RF_class_roll5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14314</td>\n",
       "      <td>1927-08-31</td>\n",
       "      <td>-0.164557</td>\n",
       "      <td>3902.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538722</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040267</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.551246</td>\n",
       "      <td>0.668133</td>\n",
       "      <td>0.709597</td>\n",
       "      <td>0.443203</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.397061</td>\n",
       "      <td>0.511976</td>\n",
       "      <td>0.645637</td>\n",
       "      <td>0.529397</td>\n",
       "      <td>0.644251</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>1927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12730</td>\n",
       "      <td>1927-08-31</td>\n",
       "      <td>-0.069853</td>\n",
       "      <td>88107.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538722</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043893</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.611572</td>\n",
       "      <td>0.736577</td>\n",
       "      <td>0.697120</td>\n",
       "      <td>0.824047</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.397061</td>\n",
       "      <td>0.511976</td>\n",
       "      <td>0.645637</td>\n",
       "      <td>0.529397</td>\n",
       "      <td>0.644251</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>1927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11594</td>\n",
       "      <td>1927-08-31</td>\n",
       "      <td>0.149390</td>\n",
       "      <td>14137.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538722</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045470</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.572206</td>\n",
       "      <td>0.709391</td>\n",
       "      <td>0.708355</td>\n",
       "      <td>0.869882</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.397061</td>\n",
       "      <td>0.511976</td>\n",
       "      <td>0.645637</td>\n",
       "      <td>0.529397</td>\n",
       "      <td>0.644251</td>\n",
       "      <td>0.005677</td>\n",
       "      <td>1927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75471</td>\n",
       "      <td>1927-08-31</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>1575.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538722</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040866</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.570800</td>\n",
       "      <td>0.709576</td>\n",
       "      <td>0.684379</td>\n",
       "      <td>0.860310</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.397061</td>\n",
       "      <td>0.511976</td>\n",
       "      <td>0.645637</td>\n",
       "      <td>0.529397</td>\n",
       "      <td>0.644251</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>1927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10786</td>\n",
       "      <td>1927-08-31</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>111600.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538722</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045594</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.596852</td>\n",
       "      <td>0.722659</td>\n",
       "      <td>0.703022</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.397061</td>\n",
       "      <td>0.511976</td>\n",
       "      <td>0.645637</td>\n",
       "      <td>0.529397</td>\n",
       "      <td>0.644251</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>1927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PERMNO       date       RET         ME  bull_D    bear_D    bull_W  \\\n",
       "0   14314 1927-08-31 -0.164557    3902.25     0.0  0.000000  0.000000   \n",
       "1   12730 1927-08-31 -0.069853   88107.25     0.0  0.416667  0.000000   \n",
       "2   11594 1927-08-31  0.149390   14137.50     0.0  0.083333  0.000000   \n",
       "3   75471 1927-08-31  0.216216    1575.00     0.0  0.000000  0.000000   \n",
       "4   10786 1927-08-31  0.169811  111600.00     0.0  0.166667  0.583333   \n",
       "\n",
       "     bear_W    bull_M  bear_M      LMKT      IVOL  y       STR  LTURNOVER  \\\n",
       "0  0.083333  0.000000     0.0  0.538722  0.000033  0  0.040267   0.000003   \n",
       "1  0.000000  0.000000     0.0  0.538722  0.000005  0  0.043893   0.000019   \n",
       "2  0.000000  0.250000     0.0  0.538722  0.000077  1  0.045470   0.000002   \n",
       "3  0.000000  0.083333     0.0  0.538722  0.000090  1  0.040866   0.000003   \n",
       "4  0.000000  0.083333     0.0  0.538722  0.000013  1  0.045594   0.000056   \n",
       "\n",
       "       IMOM       MOM       LTR   PCTHIGH     IVOL2     IVOL3     MVOL  \\\n",
       "0  0.551246  0.668133  0.709597  0.443203  0.000036  0.000097  0.00106   \n",
       "1  0.611572  0.736577  0.697120  0.824047  0.000005  0.000004  0.00106   \n",
       "2  0.572206  0.709391  0.708355  0.869882  0.000005  0.000018  0.00106   \n",
       "3  0.570800  0.709576  0.684379  0.860310  0.000038  0.000123  0.00106   \n",
       "4  0.596852  0.722659  0.703022  1.000000  0.000003  0.000006  0.00106   \n",
       "\n",
       "      MVOL2     MVOL3     LMKT2     LMKT3      MMOM     MIMOM      MLTR  \\\n",
       "0  0.008129  0.001942  0.397061  0.511976  0.645637  0.529397  0.644251   \n",
       "1  0.008129  0.001942  0.397061  0.511976  0.645637  0.529397  0.644251   \n",
       "2  0.008129  0.001942  0.397061  0.511976  0.645637  0.529397  0.644251   \n",
       "3  0.008129  0.001942  0.397061  0.511976  0.645637  0.529397  0.644251   \n",
       "4  0.008129  0.001942  0.397061  0.511976  0.645637  0.529397  0.644251   \n",
       "\n",
       "    LSPREAD  year  base_ols_default  ols_default  ridge_clas_roll5  \\\n",
       "0  0.002245  1927               NaN          NaN               NaN   \n",
       "1  0.001956  1927               NaN          NaN               NaN   \n",
       "2  0.005677  1927               NaN          NaN               NaN   \n",
       "3  0.003594  1927               NaN          NaN               NaN   \n",
       "4  0.003555  1927               NaN          NaN               NaN   \n",
       "\n",
       "   DT_class_roll5  RF_class_roll5  \n",
       "0             NaN             NaN  \n",
       "1             NaN             NaN  \n",
       "2             NaN             NaN  \n",
       "3             NaN             NaN  \n",
       "4             NaN             NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c1f1522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T17:40:56.816822Z",
     "iopub.status.busy": "2024-02-29T17:40:56.815850Z",
     "iopub.status.idle": "2024-02-29T17:40:56.822352Z",
     "shell.execute_reply": "2024-02-29T17:40:56.821525Z"
    },
    "papermill": {
     "duration": 0.067073,
     "end_time": "2024-02-29T17:40:56.824487",
     "exception": false,
     "start_time": "2024-02-29T17:40:56.757414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_ols_default',\n",
       " 'ols_default',\n",
       " 'ridge_clas_roll5',\n",
       " 'DT_class_roll5',\n",
       " 'RF_class_roll5']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_cols\n",
    "# prediction_cols = ['logit_default','OLS_default','logit_roll6','DT_reg_roll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aeed824",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T17:40:56.940914Z",
     "iopub.status.busy": "2024-02-29T17:40:56.939819Z",
     "iopub.status.idle": "2024-02-29T17:40:58.562231Z",
     "shell.execute_reply": "2024-02-29T17:40:58.560957Z"
    },
    "papermill": {
     "duration": 1.683728,
     "end_time": "2024-02-29T17:40:58.565053",
     "exception": false,
     "start_time": "2024-02-29T17:40:56.881325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>RET</th>\n",
       "      <th>ME</th>\n",
       "      <th>y</th>\n",
       "      <th>base_ols_default</th>\n",
       "      <th>ols_default</th>\n",
       "      <th>ridge_clas_roll5</th>\n",
       "      <th>DT_class_roll5</th>\n",
       "      <th>RF_class_roll5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39215</th>\n",
       "      <td>1933-01-31</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>456.750</td>\n",
       "      <td>1</td>\n",
       "      <td>0.275076</td>\n",
       "      <td>0.589930</td>\n",
       "      <td>5.548031e-01</td>\n",
       "      <td>0.84842</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39216</th>\n",
       "      <td>1933-01-31</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>18036.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.756186</td>\n",
       "      <td>0.945905</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39217</th>\n",
       "      <td>1933-01-31</td>\n",
       "      <td>-0.006993</td>\n",
       "      <td>1975.125</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050649</td>\n",
       "      <td>0.231157</td>\n",
       "      <td>8.458596e-08</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39218</th>\n",
       "      <td>1933-01-31</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>241.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.704957</td>\n",
       "      <td>0.862059</td>\n",
       "      <td>9.997302e-01</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39219</th>\n",
       "      <td>1933-01-31</td>\n",
       "      <td>-0.058824</td>\n",
       "      <td>3304.000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.222943</td>\n",
       "      <td>-0.008792</td>\n",
       "      <td>5.928324e-14</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date       RET         ME  y  base_ols_default  ols_default  \\\n",
       "39215 1933-01-31  0.058824    456.750  1          0.275076     0.589930   \n",
       "39216 1933-01-31  0.427451  18036.000  1          0.756186     0.945905   \n",
       "39217 1933-01-31 -0.006993   1975.125  0          0.050649     0.231157   \n",
       "39218 1933-01-31  0.166667    241.500  1          0.704957     0.862059   \n",
       "39219 1933-01-31 -0.058824   3304.000  0         -0.222943    -0.008792   \n",
       "\n",
       "       ridge_clas_roll5  DT_class_roll5  RF_class_roll5  \n",
       "39215      5.548031e-01         0.84842            0.57  \n",
       "39216      1.000000e+00         1.00000            0.93  \n",
       "39217      8.458596e-08         0.00000            0.06  \n",
       "39218      9.997302e-01         1.00000            0.85  \n",
       "39219      5.928324e-14         0.00000            0.02  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio = df[['date', 'RET', 'ME', 'y'] + prediction_cols].copy()\n",
    "portfolio['date'] = pd.to_datetime(portfolio['date'])\n",
    "\n",
    "# drop rows with missing values\n",
    "portfolio.dropna(inplace=True)\n",
    "\n",
    "portfolio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c135ab09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T17:40:58.683661Z",
     "iopub.status.busy": "2024-02-29T17:40:58.682415Z",
     "iopub.status.idle": "2024-02-29T17:40:58.700143Z",
     "shell.execute_reply": "2024-02-29T17:40:58.698994Z"
    },
    "papermill": {
     "duration": 0.079281,
     "end_time": "2024-02-29T17:40:58.702646",
     "exception": false,
     "start_time": "2024-02-29T17:40:58.623365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>RET</th>\n",
       "      <th>ME</th>\n",
       "      <th>y</th>\n",
       "      <th>base_ols_default</th>\n",
       "      <th>ols_default</th>\n",
       "      <th>ridge_clas_roll5</th>\n",
       "      <th>DT_class_roll5</th>\n",
       "      <th>RF_class_roll5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3076047</th>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>-0.203046</td>\n",
       "      <td>4.174787e+04</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.784252</td>\n",
       "      <td>-0.838064</td>\n",
       "      <td>8.842566e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076048</th>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>1.110135e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.859305</td>\n",
       "      <td>0.836580</td>\n",
       "      <td>9.335867e-01</td>\n",
       "      <td>0.978878</td>\n",
       "      <td>0.966140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076049</th>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>0.074970</td>\n",
       "      <td>3.728386e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.907330</td>\n",
       "      <td>0.869929</td>\n",
       "      <td>9.943753e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076050</th>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>-0.029348</td>\n",
       "      <td>1.304941e+05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088415</td>\n",
       "      <td>0.048938</td>\n",
       "      <td>1.142512e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076051</th>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>0.323765</td>\n",
       "      <td>9.311106e+08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.723794</td>\n",
       "      <td>0.825924</td>\n",
       "      <td>9.377386e-01</td>\n",
       "      <td>0.978878</td>\n",
       "      <td>0.953506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date       RET            ME  y  base_ols_default  ols_default  \\\n",
       "3076047 2022-07-31 -0.203046  4.174787e+04  0         -0.784252    -0.838064   \n",
       "3076048 2022-07-31  0.135593  1.110135e+06  1          0.859305     0.836580   \n",
       "3076049 2022-07-31  0.074970  3.728386e+06  1          0.907330     0.869929   \n",
       "3076050 2022-07-31 -0.029348  1.304941e+05  0          0.088415     0.048938   \n",
       "3076051 2022-07-31  0.323765  9.311106e+08  1          0.723794     0.825924   \n",
       "\n",
       "         ridge_clas_roll5  DT_class_roll5  RF_class_roll5  \n",
       "3076047      8.842566e-08        0.000000        0.049690  \n",
       "3076048      9.335867e-01        0.978878        0.966140  \n",
       "3076049      9.943753e-01        1.000000        0.990000  \n",
       "3076050      1.142512e-02        0.000000        0.009133  \n",
       "3076051      9.377386e-01        0.978878        0.953506  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "642d6c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T17:40:58.821141Z",
     "iopub.status.busy": "2024-02-29T17:40:58.820177Z",
     "iopub.status.idle": "2024-02-29T17:41:16.238252Z",
     "shell.execute_reply": "2024-02-29T17:41:16.236946Z"
    },
    "papermill": {
     "duration": 17.482218,
     "end_time": "2024-02-29T17:41:16.242824",
     "exception": false,
     "start_time": "2024-02-29T17:40:58.760606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2999037948.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  vwreturns_temp = portfolio.groupby('date').apply(lambda x: np.sum(x['RET'] * x['ME'] * x[position_col]) / np.sum(x['ME'])).reset_index(name=vwret_col)\n",
      "/tmp/ipykernel_18/2999037948.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  vwreturns_temp = portfolio.groupby('date').apply(lambda x: np.sum(x['RET'] * x['ME'] * x[position_col]) / np.sum(x['ME'])).reset_index(name=vwret_col)\n",
      "/tmp/ipykernel_18/2999037948.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  vwreturns_temp = portfolio.groupby('date').apply(lambda x: np.sum(x['RET'] * x['ME'] * x[position_col]) / np.sum(x['ME'])).reset_index(name=vwret_col)\n",
      "/tmp/ipykernel_18/2999037948.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  vwreturns_temp = portfolio.groupby('date').apply(lambda x: np.sum(x['RET'] * x['ME'] * x[position_col]) / np.sum(x['ME'])).reset_index(name=vwret_col)\n",
      "/tmp/ipykernel_18/2999037948.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  vwreturns_temp = portfolio.groupby('date').apply(lambda x: np.sum(x['RET'] * x['ME'] * x[position_col]) / np.sum(x['ME'])).reset_index(name=vwret_col)\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store value-weighted returns for each model\n",
    "vwreturns = pd.DataFrame(portfolio['date'].unique(), columns=['date'])  # Ensures all dates are included\n",
    "\n",
    "for pred_col in prediction_cols:\n",
    "    # Calculate deciles for this prediction\n",
    "    decile_col = f'decile_{pred_col}'\n",
    "    portfolio[decile_col] = portfolio.groupby(['date'])[pred_col].transform(lambda x: pd.qcut(x, 10, labels=False, duplicates='drop'))\n",
    "    \n",
    "    # Determine position based on deciles\n",
    "    position_col = f'position_{pred_col}'\n",
    "    portfolio[position_col] = np.where(portfolio[decile_col] == 9, 1, np.where(portfolio[decile_col] == 0, -1, 0))\n",
    "    \n",
    "    # Calculate the value-weighted return for this prediction\n",
    "    vwret_col = f'vwreturn_{pred_col}'\n",
    "    vwreturns_temp = portfolio.groupby('date').apply(lambda x: np.sum(x['RET'] * x['ME'] * x[position_col]) / np.sum(x['ME'])).reset_index(name=vwret_col)\n",
    "    \n",
    "    # Merge the temporary value-weighted returns with the main vwreturns DataFrame\n",
    "    vwreturns = vwreturns.merge(vwreturns_temp, on='date', how='left')\n",
    "\n",
    "# Ensure the 'date' column is the first column and is sorted\n",
    "vwreturns = vwreturns.sort_values('date').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e32a96eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T17:41:16.362719Z",
     "iopub.status.busy": "2024-02-29T17:41:16.361662Z",
     "iopub.status.idle": "2024-02-29T17:41:16.376653Z",
     "shell.execute_reply": "2024-02-29T17:41:16.375352Z"
    },
    "papermill": {
     "duration": 0.077636,
     "end_time": "2024-02-29T17:41:16.379058",
     "exception": false,
     "start_time": "2024-02-29T17:41:16.301422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>vwreturn_base_ols_default</th>\n",
       "      <th>vwreturn_ols_default</th>\n",
       "      <th>vwreturn_ridge_clas_roll5</th>\n",
       "      <th>vwreturn_DT_class_roll5</th>\n",
       "      <th>vwreturn_RF_class_roll5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1933-01-31</td>\n",
       "      <td>0.020350</td>\n",
       "      <td>0.018723</td>\n",
       "      <td>0.024002</td>\n",
       "      <td>0.021283</td>\n",
       "      <td>0.018664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1933-02-28</td>\n",
       "      <td>0.010923</td>\n",
       "      <td>0.011374</td>\n",
       "      <td>0.009797</td>\n",
       "      <td>0.065299</td>\n",
       "      <td>0.016778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1933-03-31</td>\n",
       "      <td>0.028053</td>\n",
       "      <td>0.019686</td>\n",
       "      <td>0.020832</td>\n",
       "      <td>0.026689</td>\n",
       "      <td>0.018977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1933-04-30</td>\n",
       "      <td>0.075213</td>\n",
       "      <td>0.103667</td>\n",
       "      <td>0.104251</td>\n",
       "      <td>-0.006130</td>\n",
       "      <td>0.008683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1933-05-31</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.022140</td>\n",
       "      <td>0.022650</td>\n",
       "      <td>-0.004763</td>\n",
       "      <td>0.019891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  vwreturn_base_ols_default  vwreturn_ols_default  \\\n",
       "0 1933-01-31                   0.020350              0.018723   \n",
       "1 1933-02-28                   0.010923              0.011374   \n",
       "2 1933-03-31                   0.028053              0.019686   \n",
       "3 1933-04-30                   0.075213              0.103667   \n",
       "4 1933-05-31                   0.024194              0.022140   \n",
       "\n",
       "   vwreturn_ridge_clas_roll5  vwreturn_DT_class_roll5  vwreturn_RF_class_roll5  \n",
       "0                   0.024002                 0.021283                 0.018664  \n",
       "1                   0.009797                 0.065299                 0.016778  \n",
       "2                   0.020832                 0.026689                 0.018977  \n",
       "3                   0.104251                -0.006130                 0.008683  \n",
       "4                   0.022650                -0.004763                 0.019891  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vwreturns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ace968",
   "metadata": {
    "papermill": {
     "duration": 0.058498,
     "end_time": "2024-02-29T17:41:16.496354",
     "exception": false,
     "start_time": "2024-02-29T17:41:16.437856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Compare to market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "564121fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T17:41:16.616734Z",
     "iopub.status.busy": "2024-02-29T17:41:16.615893Z",
     "iopub.status.idle": "2024-02-29T17:41:16.658008Z",
     "shell.execute_reply": "2024-02-29T17:41:16.657118Z"
    },
    "papermill": {
     "duration": 0.10551,
     "end_time": "2024-02-29T17:41:16.660570",
     "exception": false,
     "start_time": "2024-02-29T17:41:16.555060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#market = pd.read_csv('FF3_clean.csv')\n",
    "market = pd.read_csv('/kaggle/input/sign-prediction-datasets/FF3_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f935560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T17:41:16.781059Z",
     "iopub.status.busy": "2024-02-29T17:41:16.780275Z",
     "iopub.status.idle": "2024-02-29T17:41:16.794610Z",
     "shell.execute_reply": "2024-02-29T17:41:16.793323Z"
    },
    "papermill": {
     "duration": 0.077803,
     "end_time": "2024-02-29T17:41:16.797277",
     "exception": false,
     "start_time": "2024-02-29T17:41:16.719474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1926-07-31</td>\n",
       "      <td>2.96</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>-2.43</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1926-08-31</td>\n",
       "      <td>2.64</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1926-09-30</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1926-10-31</td>\n",
       "      <td>-3.24</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1926-11-30</td>\n",
       "      <td>2.53</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  Mkt-RF   SMB   HML    RF\n",
       "0  1926-07-31    2.96 -2.56 -2.43  0.22\n",
       "1  1926-08-31    2.64 -1.17  3.82  0.25\n",
       "2  1926-09-30    0.36 -1.40  0.13  0.23\n",
       "3  1926-10-31   -3.24 -0.09  0.70  0.32\n",
       "4  1926-11-30    2.53 -0.10 -0.51  0.31"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f71abf27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T17:41:16.918008Z",
     "iopub.status.busy": "2024-02-29T17:41:16.917160Z",
     "iopub.status.idle": "2024-02-29T17:41:16.937574Z",
     "shell.execute_reply": "2024-02-29T17:41:16.936253Z"
    },
    "papermill": {
     "duration": 0.083771,
     "end_time": "2024-02-29T17:41:16.940378",
     "exception": false,
     "start_time": "2024-02-29T17:41:16.856607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a new 'Mkt' which is a sum of Mkt-RF and RF\n",
    "market['Mkt'] = market['Mkt-RF'] + market['RF']\n",
    "\n",
    "# divide all columns by 100 except 'date'\n",
    "market.iloc[:, 1:] = market.iloc[:, 1:] / 100\n",
    "\n",
    "#set the 'date' column to datetime format\n",
    "market['date'] = pd.to_datetime(market['date'])\n",
    "\n",
    "# merge the market data (only date and Mkt columns) with the vwreturns DataFrame\n",
    "vwreturns = vwreturns.merge(market[['date', 'Mkt']], on='date', how='left')\n",
    "\n",
    "# transform all columns (except 'date') to a log: log(x+1) and save the result as lvwreturns\n",
    "lvwreturns = vwreturns.copy()\n",
    "lvwreturns.iloc[:, 1:] = np.log(vwreturns.iloc[:, 1:] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a0b61cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T17:41:17.061480Z",
     "iopub.status.busy": "2024-02-29T17:41:17.060237Z",
     "iopub.status.idle": "2024-02-29T17:41:17.077121Z",
     "shell.execute_reply": "2024-02-29T17:41:17.076108Z"
    },
    "papermill": {
     "duration": 0.080094,
     "end_time": "2024-02-29T17:41:17.079495",
     "exception": false,
     "start_time": "2024-02-29T17:41:16.999401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>vwreturn_base_ols_default</th>\n",
       "      <th>vwreturn_ols_default</th>\n",
       "      <th>vwreturn_ridge_clas_roll5</th>\n",
       "      <th>vwreturn_DT_class_roll5</th>\n",
       "      <th>vwreturn_RF_class_roll5</th>\n",
       "      <th>Mkt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1933-01-31</td>\n",
       "      <td>0.020350</td>\n",
       "      <td>0.018723</td>\n",
       "      <td>0.024002</td>\n",
       "      <td>0.021283</td>\n",
       "      <td>0.018664</td>\n",
       "      <td>0.0126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1933-02-28</td>\n",
       "      <td>0.010923</td>\n",
       "      <td>0.011374</td>\n",
       "      <td>0.009797</td>\n",
       "      <td>0.065299</td>\n",
       "      <td>0.016778</td>\n",
       "      <td>-0.1527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1933-03-31</td>\n",
       "      <td>0.028053</td>\n",
       "      <td>0.019686</td>\n",
       "      <td>0.020832</td>\n",
       "      <td>0.026689</td>\n",
       "      <td>0.018977</td>\n",
       "      <td>0.0333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1933-04-30</td>\n",
       "      <td>0.075213</td>\n",
       "      <td>0.103667</td>\n",
       "      <td>0.104251</td>\n",
       "      <td>-0.006130</td>\n",
       "      <td>0.008683</td>\n",
       "      <td>0.3895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1933-05-31</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.022140</td>\n",
       "      <td>0.022650</td>\n",
       "      <td>-0.004763</td>\n",
       "      <td>0.019891</td>\n",
       "      <td>0.2147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  vwreturn_base_ols_default  vwreturn_ols_default  \\\n",
       "0 1933-01-31                   0.020350              0.018723   \n",
       "1 1933-02-28                   0.010923              0.011374   \n",
       "2 1933-03-31                   0.028053              0.019686   \n",
       "3 1933-04-30                   0.075213              0.103667   \n",
       "4 1933-05-31                   0.024194              0.022140   \n",
       "\n",
       "   vwreturn_ridge_clas_roll5  vwreturn_DT_class_roll5  \\\n",
       "0                   0.024002                 0.021283   \n",
       "1                   0.009797                 0.065299   \n",
       "2                   0.020832                 0.026689   \n",
       "3                   0.104251                -0.006130   \n",
       "4                   0.022650                -0.004763   \n",
       "\n",
       "   vwreturn_RF_class_roll5     Mkt  \n",
       "0                 0.018664  0.0126  \n",
       "1                 0.016778 -0.1527  \n",
       "2                 0.018977  0.0333  \n",
       "3                 0.008683  0.3895  \n",
       "4                 0.019891  0.2147  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vwreturns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fbd4a51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T17:41:17.200141Z",
     "iopub.status.busy": "2024-02-29T17:41:17.199704Z",
     "iopub.status.idle": "2024-02-29T17:41:17.215519Z",
     "shell.execute_reply": "2024-02-29T17:41:17.214252Z"
    },
    "papermill": {
     "duration": 0.079775,
     "end_time": "2024-02-29T17:41:17.218582",
     "exception": false,
     "start_time": "2024-02-29T17:41:17.138807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>vwreturn_base_ols_default</th>\n",
       "      <th>vwreturn_ols_default</th>\n",
       "      <th>vwreturn_ridge_clas_roll5</th>\n",
       "      <th>vwreturn_DT_class_roll5</th>\n",
       "      <th>vwreturn_RF_class_roll5</th>\n",
       "      <th>Mkt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1933-01-31</td>\n",
       "      <td>0.020146</td>\n",
       "      <td>0.018550</td>\n",
       "      <td>0.023718</td>\n",
       "      <td>0.021059</td>\n",
       "      <td>0.018492</td>\n",
       "      <td>0.012521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1933-02-28</td>\n",
       "      <td>0.010864</td>\n",
       "      <td>0.011309</td>\n",
       "      <td>0.009749</td>\n",
       "      <td>0.063255</td>\n",
       "      <td>0.016639</td>\n",
       "      <td>-0.165700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1933-03-31</td>\n",
       "      <td>0.027667</td>\n",
       "      <td>0.019495</td>\n",
       "      <td>0.020618</td>\n",
       "      <td>0.026339</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.032758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1933-04-30</td>\n",
       "      <td>0.072519</td>\n",
       "      <td>0.098638</td>\n",
       "      <td>0.099167</td>\n",
       "      <td>-0.006149</td>\n",
       "      <td>0.008645</td>\n",
       "      <td>0.328944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1933-05-31</td>\n",
       "      <td>0.023906</td>\n",
       "      <td>0.021899</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>-0.004774</td>\n",
       "      <td>0.019696</td>\n",
       "      <td>0.194497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  vwreturn_base_ols_default  vwreturn_ols_default  \\\n",
       "0 1933-01-31                   0.020146              0.018550   \n",
       "1 1933-02-28                   0.010864              0.011309   \n",
       "2 1933-03-31                   0.027667              0.019495   \n",
       "3 1933-04-30                   0.072519              0.098638   \n",
       "4 1933-05-31                   0.023906              0.021899   \n",
       "\n",
       "   vwreturn_ridge_clas_roll5  vwreturn_DT_class_roll5  \\\n",
       "0                   0.023718                 0.021059   \n",
       "1                   0.009749                 0.063255   \n",
       "2                   0.020618                 0.026339   \n",
       "3                   0.099167                -0.006149   \n",
       "4                   0.022398                -0.004774   \n",
       "\n",
       "   vwreturn_RF_class_roll5       Mkt  \n",
       "0                 0.018492  0.012521  \n",
       "1                 0.016639 -0.165700  \n",
       "2                 0.018800  0.032758  \n",
       "3                 0.008645  0.328944  \n",
       "4                 0.019696  0.194497  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvwreturns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd1fa8a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T17:41:17.342612Z",
     "iopub.status.busy": "2024-02-29T17:41:17.342226Z",
     "iopub.status.idle": "2024-02-29T17:41:17.376416Z",
     "shell.execute_reply": "2024-02-29T17:41:17.375229Z"
    },
    "papermill": {
     "duration": 0.097526,
     "end_time": "2024-02-29T17:41:17.378988",
     "exception": false,
     "start_time": "2024-02-29T17:41:17.281462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>vwreturn_base_ols_default</th>\n",
       "      <th>vwreturn_ols_default</th>\n",
       "      <th>vwreturn_ridge_clas_roll5</th>\n",
       "      <th>vwreturn_DT_class_roll5</th>\n",
       "      <th>vwreturn_RF_class_roll5</th>\n",
       "      <th>Mkt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1072</td>\n",
       "      <td>1072.000000</td>\n",
       "      <td>1072.000000</td>\n",
       "      <td>1072.000000</td>\n",
       "      <td>1072.000000</td>\n",
       "      <td>1072.000000</td>\n",
       "      <td>1072.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1977-11-17 20:54:37.611940288</td>\n",
       "      <td>0.014942</td>\n",
       "      <td>0.014632</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>0.013466</td>\n",
       "      <td>0.009039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1933-01-31 00:00:00</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>-0.046196</td>\n",
       "      <td>-0.042875</td>\n",
       "      <td>-0.245581</td>\n",
       "      <td>-0.002884</td>\n",
       "      <td>-0.272203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1955-05-23 06:00:00</td>\n",
       "      <td>0.009826</td>\n",
       "      <td>0.009861</td>\n",
       "      <td>0.007268</td>\n",
       "      <td>-0.008432</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>-0.017248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1977-12-15 12:00:00</td>\n",
       "      <td>0.013586</td>\n",
       "      <td>0.013339</td>\n",
       "      <td>0.010994</td>\n",
       "      <td>0.006490</td>\n",
       "      <td>0.012197</td>\n",
       "      <td>0.013262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2000-04-07 12:00:00</td>\n",
       "      <td>0.018027</td>\n",
       "      <td>0.017580</td>\n",
       "      <td>0.015275</td>\n",
       "      <td>0.023977</td>\n",
       "      <td>0.017050</td>\n",
       "      <td>0.038235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2022-07-31 00:00:00</td>\n",
       "      <td>0.078491</td>\n",
       "      <td>0.098638</td>\n",
       "      <td>0.099167</td>\n",
       "      <td>0.207777</td>\n",
       "      <td>0.081457</td>\n",
       "      <td>0.328944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.007952</td>\n",
       "      <td>0.007948</td>\n",
       "      <td>0.035807</td>\n",
       "      <td>0.008550</td>\n",
       "      <td>0.048197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                date  vwreturn_base_ols_default  \\\n",
       "count                           1072                1072.000000   \n",
       "mean   1977-11-17 20:54:37.611940288                   0.014942   \n",
       "min              1933-01-31 00:00:00                  -0.011114   \n",
       "25%              1955-05-23 06:00:00                   0.009826   \n",
       "50%              1977-12-15 12:00:00                   0.013586   \n",
       "75%              2000-04-07 12:00:00                   0.018027   \n",
       "max              2022-07-31 00:00:00                   0.078491   \n",
       "std                              NaN                   0.007929   \n",
       "\n",
       "       vwreturn_ols_default  vwreturn_ridge_clas_roll5  \\\n",
       "count           1072.000000                1072.000000   \n",
       "mean               0.014632                   0.011833   \n",
       "min               -0.046196                  -0.042875   \n",
       "25%                0.009861                   0.007268   \n",
       "50%                0.013339                   0.010994   \n",
       "75%                0.017580                   0.015275   \n",
       "max                0.098638                   0.099167   \n",
       "std                0.007952                   0.007948   \n",
       "\n",
       "       vwreturn_DT_class_roll5  vwreturn_RF_class_roll5          Mkt  \n",
       "count              1072.000000              1072.000000  1072.000000  \n",
       "mean                  0.007225                 0.013466     0.009039  \n",
       "min                  -0.245581                -0.002884    -0.272203  \n",
       "25%                  -0.008432                 0.008122    -0.017248  \n",
       "50%                   0.006490                 0.012197     0.013262  \n",
       "75%                   0.023977                 0.017050     0.038235  \n",
       "max                   0.207777                 0.081457     0.328944  \n",
       "std                   0.035807                 0.008550     0.048197  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvwreturns.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "404a9227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T17:41:17.502771Z",
     "iopub.status.busy": "2024-02-29T17:41:17.502331Z",
     "iopub.status.idle": "2024-02-29T17:41:20.652852Z",
     "shell.execute_reply": "2024-02-29T17:41:20.651911Z"
    },
    "papermill": {
     "duration": 3.215672,
     "end_time": "2024-02-29T17:41:20.655536",
     "exception": false,
     "start_time": "2024-02-29T17:41:17.439864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the lvwreturns and portfolio DataFrame to a parquet file into 'outputs' folder\n",
    "\n",
    "# for reproducibility and visualization purposes\n",
    "lvwreturns.to_parquet('market_lvwreturns_class1.parquet')\n",
    "portfolio.to_parquet('market_portfolio_class1.parquet')\n",
    "\n",
    "# save vwreturns DataFrame to a .dta file into 'outputs' folder\n",
    "#vwreturns.to_stata('outputs/vwreturns.dta') # for backtasting in R - we need normal returns, not log returns\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4464890,
     "sourceId": 7657795,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20310.625563,
   "end_time": "2024-02-29T17:41:21.589332",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-29T12:02:50.963769",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
